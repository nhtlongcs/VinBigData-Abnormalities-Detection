{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2021_VINBIGDATA_DETECTRON2_101_FOLD0",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg6bQN7DkgWy+igoscOGy8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhtlongcs/VinBigData-Abnormalities-Detection/blob/ffyytt-detectron2/2021_TRAIN_VINBIGDATA_DETECTRON2_KFOLD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dl3WwtZYNAY",
        "outputId": "772a525d-df4c-4f19-df1c-595f2f8bbd3a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Mar  6 08:18:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKIJPQl5YSik",
        "outputId": "4d4a375c-8cfa-4e87-986e-d9d0280b2dc5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUlvCcjqYT5D",
        "outputId": "3eca6aad-dd43-45ca-ce35-7c7803a7a9ae"
      },
      "source": [
        "!pip install -qq PyYAML==5.4.1\r\n",
        "!pip install -qq detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\r\n",
        "!pip install -qq git+https://github.com/albumentations-team/albumentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KqvMVd0YXaj"
      },
      "source": [
        "import json\r\n",
        "token = {\"username\":\"duonganhkiet\",\"key\":\"c7b0eb66e2722030c850b9ea619a3fb0\"}\r\n",
        "!mkdir -p '/root/.kaggle/'\r\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\r\n",
        "    json.dump(token, file)\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB_7Q8TpYY-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15270cb2-4036-4346-8c2f-65b61676abb0"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import copy\r\n",
        "import time\r\n",
        "import yaml\r\n",
        "import random\r\n",
        "import logging\r\n",
        "import zipfile\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import multiprocessing\r\n",
        "\r\n",
        "from tqdm import *\r\n",
        "from typing import *\r\n",
        "from glob import glob\r\n",
        "from pathlib import Path\r\n",
        "from collections import OrderedDict\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "import albumentations as A\r\n",
        "from albumentations.pytorch.transforms import ToTensorV2\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.nn.parallel import DistributedDataParallel\r\n",
        "import torchvision\r\n",
        "\r\n",
        "import detectron2\r\n",
        "from detectron2.data import *\r\n",
        "from detectron2.config import *\r\n",
        "from detectron2.solver import *\r\n",
        "from detectron2 import model_zoo\r\n",
        "from detectron2.modeling import *\r\n",
        "from detectron2.checkpoint import *\r\n",
        "from detectron2.evaluation import *\r\n",
        "from detectron2.structures import *\r\n",
        "import detectron2.utils.comm as comm\r\n",
        "from detectron2.utils.events import *\r\n",
        "from detectron2.utils.visualizer import *\r\n",
        "from detectron2.data import detection_utils as utils\r\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer, launch\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV_DfX-1Ydtj"
      },
      "source": [
        "if not os.path.exists('data/vinbigdata/'):\r\n",
        "    os.makedirs('data/vinbigdata/')\r\n",
        "    !kaggle datasets download -d duonganhkiet/2021-vin-mydataset\r\n",
        "    !unzip -q 2021-vin-mydataset.zip -d data/vinbigdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jC2ktEfYycz"
      },
      "source": [
        "FOLD = 0\r\n",
        "config = {\r\n",
        "    'image_paths': 'data/vinbigdata/train/',\r\n",
        "    'fold': FOLD,\r\n",
        "    'train_no_finding': False,\r\n",
        "    'seed': 1312,\r\n",
        "\r\n",
        "    'yaml': \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\",\r\n",
        "    'WEIGHT': None,\r\n",
        "\r\n",
        "    'imgSize': 2048,\r\n",
        "    'batch_size': 2,\r\n",
        "    'lr': 3e-3,\r\n",
        "    'epochs': 38,\r\n",
        "\r\n",
        "    'save_dir': 'gdrive/MyDrive/2021_VINBIGDATA/NEW_FOLD/DETECTRON2_101/FOLD'+str(FOLD),\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RM7gAIGZZUk"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "    random.seed(seed)\r\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "\r\n",
        "seed_everything(config['seed'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWGEp5zoZbFP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "91ebce71-6e6a-4742-8557-4ef960ac10e5"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "df = pd.read_csv('data/vinbigdata/train.csv')\r\n",
        "\r\n",
        "df['x_min'] = np.where(df['x_min'].isnull(), 0, df['x_min'])\r\n",
        "df['x_max'] = np.where(df['x_max'].isnull(), 1, df['x_max'])\r\n",
        "df['y_min'] = np.where(df['y_min'].isnull(), 0, df['y_min'])\r\n",
        "df['y_max'] = np.where(df['y_max'].isnull(), 1, df['y_max'])\r\n",
        "\r\n",
        "if (not config['train_no_finding']):\r\n",
        "    df = df[df['class_name'] != 'No finding']\r\n",
        "    \r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_id</th>\n",
              "      <th>rad_id</th>\n",
              "      <th>x_min</th>\n",
              "      <th>y_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>y_max</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>3</td>\n",
              "      <td>R10</td>\n",
              "      <td>691.0</td>\n",
              "      <td>1375.0</td>\n",
              "      <td>1653.0</td>\n",
              "      <td>1831.0</td>\n",
              "      <td>2080</td>\n",
              "      <td>2336</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>051132a778e61a86eb147c7c6f564dfe</td>\n",
              "      <td>Aortic enlargement</td>\n",
              "      <td>0</td>\n",
              "      <td>R10</td>\n",
              "      <td>1264.0</td>\n",
              "      <td>743.0</td>\n",
              "      <td>1611.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>2304</td>\n",
              "      <td>2880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1c32170b4af4ce1a3030eb8167753b06</td>\n",
              "      <td>Pleural thickening</td>\n",
              "      <td>11</td>\n",
              "      <td>R9</td>\n",
              "      <td>627.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>947.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>2540</td>\n",
              "      <td>3072</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0c7a38f293d5f5e4846aa4ca6db4daf1</td>\n",
              "      <td>ILD</td>\n",
              "      <td>5</td>\n",
              "      <td>R17</td>\n",
              "      <td>1347.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>2188.0</td>\n",
              "      <td>2169.0</td>\n",
              "      <td>2285</td>\n",
              "      <td>2555</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>47ed17dcb2cbeec15182ed335a8b5a9e</td>\n",
              "      <td>Nodule/Mass</td>\n",
              "      <td>8</td>\n",
              "      <td>R9</td>\n",
              "      <td>557.0</td>\n",
              "      <td>2352.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>2484.0</td>\n",
              "      <td>2568</td>\n",
              "      <td>3353</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           image_id          class_name  ...  height fold\n",
              "2  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly  ...    2336    2\n",
              "3  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement  ...    2880    0\n",
              "5  1c32170b4af4ce1a3030eb8167753b06  Pleural thickening  ...    3072    1\n",
              "6  0c7a38f293d5f5e4846aa4ca6db4daf1                 ILD  ...    2555    3\n",
              "7  47ed17dcb2cbeec15182ed335a8b5a9e         Nodule/Mass  ...    3353    1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-oZ9V1SZ5yV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2aba1b-e898-44e4-d154-fb033908eb40"
      },
      "source": [
        "image_ids = df['image_id'].unique()\r\n",
        "train_ids = df['image_id'][df['fold'] != config['fold']].unique()\r\n",
        "valid_ids = df['image_id'][df['fold'] == config['fold']].unique()\r\n",
        "print(len(train_ids), len(valid_ids))\r\n",
        "valid_df = df[df['image_id'].isin(valid_ids)]\r\n",
        "train_df = df[df['image_id'].isin(train_ids)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3516 878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQaZ0d4ClHgh"
      },
      "source": [
        "if not os.path.exists(config['image_paths']):\r\n",
        "    !gdown --id 1y4wV9T_ITyG8hz5OE3cUhtVqEP14cEx4\r\n",
        "    !kaggle datasets download -d awsaf49/vinbigdata-original-image-dataset\r\n",
        "    os.makedirs(config['image_paths'])\r\n",
        "    with zipfile.ZipFile('vinbigdata-original-image-dataset.zip') as z:\r\n",
        "        for filename in tqdm(image_ids):\r\n",
        "            with open(config['image_paths']+filename+'.jpg', 'wb+') as f:\r\n",
        "                f.write(z.read('vinbigdata/train/'+filename+'.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vf2cnQ7lDQ2"
      },
      "source": [
        "def get_train_dicts(df):\r\n",
        "    dataset_dicts = []\r\n",
        "    for index, image_id in enumerate(tqdm(df[\"image_id\"].unique())):\r\n",
        "        record = {}\r\n",
        "        data = df[df['image_id'] == image_id]\r\n",
        "        record[\"image_id\"] = image_id\r\n",
        "        record[\"file_name\"] = config['image_paths'] + image_id + \".jpg\"\r\n",
        "        record[\"height\"] = data['height'].values[0] \r\n",
        "        record[\"width\"] = data['width'].values[0]\r\n",
        "\r\n",
        "        record[\"annotations\"] = [{\"bbox\": [data['x_min'].values[i], data['y_min'].values[i], data['x_max'].values[i], data['y_max'].values[i]],\r\n",
        "                                  \"bbox_mode\": BoxMode.XYXY_ABS,\r\n",
        "                                  \"category_id\": data['class_id'].values[i]}\r\n",
        "                                 \r\n",
        "                                  for i in range(len(data))]\r\n",
        "\r\n",
        "        dataset_dicts.append(record)\r\n",
        "\r\n",
        "    return dataset_dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Ilxxnna6BN"
      },
      "source": [
        "def get_train_transforms():\r\n",
        "    return A.Compose(\r\n",
        "        [\r\n",
        "         A.OneOf([\r\n",
        "            A.MotionBlur(p=0.2),\r\n",
        "            A.GaussianBlur(),\r\n",
        "            A.MedianBlur(blur_limit=3, p=0.3),\r\n",
        "            A.Blur(blur_limit=3, p=0.1)\r\n",
        "         ], p=0.3),\r\n",
        "         \r\n",
        "         A.OneOf([\r\n",
        "            A.HorizontalFlip(p=1.0),\r\n",
        "            A.VerticalFlip(p=1.0),\r\n",
        "            A.RandomRotate90(p=1.0),\r\n",
        "            A.Transpose(p=0.5),\r\n",
        "         ], p=0.5),\r\n",
        "\r\n",
        "         A.OneOf([\r\n",
        "            A.HueSaturationValue(hue_shift_limit=0.1, sat_shift_limit= 0.1, val_shift_limit=0.1, p=0.01),\r\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),            \r\n",
        "         ], p=0.5),\r\n",
        "         \r\n",
        "         A.OneOf([ \r\n",
        "            A.Cutout(num_holes=1, max_h_size=4, max_w_size=4, fill_value=0, p=1.0),\r\n",
        "            A.Cutout(num_holes=2, max_h_size=2, max_w_size=2, fill_value=0, p=1.0),\r\n",
        "         ], p = 0.01),\r\n",
        "\r\n",
        "         A.JpegCompression(quality_lower=80, quality_upper=95, p=0.02),\r\n",
        "         A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\r\n",
        "\r\n",
        "         A.Resize(height = config['imgSize'], width = config['imgSize'])\r\n",
        "        ],\r\n",
        "        p=1.0, \r\n",
        "        bbox_params=A.BboxParams(\r\n",
        "            format='pascal_voc',\r\n",
        "            min_area=0, \r\n",
        "            min_visibility=0,\r\n",
        "            label_fields=['category_ids']\r\n",
        "        )\r\n",
        "    )\r\n",
        "\r\n",
        "def get_valid_transforms():\r\n",
        "    return A.Compose(\r\n",
        "        [\r\n",
        "         A.Resize(height = config['imgSize'], width = config['imgSize'])\r\n",
        "        ], \r\n",
        "        p=1.0, \r\n",
        "        bbox_params=A.BboxParams(\r\n",
        "            format='pascal_voc',\r\n",
        "            min_area=0, \r\n",
        "            min_visibility=0,\r\n",
        "            label_fields=['category_ids']\r\n",
        "        )\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "class AlbumentationsMapper:\r\n",
        "    \"\"\"Mapper which uses `albumentations` augmentations\"\"\"\r\n",
        "    def __init__(self, cfg, is_train: bool = True):\r\n",
        "        self.is_train = is_train\r\n",
        "        if self.is_train:\r\n",
        "            self.transform = get_train_transforms()\r\n",
        "        else:\r\n",
        "            self.transform = get_valid_transforms()\r\n",
        "\r\n",
        "    def __call__(self, dataset_dict):\r\n",
        "        dataset_dict = copy.deepcopy(dataset_dict)\r\n",
        "        image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\r\n",
        "\r\n",
        "        prev_anno = dataset_dict[\"annotations\"]\r\n",
        "        bboxes = np.array([obj[\"bbox\"] for obj in prev_anno], dtype=np.float32)\r\n",
        "        category_id = np.arange(len(dataset_dict[\"annotations\"]))\r\n",
        "\r\n",
        "        transformed = self.transform(image=image, bboxes=bboxes, category_ids=category_id)\r\n",
        "        image = transformed[\"image\"]\r\n",
        "        annos = []\r\n",
        "        for i, j in enumerate(transformed[\"category_ids\"]):\r\n",
        "            d = prev_anno[j]\r\n",
        "            d[\"bbox\"] = transformed[\"bboxes\"][i]\r\n",
        "            annos.append(d)\r\n",
        "        dataset_dict.pop(\"annotations\", None)\r\n",
        "\r\n",
        "        image_shape = image.shape[:2]\r\n",
        "        dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\r\n",
        "        instances = utils.annotations_to_instances(annos, image_shape)\r\n",
        "        dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\r\n",
        "        return dataset_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24VXyD6ebSbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c69f1f-dfaf-4076-918d-eae8cd3a88bc"
      },
      "source": [
        "thing_classes = [\r\n",
        "    \"Aortic enlargement\",\r\n",
        "    \"Atelectasis\",\r\n",
        "    \"Calcification\",\r\n",
        "    \"Cardiomegaly\",\r\n",
        "    \"Consolidation\",\r\n",
        "    \"ILD\",\r\n",
        "    \"Infiltration\",\r\n",
        "    \"Lung Opacity\",\r\n",
        "    \"Nodule/Mass\",\r\n",
        "    \"Other lesion\",\r\n",
        "    \"Pleural effusion\",\r\n",
        "    \"Pleural thickening\",\r\n",
        "    \"Pneumothorax\",\r\n",
        "    \"Pulmonary fibrosis\"\r\n",
        "]\r\n",
        "\r\n",
        "DatasetCatalog.register(\"vinbigdata_train\",lambda:get_train_dicts(train_df))\r\n",
        "MetadataCatalog.get(\"vinbigdata_train\").set(thing_classes=thing_classes)\r\n",
        "\r\n",
        "DatasetCatalog.register(\"vinbigdata_valid\",lambda:get_train_dicts(valid_df))\r\n",
        "MetadataCatalog.get(\"vinbigdata_valid\").set(thing_classes=thing_classes,evaluator_type=\"coco\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(evaluator_type='coco', name='vinbigdata_valid', thing_classes=['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-HkGekwCOwV"
      },
      "source": [
        "cfg = get_cfg()\r\n",
        "os.makedirs(config['save_dir'], exist_ok=True)\r\n",
        "cfg.merge_from_file(model_zoo.get_config_file(config['yaml']))\r\n",
        "cfg.MODEL.WEIGHTS = config['WEIGHT'] if (config['WEIGHT']) else model_zoo.get_checkpoint_url(config['yaml'])\r\n",
        "\r\n",
        "cfg.DATASETS.TRAIN = (\"vinbigdata_train\",)\r\n",
        "cfg.DATASETS.TEST = (\"vinbigdata_valid\",)\r\n",
        "cfg.DATALOADER.NUM_WORKERS = multiprocessing.cpu_count()\r\n",
        "cfg.OUTPUT_DIR = config['save_dir']\r\n",
        "\r\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\" # \"WarmupCosineLR\"\r\n",
        "cfg.SOLVER.BASE_LR = config['lr']\r\n",
        "\r\n",
        "cfg.SOLVER.MAX_ITER = (config['epochs']*len(train_ids))//config['batch_size']\r\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = len(train_ids)//config['batch_size']\r\n",
        "cfg.TEST.EVAL_PERIOD = len(train_ids)//config['batch_size']\r\n",
        "\r\n",
        "cfg.SOLVER.IMS_PER_BATCH = config['batch_size']\r\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\r\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\r\n",
        "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcVd20CHhq5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab4be6f-563e-44ac-e9ce-458c6c15ceb9"
      },
      "source": [
        "\"\"\"\r\n",
        "Original code from https://github.com/cocodataset/cocoapi/blob/8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9/PythonAPI/pycocotools/cocoeval.py\r\n",
        "Just modified to show AP@40\r\n",
        "\"\"\"\r\n",
        "# Copyright (c) Facebook, Inc. and its affiliates.\r\n",
        "import contextlib\r\n",
        "import copy\r\n",
        "import io\r\n",
        "import itertools\r\n",
        "import json\r\n",
        "import logging\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "from collections import OrderedDict\r\n",
        "import pycocotools.mask as mask_util\r\n",
        "import torch\r\n",
        "from pycocotools.coco import COCO\r\n",
        "from pycocotools.cocoeval import COCOeval\r\n",
        "from tabulate import tabulate\r\n",
        "\r\n",
        "import detectron2.utils.comm as comm\r\n",
        "from detectron2.config import CfgNode\r\n",
        "from detectron2.data import MetadataCatalog\r\n",
        "from detectron2.data.datasets.coco import convert_to_coco_json\r\n",
        "from detectron2.evaluation.evaluator import DatasetEvaluator\r\n",
        "from detectron2.evaluation.fast_eval_api import COCOeval_opt\r\n",
        "from detectron2.structures import Boxes, BoxMode, pairwise_iou\r\n",
        "from detectron2.utils.file_io import PathManager\r\n",
        "from detectron2.utils.logger import create_small_table\r\n",
        "\r\n",
        "\r\n",
        "def vin_summarize(self):\r\n",
        "    '''\r\n",
        "    Compute and display summary metrics for evaluation results.\r\n",
        "    Note this functin can *only* be applied on the default parameter setting\r\n",
        "    '''\r\n",
        "\r\n",
        "    def _summarize(ap=1, iouThr=None, areaRng='all', maxDets=100):\r\n",
        "        p = self.params\r\n",
        "        iStr = ' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'\r\n",
        "        titleStr = 'Average Precision' if ap == 1 else 'Average Recall'\r\n",
        "        typeStr = '(AP)' if ap == 1 else '(AR)'\r\n",
        "        iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \\\r\n",
        "            if iouThr is None else '{:0.2f}'.format(iouThr)\r\n",
        "\r\n",
        "        aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]\r\n",
        "        mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]\r\n",
        "        if ap == 1:\r\n",
        "            # dimension of precision: [TxRxKxAxM]\r\n",
        "            s = self.eval['precision']\r\n",
        "            # IoU\r\n",
        "            if iouThr is not None:\r\n",
        "                t = np.where(iouThr == p.iouThrs)[0]\r\n",
        "                s = s[t]\r\n",
        "            s = s[:, :, :, aind, mind]\r\n",
        "        else:\r\n",
        "            # dimension of recall: [TxKxAxM]\r\n",
        "            s = self.eval['recall']\r\n",
        "            if iouThr is not None:\r\n",
        "                t = np.where(iouThr == p.iouThrs)[0]\r\n",
        "                s = s[t]\r\n",
        "            s = s[:, :, aind, mind]\r\n",
        "        if len(s[s > -1]) == 0:\r\n",
        "            mean_s = -1\r\n",
        "        else:\r\n",
        "            mean_s = np.mean(s[s > -1])\r\n",
        "        print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))\r\n",
        "        return mean_s\r\n",
        "\r\n",
        "    def _summarizeDets():\r\n",
        "        stats = np.zeros((12,))\r\n",
        "        stats[0] = _summarize(1)\r\n",
        "        stats[1] = _summarize(1, iouThr=.5, maxDets=self.params.maxDets[2])\r\n",
        "        # stats[2] = _summarize(1, iouThr=.75, maxDets=self.params.maxDets[2])\r\n",
        "        stats[2] = _summarize(1, iouThr=.4, maxDets=self.params.maxDets[2])\r\n",
        "        stats[3] = _summarize(1, areaRng='small', maxDets=self.params.maxDets[2])\r\n",
        "        stats[4] = _summarize(1, areaRng='medium', maxDets=self.params.maxDets[2])\r\n",
        "        stats[5] = _summarize(1, areaRng='large', maxDets=self.params.maxDets[2])\r\n",
        "        stats[6] = _summarize(0, maxDets=self.params.maxDets[0])\r\n",
        "        stats[7] = _summarize(0, maxDets=self.params.maxDets[1])\r\n",
        "        stats[8] = _summarize(0, maxDets=self.params.maxDets[2])\r\n",
        "        stats[9] = _summarize(0, areaRng='small', maxDets=self.params.maxDets[2])\r\n",
        "        stats[10] = _summarize(0, areaRng='medium', maxDets=self.params.maxDets[2])\r\n",
        "        stats[11] = _summarize(0, areaRng='large', maxDets=self.params.maxDets[2])\r\n",
        "        return stats\r\n",
        "\r\n",
        "    def _summarizeKps():\r\n",
        "        stats = np.zeros((10,))\r\n",
        "        stats[0] = _summarize(1, maxDets=20)\r\n",
        "        stats[1] = _summarize(1, maxDets=20, iouThr=.5)\r\n",
        "        stats[2] = _summarize(1, maxDets=20, iouThr=.75)\r\n",
        "        stats[3] = _summarize(1, maxDets=20, areaRng='medium')\r\n",
        "        stats[4] = _summarize(1, maxDets=20, areaRng='large')\r\n",
        "        stats[5] = _summarize(0, maxDets=20)\r\n",
        "        stats[6] = _summarize(0, maxDets=20, iouThr=.5)\r\n",
        "        stats[7] = _summarize(0, maxDets=20, iouThr=.75)\r\n",
        "        stats[8] = _summarize(0, maxDets=20, areaRng='medium')\r\n",
        "        stats[9] = _summarize(0, maxDets=20, areaRng='large')\r\n",
        "        return stats\r\n",
        "\r\n",
        "    if not self.eval:\r\n",
        "        raise Exception('Please run accumulate() first')\r\n",
        "    iouType = self.params.iouType\r\n",
        "    if iouType == 'segm' or iouType == 'bbox':\r\n",
        "        summarize = _summarizeDets\r\n",
        "    elif iouType == 'keypoints':\r\n",
        "        summarize = _summarizeKps\r\n",
        "    self.stats = summarize()\r\n",
        "\r\n",
        "\r\n",
        "print(\"HACKING: overriding COCOeval.summarize = vin_summarize...\")\r\n",
        "COCOeval.summarize = vin_summarize\r\n",
        "\r\n",
        "\r\n",
        "class VinbigdataEvaluator(DatasetEvaluator):\r\n",
        "    \"\"\"\r\n",
        "    Evaluate AR for object proposals, AP for instance detection/segmentation, AP\r\n",
        "    for keypoint detection outputs using COCO's metrics.\r\n",
        "    See http://cocodataset.org/#detection-eval and\r\n",
        "    http://cocodataset.org/#keypoints-eval to understand its metrics.\r\n",
        "\r\n",
        "    In addition to COCO, this evaluator is able to support any bounding box detection,\r\n",
        "    instance segmentation, or keypoint detection dataset.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        dataset_name,\r\n",
        "        tasks=None,\r\n",
        "        distributed=True,\r\n",
        "        output_dir=None,\r\n",
        "        *,\r\n",
        "        use_fast_impl=True,\r\n",
        "        kpt_oks_sigmas=(),\r\n",
        "    ):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            dataset_name (str): name of the dataset to be evaluated.\r\n",
        "                It must have either the following corresponding metadata:\r\n",
        "\r\n",
        "                    \"json_file\": the path to the COCO format annotation\r\n",
        "\r\n",
        "                Or it must be in detectron2's standard dataset format\r\n",
        "                so it can be converted to COCO format automatically.\r\n",
        "            tasks (tuple[str]): tasks that can be evaluated under the given\r\n",
        "                configuration. A task is one of \"bbox\", \"segm\", \"keypoints\".\r\n",
        "                By default, will infer this automatically from predictions.\r\n",
        "            distributed (True): if True, will collect results from all ranks and run evaluation\r\n",
        "                in the main process.\r\n",
        "                Otherwise, will only evaluate the results in the current process.\r\n",
        "            output_dir (str): optional, an output directory to dump all\r\n",
        "                results predicted on the dataset. The dump contains two files:\r\n",
        "\r\n",
        "                1. \"instances_predictions.pth\" a file in torch serialization\r\n",
        "                   format that contains all the raw original predictions.\r\n",
        "                2. \"coco_instances_results.json\" a json file in COCO's result\r\n",
        "                   format.\r\n",
        "            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.\r\n",
        "                Although the results should be very close to the official implementation in COCO\r\n",
        "                API, it is still recommended to compute results with the official API for use in\r\n",
        "                papers. The faster implementation also uses more RAM.\r\n",
        "            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.\r\n",
        "                See http://cocodataset.org/#keypoints-eval\r\n",
        "                When empty, it will use the defaults in COCO.\r\n",
        "                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.\r\n",
        "        \"\"\"\r\n",
        "        self._logger = logging.getLogger(__name__)\r\n",
        "        self._distributed = distributed\r\n",
        "        self._output_dir = output_dir\r\n",
        "        self._use_fast_impl = use_fast_impl\r\n",
        "\r\n",
        "        if tasks is not None and isinstance(tasks, CfgNode):\r\n",
        "            kpt_oks_sigmas = (\r\n",
        "                tasks.TEST.KEYPOINT_OKS_SIGMAS if not kpt_oks_sigmas else kpt_oks_sigmas\r\n",
        "            )\r\n",
        "            self._logger.warn(\r\n",
        "                \"COCO Evaluator instantiated using config, this is deprecated behavior.\"\r\n",
        "                \" Please pass in explicit arguments instead.\"\r\n",
        "            )\r\n",
        "            self._tasks = None  # Infering it from predictions should be better\r\n",
        "        else:\r\n",
        "            self._tasks = tasks\r\n",
        "\r\n",
        "        self._cpu_device = torch.device(\"cpu\")\r\n",
        "\r\n",
        "        self._metadata = MetadataCatalog.get(dataset_name)\r\n",
        "        if not hasattr(self._metadata, \"json_file\"):\r\n",
        "            self._logger.info(\r\n",
        "                f\"'{dataset_name}' is not registered by `register_coco_instances`.\"\r\n",
        "                \" Therefore trying to convert it to COCO format ...\"\r\n",
        "            )\r\n",
        "\r\n",
        "            cache_path = os.path.join(output_dir, f\"{dataset_name}_coco_format.json\")\r\n",
        "            self._metadata.json_file = cache_path\r\n",
        "            convert_to_coco_json(dataset_name, cache_path)\r\n",
        "\r\n",
        "        json_file = PathManager.get_local_path(self._metadata.json_file)\r\n",
        "        with contextlib.redirect_stdout(io.StringIO()):\r\n",
        "            self._coco_api = COCO(json_file)\r\n",
        "\r\n",
        "        # Test set json files do not contain annotations (evaluation must be\r\n",
        "        # performed using the COCO evaluation server).\r\n",
        "        self._do_evaluation = \"annotations\" in self._coco_api.dataset\r\n",
        "        if self._do_evaluation:\r\n",
        "            self._kpt_oks_sigmas = kpt_oks_sigmas\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self._predictions = []\r\n",
        "\r\n",
        "    def process(self, inputs, outputs):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\r\n",
        "                It is a list of dict. Each dict corresponds to an image and\r\n",
        "                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\r\n",
        "            outputs: the outputs of a COCO model. It is a list of dicts with key\r\n",
        "                \"instances\" that contains :class:`Instances`.\r\n",
        "        \"\"\"\r\n",
        "        for input, output in zip(inputs, outputs):\r\n",
        "            prediction = {\"image_id\": input[\"image_id\"]}\r\n",
        "\r\n",
        "            if \"instances\" in output:\r\n",
        "                instances = output[\"instances\"].to(self._cpu_device)\r\n",
        "                prediction[\"instances\"] = instances_to_coco_json(instances, input[\"image_id\"])\r\n",
        "            if \"proposals\" in output:\r\n",
        "                prediction[\"proposals\"] = output[\"proposals\"].to(self._cpu_device)\r\n",
        "            if len(prediction) > 1:\r\n",
        "                self._predictions.append(prediction)\r\n",
        "\r\n",
        "    def evaluate(self, img_ids=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset\r\n",
        "        \"\"\"\r\n",
        "        if self._distributed:\r\n",
        "            comm.synchronize()\r\n",
        "            predictions = comm.gather(self._predictions, dst=0)\r\n",
        "            predictions = list(itertools.chain(*predictions))\r\n",
        "\r\n",
        "            if not comm.is_main_process():\r\n",
        "                return {}\r\n",
        "        else:\r\n",
        "            predictions = self._predictions\r\n",
        "\r\n",
        "        if len(predictions) == 0:\r\n",
        "            self._logger.warning(\"[VinbigdataEvaluator] Did not receive valid predictions.\")\r\n",
        "            return {}\r\n",
        "\r\n",
        "        if self._output_dir:\r\n",
        "            PathManager.mkdirs(self._output_dir)\r\n",
        "            file_path = os.path.join(self._output_dir, \"instances_predictions.pth\")\r\n",
        "            with PathManager.open(file_path, \"wb\") as f:\r\n",
        "                torch.save(predictions, f)\r\n",
        "\r\n",
        "        self._results = OrderedDict()\r\n",
        "        if \"proposals\" in predictions[0]:\r\n",
        "            self._eval_box_proposals(predictions)\r\n",
        "        if \"instances\" in predictions[0]:\r\n",
        "            self._eval_predictions(predictions, img_ids=img_ids)\r\n",
        "        # Copy so the caller can do whatever with results\r\n",
        "        return copy.deepcopy(self._results)\r\n",
        "\r\n",
        "    def _tasks_from_predictions(self, predictions):\r\n",
        "        \"\"\"\r\n",
        "        Get COCO API \"tasks\" (i.e. iou_type) from COCO-format predictions.\r\n",
        "        \"\"\"\r\n",
        "        tasks = {\"bbox\"}\r\n",
        "        for pred in predictions:\r\n",
        "            if \"segmentation\" in pred:\r\n",
        "                tasks.add(\"segm\")\r\n",
        "            if \"keypoints\" in pred:\r\n",
        "                tasks.add(\"keypoints\")\r\n",
        "        return sorted(tasks)\r\n",
        "\r\n",
        "    def _eval_predictions(self, predictions, img_ids=None):\r\n",
        "        \"\"\"\r\n",
        "        Evaluate predictions. Fill self._results with the metrics of the tasks.\r\n",
        "        \"\"\"\r\n",
        "        self._logger.info(\"Preparing results for COCO format ...\")\r\n",
        "        coco_results = list(itertools.chain(*[x[\"instances\"] for x in predictions]))\r\n",
        "        tasks = self._tasks or self._tasks_from_predictions(coco_results)\r\n",
        "\r\n",
        "        # unmap the category ids for COCO\r\n",
        "        if hasattr(self._metadata, \"thing_dataset_id_to_contiguous_id\"):\r\n",
        "            dataset_id_to_contiguous_id = self._metadata.thing_dataset_id_to_contiguous_id\r\n",
        "            all_contiguous_ids = list(dataset_id_to_contiguous_id.values())\r\n",
        "            num_classes = len(all_contiguous_ids)\r\n",
        "            assert min(all_contiguous_ids) == 0 and max(all_contiguous_ids) == num_classes - 1\r\n",
        "\r\n",
        "            reverse_id_mapping = {v: k for k, v in dataset_id_to_contiguous_id.items()}\r\n",
        "            for result in coco_results:\r\n",
        "                category_id = result[\"category_id\"]\r\n",
        "                assert category_id < num_classes, (\r\n",
        "                    f\"A prediction has class={category_id}, \"\r\n",
        "                    f\"but the dataset only has {num_classes} classes and \"\r\n",
        "                    f\"predicted class id should be in [0, {num_classes - 1}].\"\r\n",
        "                )\r\n",
        "                result[\"category_id\"] = reverse_id_mapping[category_id]\r\n",
        "\r\n",
        "        if self._output_dir:\r\n",
        "            file_path = os.path.join(self._output_dir, \"coco_instances_results.json\")\r\n",
        "            self._logger.info(\"Saving results to {}\".format(file_path))\r\n",
        "            with PathManager.open(file_path, \"w\") as f:\r\n",
        "                f.write(json.dumps(coco_results))\r\n",
        "                f.flush()\r\n",
        "\r\n",
        "        if not self._do_evaluation:\r\n",
        "            self._logger.info(\"Annotations are not available for evaluation.\")\r\n",
        "            return\r\n",
        "\r\n",
        "        self._logger.info(\r\n",
        "            \"Evaluating predictions with {} COCO API...\".format(\r\n",
        "                \"unofficial\" if self._use_fast_impl else \"official\"\r\n",
        "            )\r\n",
        "        )\r\n",
        "        for task in sorted(tasks):\r\n",
        "            coco_eval = (\r\n",
        "                _evaluate_predictions_on_coco(\r\n",
        "                    self._coco_api,\r\n",
        "                    coco_results,\r\n",
        "                    task,\r\n",
        "                    kpt_oks_sigmas=self._kpt_oks_sigmas,\r\n",
        "                    use_fast_impl=self._use_fast_impl,\r\n",
        "                    img_ids=img_ids,\r\n",
        "                )\r\n",
        "                if len(coco_results) > 0\r\n",
        "                else None  # cocoapi does not handle empty results very well\r\n",
        "            )\r\n",
        "\r\n",
        "            res = self._derive_coco_results(\r\n",
        "                coco_eval, task, class_names=self._metadata.get(\"thing_classes\")\r\n",
        "            )\r\n",
        "            self._results[task] = res\r\n",
        "\r\n",
        "    def _eval_box_proposals(self, predictions):\r\n",
        "        \"\"\"\r\n",
        "        Evaluate the box proposals in predictions.\r\n",
        "        Fill self._results with the metrics for \"box_proposals\" task.\r\n",
        "        \"\"\"\r\n",
        "        if self._output_dir:\r\n",
        "            # Saving generated box proposals to file.\r\n",
        "            # Predicted box_proposals are in XYXY_ABS mode.\r\n",
        "            bbox_mode = BoxMode.XYXY_ABS.value\r\n",
        "            ids, boxes, objectness_logits = [], [], []\r\n",
        "            for prediction in predictions:\r\n",
        "                ids.append(prediction[\"image_id\"])\r\n",
        "                boxes.append(prediction[\"proposals\"].proposal_boxes.tensor.numpy())\r\n",
        "                objectness_logits.append(prediction[\"proposals\"].objectness_logits.numpy())\r\n",
        "\r\n",
        "            proposal_data = {\r\n",
        "                \"boxes\": boxes,\r\n",
        "                \"objectness_logits\": objectness_logits,\r\n",
        "                \"ids\": ids,\r\n",
        "                \"bbox_mode\": bbox_mode,\r\n",
        "            }\r\n",
        "            with PathManager.open(os.path.join(self._output_dir, \"box_proposals.pkl\"), \"wb\") as f:\r\n",
        "                pickle.dump(proposal_data, f)\r\n",
        "\r\n",
        "        if not self._do_evaluation:\r\n",
        "            self._logger.info(\"Annotations are not available for evaluation.\")\r\n",
        "            return\r\n",
        "\r\n",
        "        self._logger.info(\"Evaluating bbox proposals ...\")\r\n",
        "        res = {}\r\n",
        "        areas = {\"all\": \"\", \"small\": \"s\", \"medium\": \"m\", \"large\": \"l\"}\r\n",
        "        for limit in [100, 1000]:\r\n",
        "            for area, suffix in areas.items():\r\n",
        "                stats = _evaluate_box_proposals(predictions, self._coco_api, area=area, limit=limit)\r\n",
        "                key = \"AR{}@{:d}\".format(suffix, limit)\r\n",
        "                res[key] = float(stats[\"ar\"].item() * 100)\r\n",
        "        self._logger.info(\"Proposal metrics: \\n\" + create_small_table(res))\r\n",
        "        self._results[\"box_proposals\"] = res\r\n",
        "\r\n",
        "    def _derive_coco_results(self, coco_eval, iou_type, class_names=None):\r\n",
        "        \"\"\"\r\n",
        "        Derive the desired score numbers from summarized COCOeval.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            coco_eval (None or COCOEval): None represents no predictions from model.\r\n",
        "            iou_type (str):\r\n",
        "            class_names (None or list[str]): if provided, will use it to predict\r\n",
        "                per-category AP.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            a dict of {metric name: score}\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        metrics = {\r\n",
        "            \"bbox\": [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"],\r\n",
        "            \"segm\": [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"],\r\n",
        "            \"keypoints\": [\"AP\", \"AP50\", \"AP75\", \"APm\", \"APl\"],\r\n",
        "        }[iou_type]\r\n",
        "\r\n",
        "        if coco_eval is None:\r\n",
        "            self._logger.warn(\"No predictions from the model!\")\r\n",
        "            return {metric: float(\"nan\") for metric in metrics}\r\n",
        "\r\n",
        "        # the standard metrics\r\n",
        "        results = {\r\n",
        "            metric: float(coco_eval.stats[idx] * 100 if coco_eval.stats[idx] >= 0 else \"nan\")\r\n",
        "            for idx, metric in enumerate(metrics)\r\n",
        "        }\r\n",
        "        self._logger.info(\r\n",
        "            \"Evaluation results for {}: \\n\".format(iou_type) + create_small_table(results)\r\n",
        "        )\r\n",
        "        if not np.isfinite(sum(results.values())):\r\n",
        "            self._logger.info(\"Some metrics cannot be computed and is shown as NaN.\")\r\n",
        "\r\n",
        "        if class_names is None or len(class_names) <= 1:\r\n",
        "            return results\r\n",
        "        # Compute per-category AP\r\n",
        "        # from https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L222-L252 # noqa\r\n",
        "        precisions = coco_eval.eval[\"precision\"]\r\n",
        "        # precision has dims (iou, recall, cls, area range, max dets)\r\n",
        "        assert len(class_names) == precisions.shape[2]\r\n",
        "\r\n",
        "        results_per_category = []\r\n",
        "        for idx, name in enumerate(class_names):\r\n",
        "            # area range index 0: all area ranges\r\n",
        "            # max dets index -1: typically 100 per image\r\n",
        "            precision = precisions[:, :, idx, 0, -1]\r\n",
        "            precision = precision[precision > -1]\r\n",
        "            ap = np.mean(precision) if precision.size else float(\"nan\")\r\n",
        "            results_per_category.append((\"{}\".format(name), float(ap * 100)))\r\n",
        "\r\n",
        "        # tabulate it\r\n",
        "        N_COLS = min(6, len(results_per_category) * 2)\r\n",
        "        results_flatten = list(itertools.chain(*results_per_category))\r\n",
        "        results_2d = itertools.zip_longest(*[results_flatten[i::N_COLS] for i in range(N_COLS)])\r\n",
        "        table = tabulate(\r\n",
        "            results_2d,\r\n",
        "            tablefmt=\"pipe\",\r\n",
        "            floatfmt=\".3f\",\r\n",
        "            headers=[\"category\", \"AP\"] * (N_COLS // 2),\r\n",
        "            numalign=\"left\",\r\n",
        "        )\r\n",
        "        self._logger.info(\"Per-category {} AP: \\n\".format(iou_type) + table)\r\n",
        "\r\n",
        "        results.update({\"AP-\" + name: ap for name, ap in results_per_category})\r\n",
        "        return results\r\n",
        "\r\n",
        "\r\n",
        "def instances_to_coco_json(instances, img_id):\r\n",
        "    \"\"\"\r\n",
        "    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        instances (Instances):\r\n",
        "        img_id (int): the image id\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        list[dict]: list of json annotations in COCO format.\r\n",
        "    \"\"\"\r\n",
        "    num_instance = len(instances)\r\n",
        "    if num_instance == 0:\r\n",
        "        return []\r\n",
        "\r\n",
        "    boxes = instances.pred_boxes.tensor.numpy()\r\n",
        "    boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\r\n",
        "    boxes = boxes.tolist()\r\n",
        "    scores = instances.scores.tolist()\r\n",
        "    classes = instances.pred_classes.tolist()\r\n",
        "\r\n",
        "    has_mask = instances.has(\"pred_masks\")\r\n",
        "    if has_mask:\r\n",
        "        # use RLE to encode the masks, because they are too large and takes memory\r\n",
        "        # since this evaluator stores outputs of the entire dataset\r\n",
        "        rles = [\r\n",
        "            mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\r\n",
        "            for mask in instances.pred_masks\r\n",
        "        ]\r\n",
        "        for rle in rles:\r\n",
        "            # \"counts\" is an array encoded by mask_util as a byte-stream. Python3's\r\n",
        "            # json writer which always produces strings cannot serialize a bytestream\r\n",
        "            # unless you decode it. Thankfully, utf-8 works out (which is also what\r\n",
        "            # the pycocotools/_mask.pyx does).\r\n",
        "            rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\r\n",
        "\r\n",
        "    has_keypoints = instances.has(\"pred_keypoints\")\r\n",
        "    if has_keypoints:\r\n",
        "        keypoints = instances.pred_keypoints\r\n",
        "\r\n",
        "    results = []\r\n",
        "    for k in range(num_instance):\r\n",
        "        result = {\r\n",
        "            \"image_id\": img_id,\r\n",
        "            \"category_id\": classes[k],\r\n",
        "            \"bbox\": boxes[k],\r\n",
        "            \"score\": scores[k],\r\n",
        "        }\r\n",
        "        if has_mask:\r\n",
        "            result[\"segmentation\"] = rles[k]\r\n",
        "        if has_keypoints:\r\n",
        "            # In COCO annotations,\r\n",
        "            # keypoints coordinates are pixel indices.\r\n",
        "            # However our predictions are floating point coordinates.\r\n",
        "            # Therefore we subtract 0.5 to be consistent with the annotation format.\r\n",
        "            # This is the inverse of data loading logic in `datasets/coco.py`.\r\n",
        "            keypoints[k][:, :2] -= 0.5\r\n",
        "            result[\"keypoints\"] = keypoints[k].flatten().tolist()\r\n",
        "        results.append(result)\r\n",
        "    return results\r\n",
        "\r\n",
        "\r\n",
        "# inspired from Detectron:\r\n",
        "# https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L255 # noqa\r\n",
        "def _evaluate_box_proposals(dataset_predictions, coco_api, thresholds=None, area=\"all\", limit=None):\r\n",
        "    \"\"\"\r\n",
        "    Evaluate detection proposal recall metrics. This function is a much\r\n",
        "    faster alternative to the official COCO API recall evaluation code. However,\r\n",
        "    it produces slightly different results.\r\n",
        "    \"\"\"\r\n",
        "    # Record max overlap value for each gt box\r\n",
        "    # Return vector of overlap values\r\n",
        "    areas = {\r\n",
        "        \"all\": 0,\r\n",
        "        \"small\": 1,\r\n",
        "        \"medium\": 2,\r\n",
        "        \"large\": 3,\r\n",
        "        \"96-128\": 4,\r\n",
        "        \"128-256\": 5,\r\n",
        "        \"256-512\": 6,\r\n",
        "        \"512-inf\": 7,\r\n",
        "    }\r\n",
        "    area_ranges = [\r\n",
        "        [0 ** 2, 1e5 ** 2],  # all\r\n",
        "        [0 ** 2, 32 ** 2],  # small\r\n",
        "        [32 ** 2, 96 ** 2],  # medium\r\n",
        "        [96 ** 2, 1e5 ** 2],  # large\r\n",
        "        [96 ** 2, 128 ** 2],  # 96-128\r\n",
        "        [128 ** 2, 256 ** 2],  # 128-256\r\n",
        "        [256 ** 2, 512 ** 2],  # 256-512\r\n",
        "        [512 ** 2, 1e5 ** 2],\r\n",
        "    ]  # 512-inf\r\n",
        "    assert area in areas, \"Unknown area range: {}\".format(area)\r\n",
        "    area_range = area_ranges[areas[area]]\r\n",
        "    gt_overlaps = []\r\n",
        "    num_pos = 0\r\n",
        "\r\n",
        "    for prediction_dict in dataset_predictions:\r\n",
        "        predictions = prediction_dict[\"proposals\"]\r\n",
        "\r\n",
        "        # sort predictions in descending order\r\n",
        "        # TODO maybe remove this and make it explicit in the documentation\r\n",
        "        inds = predictions.objectness_logits.sort(descending=True)[1]\r\n",
        "        predictions = predictions[inds]\r\n",
        "\r\n",
        "        ann_ids = coco_api.getAnnIds(imgIds=prediction_dict[\"image_id\"])\r\n",
        "        anno = coco_api.loadAnns(ann_ids)\r\n",
        "        gt_boxes = [\r\n",
        "            BoxMode.convert(obj[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\r\n",
        "            for obj in anno\r\n",
        "            if obj[\"iscrowd\"] == 0\r\n",
        "        ]\r\n",
        "        gt_boxes = torch.as_tensor(gt_boxes).reshape(-1, 4)  # guard against no boxes\r\n",
        "        gt_boxes = Boxes(gt_boxes)\r\n",
        "        gt_areas = torch.as_tensor([obj[\"area\"] for obj in anno if obj[\"iscrowd\"] == 0])\r\n",
        "\r\n",
        "        if len(gt_boxes) == 0 or len(predictions) == 0:\r\n",
        "            continue\r\n",
        "\r\n",
        "        valid_gt_inds = (gt_areas >= area_range[0]) & (gt_areas <= area_range[1])\r\n",
        "        gt_boxes = gt_boxes[valid_gt_inds]\r\n",
        "\r\n",
        "        num_pos += len(gt_boxes)\r\n",
        "\r\n",
        "        if len(gt_boxes) == 0:\r\n",
        "            continue\r\n",
        "\r\n",
        "        if limit is not None and len(predictions) > limit:\r\n",
        "            predictions = predictions[:limit]\r\n",
        "\r\n",
        "        overlaps = pairwise_iou(predictions.proposal_boxes, gt_boxes)\r\n",
        "\r\n",
        "        _gt_overlaps = torch.zeros(len(gt_boxes))\r\n",
        "        for j in range(min(len(predictions), len(gt_boxes))):\r\n",
        "            # find which proposal box maximally covers each gt box\r\n",
        "            # and get the iou amount of coverage for each gt box\r\n",
        "            max_overlaps, argmax_overlaps = overlaps.max(dim=0)\r\n",
        "\r\n",
        "            # find which gt box is 'best' covered (i.e. 'best' = most iou)\r\n",
        "            gt_ovr, gt_ind = max_overlaps.max(dim=0)\r\n",
        "            assert gt_ovr >= 0\r\n",
        "            # find the proposal box that covers the best covered gt box\r\n",
        "            box_ind = argmax_overlaps[gt_ind]\r\n",
        "            # record the iou coverage of this gt box\r\n",
        "            _gt_overlaps[j] = overlaps[box_ind, gt_ind]\r\n",
        "            assert _gt_overlaps[j] == gt_ovr\r\n",
        "            # mark the proposal box and the gt box as used\r\n",
        "            overlaps[box_ind, :] = -1\r\n",
        "            overlaps[:, gt_ind] = -1\r\n",
        "\r\n",
        "        # append recorded iou coverage level\r\n",
        "        gt_overlaps.append(_gt_overlaps)\r\n",
        "    gt_overlaps = (\r\n",
        "        torch.cat(gt_overlaps, dim=0) if len(gt_overlaps) else torch.zeros(0, dtype=torch.float32)\r\n",
        "    )\r\n",
        "    gt_overlaps, _ = torch.sort(gt_overlaps)\r\n",
        "\r\n",
        "    if thresholds is None:\r\n",
        "        step = 0.05\r\n",
        "        # thresholds = torch.arange(0.5, 0.95 + 1e-5, step, dtype=torch.float32)\r\n",
        "        thresholds = torch.arange(0.4, 0.95 + 1e-5, step, dtype=torch.float32)\r\n",
        "    recalls = torch.zeros_like(thresholds)\r\n",
        "    # compute recall for each iou threshold\r\n",
        "    for i, t in enumerate(thresholds):\r\n",
        "        recalls[i] = (gt_overlaps >= t).float().sum() / float(num_pos)\r\n",
        "    # ar = 2 * np.trapz(recalls, thresholds)\r\n",
        "    ar = recalls.mean()\r\n",
        "    return {\r\n",
        "        \"ar\": ar,\r\n",
        "        \"recalls\": recalls,\r\n",
        "        \"thresholds\": thresholds,\r\n",
        "        \"gt_overlaps\": gt_overlaps,\r\n",
        "        \"num_pos\": num_pos,\r\n",
        "    }\r\n",
        "\r\n",
        "\r\n",
        "def _evaluate_predictions_on_coco(\r\n",
        "    coco_gt, coco_results, iou_type, kpt_oks_sigmas=None, use_fast_impl=True, img_ids=None\r\n",
        "):\r\n",
        "    \"\"\"\r\n",
        "    Evaluate the coco results using COCOEval API.\r\n",
        "    \"\"\"\r\n",
        "    assert len(coco_results) > 0\r\n",
        "\r\n",
        "    if iou_type == \"segm\":\r\n",
        "        coco_results = copy.deepcopy(coco_results)\r\n",
        "        # When evaluating mask AP, if the results contain bbox, cocoapi will\r\n",
        "        # use the box area as the area of the instance, instead of the mask area.\r\n",
        "        # This leads to a different definition of small/medium/large.\r\n",
        "        # We remove the bbox field to let mask AP use mask area.\r\n",
        "        for c in coco_results:\r\n",
        "            c.pop(\"bbox\", None)\r\n",
        "\r\n",
        "    coco_dt = coco_gt.loadRes(coco_results)\r\n",
        "    coco_eval = (COCOeval_opt if use_fast_impl else COCOeval)(coco_gt, coco_dt, iou_type)\r\n",
        "\r\n",
        "    # HACKING: overwrite iouThrs to calc ious 0.4\r\n",
        "    coco_eval.params.iouThrs = np.linspace(\r\n",
        "        .4, 0.95, int(np.round((0.95 - .4) / .05)) + 1, endpoint=True)\r\n",
        "\r\n",
        "    if img_ids is not None:\r\n",
        "        coco_eval.params.imgIds = img_ids\r\n",
        "\r\n",
        "    if iou_type == \"keypoints\":\r\n",
        "        # Use the COCO default keypoint OKS sigmas unless overrides are specified\r\n",
        "        if kpt_oks_sigmas:\r\n",
        "            assert hasattr(coco_eval.params, \"kpt_oks_sigmas\"), \"pycocotools is too old!\"\r\n",
        "            coco_eval.params.kpt_oks_sigmas = np.array(kpt_oks_sigmas)\r\n",
        "        # COCOAPI requires every detection and every gt to have keypoints, so\r\n",
        "        # we just take the first entry from both\r\n",
        "        num_keypoints_dt = len(coco_results[0][\"keypoints\"]) // 3\r\n",
        "        num_keypoints_gt = len(next(iter(coco_gt.anns.values()))[\"keypoints\"]) // 3\r\n",
        "        num_keypoints_oks = len(coco_eval.params.kpt_oks_sigmas)\r\n",
        "        assert num_keypoints_oks == num_keypoints_dt == num_keypoints_gt, (\r\n",
        "            f\"[VinbigdataEvaluator] Prediction contain {num_keypoints_dt} keypoints. \"\r\n",
        "            f\"Ground truth contains {num_keypoints_gt} keypoints. \"\r\n",
        "            f\"The length of cfg.TEST.KEYPOINT_OKS_SIGMAS is {num_keypoints_oks}. \"\r\n",
        "            \"They have to agree with each other. For meaning of OKS, please refer to \"\r\n",
        "            \"http://cocodataset.org/#keypoints-eval.\"\r\n",
        "        )\r\n",
        "\r\n",
        "    coco_eval.evaluate()\r\n",
        "    coco_eval.accumulate()\r\n",
        "    coco_eval.summarize()\r\n",
        "\r\n",
        "    return coco_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HACKING: overriding COCOeval.summarize = vin_summarize...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xdZxMJoj_FI"
      },
      "source": [
        "class MyTrainer(DefaultTrainer):\r\n",
        "    @classmethod\r\n",
        "    def build_train_loader(cls, cfg, sampler=None):\r\n",
        "        return build_detection_train_loader(\r\n",
        "            cfg, mapper=AlbumentationsMapper(cfg, True), sampler=sampler\r\n",
        "        )\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def build_test_loader(cls, cfg, dataset_name):\r\n",
        "        return build_detection_test_loader(\r\n",
        "            cfg, dataset_name, mapper=AlbumentationsMapper(cfg, False)\r\n",
        "        )\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\r\n",
        "        if output_folder is None:\r\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\r\n",
        "        return VinbigdataEvaluator(dataset_name, (\"bbox\",), False, output_dir=output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AH5ToYgkBun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6bb481-7885-4a52-9a32-c58552180ac4"
      },
      "source": [
        "trainer = MyTrainer(cfg)\r\n",
        "trainer.resume_or_load(resume=False)\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:18:31 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=56, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3516/3516 [00:09<00:00, 363.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:18:41 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| Aortic enla.. | 5724         |  Atelectasis  | 213          | Calcification | 773          |\n",
            "| Cardiomegaly  | 4352         | Consolidation | 454          |      ILD      | 797          |\n",
            "| Infiltration  | 979          | Lung Opacity  | 1972         |  Nodule/Mass  | 2132         |\n",
            "| Other lesion  | 1770         | Pleural eff.. | 1984         | Pleural thi.. | 3885         |\n",
            "| Pneumothorax  | 187          | Pulmonary f.. | 3702         |               |              |\n",
            "|     total     | 28924        |               |              |               |              |\u001b[0m\n",
            "\u001b[32m[03/06 08:18:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[03/06 08:18:41 d2.data.common]: \u001b[0mSerializing 3516 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/06 08:18:42 d2.data.common]: \u001b[0mSerialized dataset takes 4.40 MiB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (56, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (56,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:18:43 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[03/06 08:19:10 d2.utils.events]: \u001b[0m eta: 23:56:24  iter: 19  total_loss: 3.229  loss_cls: 2.752  loss_box_reg: 0.0766  loss_rpn_cls: 0.2513  loss_rpn_loc: 0.07154  time: 1.3071  data_time: 0.0580  lr: 5.9943e-05  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:19:36 d2.utils.events]: \u001b[0m eta: 23:49:24  iter: 39  total_loss: 1.393  loss_cls: 0.6864  loss_box_reg: 0.08799  loss_rpn_cls: 0.1508  loss_rpn_loc: 0.1041  time: 1.2969  data_time: 0.0172  lr: 0.00011988  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:20:02 d2.utils.events]: \u001b[0m eta: 23:50:59  iter: 59  total_loss: 0.8802  loss_cls: 0.435  loss_box_reg: 0.1715  loss_rpn_cls: 0.08999  loss_rpn_loc: 0.08779  time: 1.2950  data_time: 0.0172  lr: 0.00017982  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:20:28 d2.utils.events]: \u001b[0m eta: 23:51:13  iter: 79  total_loss: 0.5929  loss_cls: 0.301  loss_box_reg: 0.1178  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.05972  time: 1.2938  data_time: 0.0171  lr: 0.00023976  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:20:53 d2.utils.events]: \u001b[0m eta: 23:47:09  iter: 99  total_loss: 0.5895  loss_cls: 0.3068  loss_box_reg: 0.1277  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.05721  time: 1.2911  data_time: 0.0184  lr: 0.0002997  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:21:19 d2.utils.events]: \u001b[0m eta: 23:47:41  iter: 119  total_loss: 0.695  loss_cls: 0.3901  loss_box_reg: 0.2199  loss_rpn_cls: 0.05868  loss_rpn_loc: 0.04469  time: 1.2929  data_time: 0.0183  lr: 0.00035964  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:21:45 d2.utils.events]: \u001b[0m eta: 23:48:50  iter: 139  total_loss: 0.6728  loss_cls: 0.3462  loss_box_reg: 0.1859  loss_rpn_cls: 0.05133  loss_rpn_loc: 0.05619  time: 1.2935  data_time: 0.0199  lr: 0.00041958  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:22:11 d2.utils.events]: \u001b[0m eta: 23:46:50  iter: 159  total_loss: 0.6442  loss_cls: 0.3044  loss_box_reg: 0.1494  loss_rpn_cls: 0.0937  loss_rpn_loc: 0.07356  time: 1.2931  data_time: 0.0170  lr: 0.00047952  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:22:37 d2.utils.events]: \u001b[0m eta: 23:47:03  iter: 179  total_loss: 0.5292  loss_cls: 0.2624  loss_box_reg: 0.154  loss_rpn_cls: 0.0533  loss_rpn_loc: 0.04506  time: 1.2928  data_time: 0.0175  lr: 0.00053946  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:23:03 d2.utils.events]: \u001b[0m eta: 23:45:58  iter: 199  total_loss: 0.5706  loss_cls: 0.2536  loss_box_reg: 0.1448  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.06401  time: 1.2921  data_time: 0.0196  lr: 0.0005994  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:23:29 d2.utils.events]: \u001b[0m eta: 23:46:15  iter: 219  total_loss: 0.5061  loss_cls: 0.2497  loss_box_reg: 0.1428  loss_rpn_cls: 0.06707  loss_rpn_loc: 0.04572  time: 1.2921  data_time: 0.0173  lr: 0.00065934  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:23:54 d2.utils.events]: \u001b[0m eta: 23:45:49  iter: 239  total_loss: 0.6685  loss_cls: 0.2872  loss_box_reg: 0.1679  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.07547  time: 1.2919  data_time: 0.0202  lr: 0.00071928  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:24:20 d2.utils.events]: \u001b[0m eta: 23:45:20  iter: 259  total_loss: 0.6157  loss_cls: 0.3038  loss_box_reg: 0.1839  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.0567  time: 1.2919  data_time: 0.0202  lr: 0.00077922  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:24:46 d2.utils.events]: \u001b[0m eta: 23:44:58  iter: 279  total_loss: 0.6391  loss_cls: 0.2538  loss_box_reg: 0.1702  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.05463  time: 1.2920  data_time: 0.0193  lr: 0.00083916  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:25:12 d2.utils.events]: \u001b[0m eta: 23:45:48  iter: 299  total_loss: 0.5063  loss_cls: 0.2364  loss_box_reg: 0.1539  loss_rpn_cls: 0.05314  loss_rpn_loc: 0.04772  time: 1.2928  data_time: 0.0189  lr: 0.0008991  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:25:38 d2.utils.events]: \u001b[0m eta: 23:45:35  iter: 319  total_loss: 0.5632  loss_cls: 0.2688  loss_box_reg: 0.1499  loss_rpn_cls: 0.06148  loss_rpn_loc: 0.04967  time: 1.2931  data_time: 0.0179  lr: 0.00095904  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:26:04 d2.utils.events]: \u001b[0m eta: 23:45:22  iter: 339  total_loss: 0.6384  loss_cls: 0.3036  loss_box_reg: 0.1759  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.07379  time: 1.2933  data_time: 0.0166  lr: 0.001019  max_mem: 11405M\n",
            "\u001b[32m[03/06 08:26:30 d2.utils.events]: \u001b[0m eta: 23:44:57  iter: 359  total_loss: 0.7146  loss_cls: 0.3464  loss_box_reg: 0.2012  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.07606  time: 1.2932  data_time: 0.0185  lr: 0.0010789  max_mem: 11484M\n",
            "\u001b[32m[03/06 08:26:56 d2.utils.events]: \u001b[0m eta: 23:44:38  iter: 379  total_loss: 0.7105  loss_cls: 0.3035  loss_box_reg: 0.2104  loss_rpn_cls: 0.08548  loss_rpn_loc: 0.06198  time: 1.2936  data_time: 0.0178  lr: 0.0011389  max_mem: 11484M\n",
            "\u001b[32m[03/06 08:27:22 d2.utils.events]: \u001b[0m eta: 23:43:52  iter: 399  total_loss: 0.743  loss_cls: 0.3386  loss_box_reg: 0.232  loss_rpn_cls: 0.06844  loss_rpn_loc: 0.07829  time: 1.2933  data_time: 0.0186  lr: 0.0011988  max_mem: 11484M\n",
            "\u001b[32m[03/06 08:27:47 d2.utils.events]: \u001b[0m eta: 23:43:27  iter: 419  total_loss: 0.7058  loss_cls: 0.3056  loss_box_reg: 0.2315  loss_rpn_cls: 0.03839  loss_rpn_loc: 0.1015  time: 1.2928  data_time: 0.0164  lr: 0.0012587  max_mem: 11484M\n",
            "\u001b[32m[03/06 08:28:14 d2.utils.events]: \u001b[0m eta: 23:43:21  iter: 439  total_loss: 0.618  loss_cls: 0.2442  loss_box_reg: 0.192  loss_rpn_cls: 0.05304  loss_rpn_loc: 0.05381  time: 1.2934  data_time: 0.0181  lr: 0.0013187  max_mem: 11484M\n",
            "\u001b[32m[03/06 08:28:39 d2.utils.events]: \u001b[0m eta: 23:42:48  iter: 459  total_loss: 0.4842  loss_cls: 0.2259  loss_box_reg: 0.2144  loss_rpn_cls: 0.03591  loss_rpn_loc: 0.04795  time: 1.2932  data_time: 0.0185  lr: 0.0013786  max_mem: 11484M\n",
            "\u001b[32m[03/06 08:29:05 d2.utils.events]: \u001b[0m eta: 23:42:10  iter: 479  total_loss: 0.6096  loss_cls: 0.3223  loss_box_reg: 0.2092  loss_rpn_cls: 0.06053  loss_rpn_loc: 0.06565  time: 1.2930  data_time: 0.0176  lr: 0.0014386  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:29:31 d2.utils.events]: \u001b[0m eta: 23:41:42  iter: 499  total_loss: 0.5886  loss_cls: 0.2322  loss_box_reg: 0.1749  loss_rpn_cls: 0.05729  loss_rpn_loc: 0.0584  time: 1.2928  data_time: 0.0179  lr: 0.0014985  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:29:57 d2.utils.events]: \u001b[0m eta: 23:41:16  iter: 519  total_loss: 0.623  loss_cls: 0.2898  loss_box_reg: 0.2  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.05175  time: 1.2927  data_time: 0.0163  lr: 0.0015584  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:30:23 d2.utils.events]: \u001b[0m eta: 23:40:52  iter: 539  total_loss: 0.4626  loss_cls: 0.1895  loss_box_reg: 0.1333  loss_rpn_cls: 0.03319  loss_rpn_loc: 0.03969  time: 1.2926  data_time: 0.0181  lr: 0.0016184  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:30:48 d2.utils.events]: \u001b[0m eta: 23:40:25  iter: 559  total_loss: 0.5723  loss_cls: 0.281  loss_box_reg: 0.2143  loss_rpn_cls: 0.03053  loss_rpn_loc: 0.05526  time: 1.2926  data_time: 0.0181  lr: 0.0016783  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:31:14 d2.utils.events]: \u001b[0m eta: 23:39:55  iter: 579  total_loss: 0.6427  loss_cls: 0.2867  loss_box_reg: 0.2065  loss_rpn_cls: 0.05217  loss_rpn_loc: 0.05826  time: 1.2923  data_time: 0.0171  lr: 0.0017383  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:31:40 d2.utils.events]: \u001b[0m eta: 23:39:29  iter: 599  total_loss: 0.5661  loss_cls: 0.249  loss_box_reg: 0.2314  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.04904  time: 1.2924  data_time: 0.0176  lr: 0.0017982  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:32:06 d2.utils.events]: \u001b[0m eta: 23:38:49  iter: 619  total_loss: 0.6514  loss_cls: 0.3  loss_box_reg: 0.2397  loss_rpn_cls: 0.05637  loss_rpn_loc: 0.06722  time: 1.2924  data_time: 0.0174  lr: 0.0018581  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:32:32 d2.utils.events]: \u001b[0m eta: 23:38:25  iter: 639  total_loss: 0.6188  loss_cls: 0.2727  loss_box_reg: 0.1994  loss_rpn_cls: 0.04685  loss_rpn_loc: 0.05484  time: 1.2927  data_time: 0.0188  lr: 0.0019181  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:32:58 d2.utils.events]: \u001b[0m eta: 23:37:59  iter: 659  total_loss: 0.7359  loss_cls: 0.3484  loss_box_reg: 0.2781  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.08087  time: 1.2927  data_time: 0.0171  lr: 0.001978  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:33:24 d2.utils.events]: \u001b[0m eta: 23:37:41  iter: 679  total_loss: 0.6442  loss_cls: 0.3079  loss_box_reg: 0.2161  loss_rpn_cls: 0.04621  loss_rpn_loc: 0.05893  time: 1.2929  data_time: 0.0182  lr: 0.002038  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:33:50 d2.utils.events]: \u001b[0m eta: 23:37:26  iter: 699  total_loss: 0.5898  loss_cls: 0.2734  loss_box_reg: 0.2275  loss_rpn_cls: 0.04849  loss_rpn_loc: 0.04421  time: 1.2931  data_time: 0.0179  lr: 0.0020979  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:34:16 d2.utils.events]: \u001b[0m eta: 23:37:14  iter: 719  total_loss: 0.6793  loss_cls: 0.3471  loss_box_reg: 0.24  loss_rpn_cls: 0.03532  loss_rpn_loc: 0.05754  time: 1.2933  data_time: 0.0172  lr: 0.0021578  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:34:42 d2.utils.events]: \u001b[0m eta: 23:36:39  iter: 739  total_loss: 0.6701  loss_cls: 0.2846  loss_box_reg: 0.2265  loss_rpn_cls: 0.04264  loss_rpn_loc: 0.05871  time: 1.2933  data_time: 0.0168  lr: 0.0022178  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:35:07 d2.utils.events]: \u001b[0m eta: 23:35:54  iter: 759  total_loss: 0.4974  loss_cls: 0.1946  loss_box_reg: 0.1973  loss_rpn_cls: 0.04019  loss_rpn_loc: 0.04892  time: 1.2928  data_time: 0.0180  lr: 0.0022777  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:35:33 d2.utils.events]: \u001b[0m eta: 23:35:23  iter: 779  total_loss: 0.5594  loss_cls: 0.2307  loss_box_reg: 0.1884  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.05581  time: 1.2926  data_time: 0.0182  lr: 0.0023377  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:35:59 d2.utils.events]: \u001b[0m eta: 23:35:07  iter: 799  total_loss: 0.6287  loss_cls: 0.2741  loss_box_reg: 0.2308  loss_rpn_cls: 0.05311  loss_rpn_loc: 0.05822  time: 1.2928  data_time: 0.0196  lr: 0.0023976  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:36:25 d2.utils.events]: \u001b[0m eta: 23:34:50  iter: 819  total_loss: 0.7  loss_cls: 0.2808  loss_box_reg: 0.2297  loss_rpn_cls: 0.04204  loss_rpn_loc: 0.06444  time: 1.2932  data_time: 0.0186  lr: 0.0024575  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:36:51 d2.utils.events]: \u001b[0m eta: 23:34:21  iter: 839  total_loss: 0.4396  loss_cls: 0.1892  loss_box_reg: 0.1271  loss_rpn_cls: 0.04706  loss_rpn_loc: 0.05138  time: 1.2931  data_time: 0.0169  lr: 0.0025175  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:37:17 d2.utils.events]: \u001b[0m eta: 23:34:01  iter: 859  total_loss: 0.6372  loss_cls: 0.2661  loss_box_reg: 0.2209  loss_rpn_cls: 0.0305  loss_rpn_loc: 0.04952  time: 1.2931  data_time: 0.0165  lr: 0.0025774  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:37:43 d2.utils.events]: \u001b[0m eta: 23:33:35  iter: 879  total_loss: 0.6506  loss_cls: 0.2755  loss_box_reg: 0.2322  loss_rpn_cls: 0.04398  loss_rpn_loc: 0.07653  time: 1.2932  data_time: 0.0170  lr: 0.0026374  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:38:08 d2.utils.events]: \u001b[0m eta: 23:33:03  iter: 899  total_loss: 0.6017  loss_cls: 0.2701  loss_box_reg: 0.2193  loss_rpn_cls: 0.03623  loss_rpn_loc: 0.04983  time: 1.2929  data_time: 0.0169  lr: 0.0026973  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:38:34 d2.utils.events]: \u001b[0m eta: 23:32:43  iter: 919  total_loss: 0.4514  loss_cls: 0.2056  loss_box_reg: 0.1552  loss_rpn_cls: 0.04325  loss_rpn_loc: 0.03965  time: 1.2930  data_time: 0.0201  lr: 0.0027572  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:39:00 d2.utils.events]: \u001b[0m eta: 23:32:16  iter: 939  total_loss: 0.6197  loss_cls: 0.2474  loss_box_reg: 0.1885  loss_rpn_cls: 0.03543  loss_rpn_loc: 0.07563  time: 1.2931  data_time: 0.0177  lr: 0.0028172  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:39:26 d2.utils.events]: \u001b[0m eta: 23:32:12  iter: 959  total_loss: 0.7224  loss_cls: 0.3282  loss_box_reg: 0.205  loss_rpn_cls: 0.04429  loss_rpn_loc: 0.06309  time: 1.2933  data_time: 0.0169  lr: 0.0028771  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:39:52 d2.utils.events]: \u001b[0m eta: 23:31:39  iter: 979  total_loss: 0.6534  loss_cls: 0.2895  loss_box_reg: 0.2261  loss_rpn_cls: 0.03421  loss_rpn_loc: 0.0598  time: 1.2934  data_time: 0.0168  lr: 0.0029371  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:40:18 d2.utils.events]: \u001b[0m eta: 23:30:59  iter: 999  total_loss: 0.5453  loss_cls: 0.2513  loss_box_reg: 0.208  loss_rpn_cls: 0.03333  loss_rpn_loc: 0.05458  time: 1.2932  data_time: 0.0174  lr: 0.002997  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:40:44 d2.utils.events]: \u001b[0m eta: 23:30:33  iter: 1019  total_loss: 0.611  loss_cls: 0.2758  loss_box_reg: 0.2273  loss_rpn_cls: 0.04665  loss_rpn_loc: 0.0662  time: 1.2932  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:41:10 d2.utils.events]: \u001b[0m eta: 23:30:13  iter: 1039  total_loss: 0.6302  loss_cls: 0.2634  loss_box_reg: 0.2137  loss_rpn_cls: 0.04159  loss_rpn_loc: 0.04897  time: 1.2933  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:41:36 d2.utils.events]: \u001b[0m eta: 23:29:42  iter: 1059  total_loss: 0.5532  loss_cls: 0.2478  loss_box_reg: 0.1997  loss_rpn_cls: 0.05254  loss_rpn_loc: 0.05825  time: 1.2933  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:42:02 d2.utils.events]: \u001b[0m eta: 23:29:16  iter: 1079  total_loss: 0.6616  loss_cls: 0.2885  loss_box_reg: 0.2401  loss_rpn_cls: 0.05084  loss_rpn_loc: 0.04924  time: 1.2932  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:42:27 d2.utils.events]: \u001b[0m eta: 23:29:18  iter: 1099  total_loss: 0.5205  loss_cls: 0.2453  loss_box_reg: 0.1813  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.04767  time: 1.2931  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:42:53 d2.utils.events]: \u001b[0m eta: 23:28:50  iter: 1119  total_loss: 0.6581  loss_cls: 0.3213  loss_box_reg: 0.2158  loss_rpn_cls: 0.04532  loss_rpn_loc: 0.04508  time: 1.2932  data_time: 0.0167  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:43:19 d2.utils.events]: \u001b[0m eta: 23:28:26  iter: 1139  total_loss: 0.5898  loss_cls: 0.2713  loss_box_reg: 0.2249  loss_rpn_cls: 0.03167  loss_rpn_loc: 0.0639  time: 1.2934  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:43:45 d2.utils.events]: \u001b[0m eta: 23:28:04  iter: 1159  total_loss: 0.6302  loss_cls: 0.278  loss_box_reg: 0.2256  loss_rpn_cls: 0.04423  loss_rpn_loc: 0.05305  time: 1.2933  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:44:11 d2.utils.events]: \u001b[0m eta: 23:27:35  iter: 1179  total_loss: 0.6983  loss_cls: 0.3184  loss_box_reg: 0.2721  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.05507  time: 1.2933  data_time: 0.0167  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:44:37 d2.utils.events]: \u001b[0m eta: 23:27:13  iter: 1199  total_loss: 0.6367  loss_cls: 0.2885  loss_box_reg: 0.2332  loss_rpn_cls: 0.04837  loss_rpn_loc: 0.07189  time: 1.2933  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:45:03 d2.utils.events]: \u001b[0m eta: 23:26:52  iter: 1219  total_loss: 0.4911  loss_cls: 0.2018  loss_box_reg: 0.1428  loss_rpn_cls: 0.0765  loss_rpn_loc: 0.05479  time: 1.2934  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:45:29 d2.utils.events]: \u001b[0m eta: 23:26:30  iter: 1239  total_loss: 0.7433  loss_cls: 0.2964  loss_box_reg: 0.2337  loss_rpn_cls: 0.04783  loss_rpn_loc: 0.06831  time: 1.2934  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:45:55 d2.utils.events]: \u001b[0m eta: 23:26:28  iter: 1259  total_loss: 0.6449  loss_cls: 0.2181  loss_box_reg: 0.2099  loss_rpn_cls: 0.04238  loss_rpn_loc: 0.0703  time: 1.2937  data_time: 0.0178  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:46:21 d2.utils.events]: \u001b[0m eta: 23:26:06  iter: 1279  total_loss: 0.6636  loss_cls: 0.3597  loss_box_reg: 0.2232  loss_rpn_cls: 0.03389  loss_rpn_loc: 0.06248  time: 1.2938  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:46:47 d2.utils.events]: \u001b[0m eta: 23:25:27  iter: 1299  total_loss: 0.688  loss_cls: 0.3173  loss_box_reg: 0.2223  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.08595  time: 1.2939  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:47:13 d2.utils.events]: \u001b[0m eta: 23:25:15  iter: 1319  total_loss: 0.8459  loss_cls: 0.3422  loss_box_reg: 0.3079  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.06876  time: 1.2939  data_time: 0.0178  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:47:39 d2.utils.events]: \u001b[0m eta: 23:24:51  iter: 1339  total_loss: 0.4885  loss_cls: 0.2233  loss_box_reg: 0.1763  loss_rpn_cls: 0.04352  loss_rpn_loc: 0.02904  time: 1.2940  data_time: 0.0168  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:48:05 d2.utils.events]: \u001b[0m eta: 23:24:35  iter: 1359  total_loss: 0.4754  loss_cls: 0.2149  loss_box_reg: 0.1709  loss_rpn_cls: 0.03206  loss_rpn_loc: 0.04138  time: 1.2942  data_time: 0.0170  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:48:31 d2.utils.events]: \u001b[0m eta: 23:24:03  iter: 1379  total_loss: 0.5806  loss_cls: 0.1959  loss_box_reg: 0.1481  loss_rpn_cls: 0.04933  loss_rpn_loc: 0.0785  time: 1.2941  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:48:57 d2.utils.events]: \u001b[0m eta: 23:23:39  iter: 1399  total_loss: 0.6582  loss_cls: 0.2993  loss_box_reg: 0.2192  loss_rpn_cls: 0.04567  loss_rpn_loc: 0.04763  time: 1.2941  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:49:23 d2.utils.events]: \u001b[0m eta: 23:23:15  iter: 1419  total_loss: 0.6071  loss_cls: 0.2748  loss_box_reg: 0.2188  loss_rpn_cls: 0.04148  loss_rpn_loc: 0.07124  time: 1.2941  data_time: 0.0170  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:49:49 d2.utils.events]: \u001b[0m eta: 23:22:52  iter: 1439  total_loss: 0.5459  loss_cls: 0.2569  loss_box_reg: 0.1798  loss_rpn_cls: 0.03749  loss_rpn_loc: 0.04279  time: 1.2942  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:50:15 d2.utils.events]: \u001b[0m eta: 23:22:58  iter: 1459  total_loss: 0.6991  loss_cls: 0.3005  loss_box_reg: 0.2414  loss_rpn_cls: 0.05711  loss_rpn_loc: 0.06839  time: 1.2945  data_time: 0.0178  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:50:41 d2.utils.events]: \u001b[0m eta: 23:22:48  iter: 1479  total_loss: 0.6901  loss_cls: 0.2643  loss_box_reg: 0.1897  loss_rpn_cls: 0.03576  loss_rpn_loc: 0.05886  time: 1.2946  data_time: 0.0174  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:51:07 d2.utils.events]: \u001b[0m eta: 23:22:30  iter: 1499  total_loss: 0.6939  loss_cls: 0.2801  loss_box_reg: 0.2621  loss_rpn_cls: 0.03673  loss_rpn_loc: 0.06491  time: 1.2948  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:51:33 d2.utils.events]: \u001b[0m eta: 23:22:00  iter: 1519  total_loss: 0.5528  loss_cls: 0.2316  loss_box_reg: 0.2129  loss_rpn_cls: 0.03454  loss_rpn_loc: 0.05025  time: 1.2947  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:52:00 d2.utils.events]: \u001b[0m eta: 23:21:55  iter: 1539  total_loss: 0.5872  loss_cls: 0.2637  loss_box_reg: 0.2093  loss_rpn_cls: 0.02712  loss_rpn_loc: 0.04488  time: 1.2950  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:52:25 d2.utils.events]: \u001b[0m eta: 23:21:42  iter: 1559  total_loss: 0.6222  loss_cls: 0.2751  loss_box_reg: 0.234  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.05054  time: 1.2950  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:52:51 d2.utils.events]: \u001b[0m eta: 23:21:03  iter: 1579  total_loss: 0.4467  loss_cls: 0.2006  loss_box_reg: 0.1643  loss_rpn_cls: 0.0365  loss_rpn_loc: 0.05224  time: 1.2948  data_time: 0.0172  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:53:17 d2.utils.events]: \u001b[0m eta: 23:20:48  iter: 1599  total_loss: 0.6336  loss_cls: 0.2735  loss_box_reg: 0.2652  loss_rpn_cls: 0.04141  loss_rpn_loc: 0.03745  time: 1.2948  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:53:43 d2.utils.events]: \u001b[0m eta: 23:20:33  iter: 1619  total_loss: 0.5584  loss_cls: 0.2753  loss_box_reg: 0.2066  loss_rpn_cls: 0.03975  loss_rpn_loc: 0.03948  time: 1.2947  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:54:09 d2.utils.events]: \u001b[0m eta: 23:19:59  iter: 1639  total_loss: 0.6431  loss_cls: 0.3383  loss_box_reg: 0.2167  loss_rpn_cls: 0.04367  loss_rpn_loc: 0.06598  time: 1.2947  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:54:35 d2.utils.events]: \u001b[0m eta: 23:19:41  iter: 1659  total_loss: 0.5174  loss_cls: 0.2429  loss_box_reg: 0.1967  loss_rpn_cls: 0.03682  loss_rpn_loc: 0.038  time: 1.2948  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:55:01 d2.utils.events]: \u001b[0m eta: 23:19:07  iter: 1679  total_loss: 0.7452  loss_cls: 0.31  loss_box_reg: 0.2546  loss_rpn_cls: 0.04384  loss_rpn_loc: 0.06607  time: 1.2948  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:55:27 d2.utils.events]: \u001b[0m eta: 23:18:40  iter: 1699  total_loss: 0.4932  loss_cls: 0.2059  loss_box_reg: 0.2053  loss_rpn_cls: 0.03865  loss_rpn_loc: 0.05607  time: 1.2949  data_time: 0.0171  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:55:53 d2.utils.events]: \u001b[0m eta: 23:18:14  iter: 1719  total_loss: 0.6197  loss_cls: 0.279  loss_box_reg: 0.2309  loss_rpn_cls: 0.02805  loss_rpn_loc: 0.05008  time: 1.2950  data_time: 0.0169  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 08:56:19 d2.utils.events]: \u001b[0m eta: 23:18:00  iter: 1739  total_loss: 0.668  loss_cls: 0.2766  loss_box_reg: 0.2663  loss_rpn_cls: 0.03725  loss_rpn_loc: 0.057  time: 1.2949  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 704.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:56:46 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| Aortic enla.. | 1438         |  Atelectasis  | 66           | Calcification | 187          |\n",
            "| Cardiomegaly  | 1075         | Consolidation | 102          |      ILD      | 203          |\n",
            "| Infiltration  | 268          | Lung Opacity  | 511          |  Nodule/Mass  | 448          |\n",
            "| Other lesion  | 433          | Pleural eff.. | 492          | Pleural thi.. | 957          |\n",
            "| Pneumothorax  | 39           | Pulmonary f.. | 953          |               |              |\n",
            "|     total     | 7172         |               |              |               |              |\u001b[0m\n",
            "\u001b[32m[03/06 08:56:46 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:56:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 08:56:46 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'vinbigdata_valid' to COCO format ...)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 683.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:56:47 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 08:56:48 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 878, #annotations: 7172\n",
            "\u001b[32m[03/06 08:56:49 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at 'gdrive/MyDrive/2021_VINBIGDATA/NEW_FOLD/DETECTRON2_101/FOLD0/inference/vinbigdata_valid_coco_format.json' ...\n",
            "\u001b[32m[03/06 08:56:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 08:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2777 s / img. ETA=0:04:20\n",
            "\u001b[32m[03/06 08:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2727 s / img. ETA=0:04:20\n",
            "\u001b[32m[03/06 08:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 46/878. 0.2677 s / img. ETA=0:04:08\n",
            "\u001b[32m[03/06 08:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 64/878. 0.2648 s / img. ETA=0:03:59\n",
            "\u001b[32m[03/06 08:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 82/878. 0.2634 s / img. ETA=0:03:52\n",
            "\u001b[32m[03/06 08:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2621 s / img. ETA=0:03:47\n",
            "\u001b[32m[03/06 08:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 118/878. 0.2615 s / img. ETA=0:03:40\n",
            "\u001b[32m[03/06 08:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 136/878. 0.2610 s / img. ETA=0:03:34\n",
            "\u001b[32m[03/06 08:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 155/878. 0.2597 s / img. ETA=0:03:26\n",
            "\u001b[32m[03/06 08:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 173/878. 0.2599 s / img. ETA=0:03:21\n",
            "\u001b[32m[03/06 08:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 192/878. 0.2594 s / img. ETA=0:03:15\n",
            "\u001b[32m[03/06 08:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 211/878. 0.2592 s / img. ETA=0:03:09\n",
            "\u001b[32m[03/06 08:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 230/878. 0.2587 s / img. ETA=0:03:03\n",
            "\u001b[32m[03/06 08:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 248/878. 0.2590 s / img. ETA=0:02:58\n",
            "\u001b[32m[03/06 08:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 266/878. 0.2589 s / img. ETA=0:02:53\n",
            "\u001b[32m[03/06 08:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 285/878. 0.2589 s / img. ETA=0:02:47\n",
            "\u001b[32m[03/06 08:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 303/878. 0.2590 s / img. ETA=0:02:42\n",
            "\u001b[32m[03/06 08:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 321/878. 0.2590 s / img. ETA=0:02:37\n",
            "\u001b[32m[03/06 08:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 339/878. 0.2589 s / img. ETA=0:02:32\n",
            "\u001b[32m[03/06 08:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 357/878. 0.2590 s / img. ETA=0:02:27\n",
            "\u001b[32m[03/06 08:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 376/878. 0.2590 s / img. ETA=0:02:22\n",
            "\u001b[32m[03/06 08:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 394/878. 0.2590 s / img. ETA=0:02:16\n",
            "\u001b[32m[03/06 08:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 412/878. 0.2589 s / img. ETA=0:02:11\n",
            "\u001b[32m[03/06 08:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 430/878. 0.2588 s / img. ETA=0:02:06\n",
            "\u001b[32m[03/06 08:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 448/878. 0.2590 s / img. ETA=0:02:01\n",
            "\u001b[32m[03/06 08:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 467/878. 0.2591 s / img. ETA=0:01:56\n",
            "\u001b[32m[03/06 08:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 485/878. 0.2590 s / img. ETA=0:01:51\n",
            "\u001b[32m[03/06 08:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 503/878. 0.2592 s / img. ETA=0:01:45\n",
            "\u001b[32m[03/06 08:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 521/878. 0.2589 s / img. ETA=0:01:40\n",
            "\u001b[32m[03/06 08:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 539/878. 0.2589 s / img. ETA=0:01:35\n",
            "\u001b[32m[03/06 08:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 557/878. 0.2588 s / img. ETA=0:01:30\n",
            "\u001b[32m[03/06 08:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 575/878. 0.2588 s / img. ETA=0:01:25\n",
            "\u001b[32m[03/06 08:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 594/878. 0.2586 s / img. ETA=0:01:20\n",
            "\u001b[32m[03/06 08:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 613/878. 0.2586 s / img. ETA=0:01:14\n",
            "\u001b[32m[03/06 08:59:47 d2.evaluation.evaluator]: \u001b[0mInference done 631/878. 0.2585 s / img. ETA=0:01:09\n",
            "\u001b[32m[03/06 08:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 650/878. 0.2585 s / img. ETA=0:01:04\n",
            "\u001b[32m[03/06 08:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 668/878. 0.2584 s / img. ETA=0:00:59\n",
            "\u001b[32m[03/06 09:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 686/878. 0.2584 s / img. ETA=0:00:54\n",
            "\u001b[32m[03/06 09:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 704/878. 0.2586 s / img. ETA=0:00:49\n",
            "\u001b[32m[03/06 09:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 723/878. 0.2585 s / img. ETA=0:00:43\n",
            "\u001b[32m[03/06 09:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 741/878. 0.2585 s / img. ETA=0:00:38\n",
            "\u001b[32m[03/06 09:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 760/878. 0.2585 s / img. ETA=0:00:33\n",
            "\u001b[32m[03/06 09:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 778/878. 0.2584 s / img. ETA=0:00:28\n",
            "\u001b[32m[03/06 09:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 796/878. 0.2583 s / img. ETA=0:00:23\n",
            "\u001b[32m[03/06 09:00:39 d2.evaluation.evaluator]: \u001b[0mInference done 815/878. 0.2582 s / img. ETA=0:00:17\n",
            "\u001b[32m[03/06 09:00:44 d2.evaluation.evaluator]: \u001b[0mInference done 834/878. 0.2581 s / img. ETA=0:00:12\n",
            "\u001b[32m[03/06 09:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 852/878. 0.2581 s / img. ETA=0:00:07\n",
            "\u001b[32m[03/06 09:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 871/878. 0.2580 s / img. ETA=0:00:01\n",
            "\u001b[32m[03/06 09:00:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:05.370881 (0.281066 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 09:00:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.257925 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.28s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.99 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.23 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.103\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.184\n",
            "\u001b[32m[03/06 09:00:59 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 09:00:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 09:00:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 09:00:59 d2.evaluation.testing]: \u001b[0mcopypaste: 6.5839,12.6088,16.3271,1.3481,2.6223,6.6599\n",
            "\u001b[32m[03/06 09:01:01 d2.utils.events]: \u001b[0m eta: 23:17:45  iter: 1759  total_loss: 0.6462  loss_cls: 0.3048  loss_box_reg: 0.2308  loss_rpn_cls: 0.03728  loss_rpn_loc: 0.05929  time: 1.2948  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:01:27 d2.utils.events]: \u001b[0m eta: 23:17:42  iter: 1779  total_loss: 0.6002  loss_cls: 0.2972  loss_box_reg: 0.2286  loss_rpn_cls: 0.03821  loss_rpn_loc: 0.05274  time: 1.2949  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:01:53 d2.utils.events]: \u001b[0m eta: 23:17:16  iter: 1799  total_loss: 0.6864  loss_cls: 0.2782  loss_box_reg: 0.2398  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.07921  time: 1.2949  data_time: 0.0172  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:02:19 d2.utils.events]: \u001b[0m eta: 23:16:49  iter: 1819  total_loss: 0.5468  loss_cls: 0.2343  loss_box_reg: 0.2137  loss_rpn_cls: 0.02798  loss_rpn_loc: 0.05308  time: 1.2949  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:02:45 d2.utils.events]: \u001b[0m eta: 23:17:31  iter: 1839  total_loss: 0.6599  loss_cls: 0.2726  loss_box_reg: 0.2577  loss_rpn_cls: 0.03517  loss_rpn_loc: 0.05111  time: 1.2952  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:03:13 d2.utils.events]: \u001b[0m eta: 23:17:57  iter: 1859  total_loss: 0.5079  loss_cls: 0.2342  loss_box_reg: 0.21  loss_rpn_cls: 0.03859  loss_rpn_loc: 0.0609  time: 1.2958  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:03:39 d2.utils.events]: \u001b[0m eta: 23:17:37  iter: 1879  total_loss: 0.5254  loss_cls: 0.208  loss_box_reg: 0.1972  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.02959  time: 1.2958  data_time: 0.0174  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:04:05 d2.utils.events]: \u001b[0m eta: 23:17:47  iter: 1899  total_loss: 0.6139  loss_cls: 0.2828  loss_box_reg: 0.2305  loss_rpn_cls: 0.03608  loss_rpn_loc: 0.05722  time: 1.2959  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:04:31 d2.utils.events]: \u001b[0m eta: 23:17:27  iter: 1919  total_loss: 0.7687  loss_cls: 0.3005  loss_box_reg: 0.2575  loss_rpn_cls: 0.04766  loss_rpn_loc: 0.0772  time: 1.2960  data_time: 0.0173  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:04:57 d2.utils.events]: \u001b[0m eta: 23:17:10  iter: 1939  total_loss: 0.6146  loss_cls: 0.2945  loss_box_reg: 0.2427  loss_rpn_cls: 0.0299  loss_rpn_loc: 0.0507  time: 1.2960  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:05:23 d2.utils.events]: \u001b[0m eta: 23:16:54  iter: 1959  total_loss: 0.5088  loss_cls: 0.2188  loss_box_reg: 0.1949  loss_rpn_cls: 0.03294  loss_rpn_loc: 0.06093  time: 1.2960  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:05:48 d2.utils.events]: \u001b[0m eta: 23:16:09  iter: 1979  total_loss: 0.6029  loss_cls: 0.2593  loss_box_reg: 0.2228  loss_rpn_cls: 0.03758  loss_rpn_loc: 0.04609  time: 1.2959  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:06:14 d2.utils.events]: \u001b[0m eta: 23:16:14  iter: 1999  total_loss: 0.6614  loss_cls: 0.3109  loss_box_reg: 0.2602  loss_rpn_cls: 0.04037  loss_rpn_loc: 0.0548  time: 1.2960  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:06:40 d2.utils.events]: \u001b[0m eta: 23:15:37  iter: 2019  total_loss: 0.5281  loss_cls: 0.2332  loss_box_reg: 0.1917  loss_rpn_cls: 0.03015  loss_rpn_loc: 0.05264  time: 1.2960  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:07:07 d2.utils.events]: \u001b[0m eta: 23:15:22  iter: 2039  total_loss: 0.6694  loss_cls: 0.2544  loss_box_reg: 0.2419  loss_rpn_cls: 0.03827  loss_rpn_loc: 0.08549  time: 1.2961  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:07:33 d2.utils.events]: \u001b[0m eta: 23:15:42  iter: 2059  total_loss: 0.6131  loss_cls: 0.275  loss_box_reg: 0.2057  loss_rpn_cls: 0.04184  loss_rpn_loc: 0.05922  time: 1.2962  data_time: 0.0169  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:07:59 d2.utils.events]: \u001b[0m eta: 23:15:27  iter: 2079  total_loss: 0.7758  loss_cls: 0.3251  loss_box_reg: 0.247  loss_rpn_cls: 0.04237  loss_rpn_loc: 0.09659  time: 1.2963  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:08:25 d2.utils.events]: \u001b[0m eta: 23:15:36  iter: 2099  total_loss: 0.6714  loss_cls: 0.2704  loss_box_reg: 0.2094  loss_rpn_cls: 0.04295  loss_rpn_loc: 0.07663  time: 1.2965  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:08:51 d2.utils.events]: \u001b[0m eta: 23:15:11  iter: 2119  total_loss: 0.7001  loss_cls: 0.2952  loss_box_reg: 0.2474  loss_rpn_cls: 0.04381  loss_rpn_loc: 0.07293  time: 1.2966  data_time: 0.0171  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:09:17 d2.utils.events]: \u001b[0m eta: 23:14:41  iter: 2139  total_loss: 0.5838  loss_cls: 0.2473  loss_box_reg: 0.2262  loss_rpn_cls: 0.03224  loss_rpn_loc: 0.04119  time: 1.2966  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:09:43 d2.utils.events]: \u001b[0m eta: 23:14:05  iter: 2159  total_loss: 0.5556  loss_cls: 0.2445  loss_box_reg: 0.2097  loss_rpn_cls: 0.03434  loss_rpn_loc: 0.07282  time: 1.2966  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:10:09 d2.utils.events]: \u001b[0m eta: 23:13:52  iter: 2179  total_loss: 0.5405  loss_cls: 0.2319  loss_box_reg: 0.2221  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.05047  time: 1.2966  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:10:35 d2.utils.events]: \u001b[0m eta: 23:13:27  iter: 2199  total_loss: 0.7446  loss_cls: 0.2875  loss_box_reg: 0.2843  loss_rpn_cls: 0.04319  loss_rpn_loc: 0.08286  time: 1.2966  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:11:01 d2.utils.events]: \u001b[0m eta: 23:13:01  iter: 2219  total_loss: 0.704  loss_cls: 0.3157  loss_box_reg: 0.2984  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.04781  time: 1.2966  data_time: 0.0173  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:11:27 d2.utils.events]: \u001b[0m eta: 23:12:28  iter: 2239  total_loss: 0.5836  loss_cls: 0.2327  loss_box_reg: 0.2132  loss_rpn_cls: 0.03655  loss_rpn_loc: 0.07432  time: 1.2965  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:11:53 d2.utils.events]: \u001b[0m eta: 23:11:55  iter: 2259  total_loss: 0.5989  loss_cls: 0.2443  loss_box_reg: 0.2279  loss_rpn_cls: 0.03505  loss_rpn_loc: 0.06339  time: 1.2965  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:12:19 d2.utils.events]: \u001b[0m eta: 23:11:23  iter: 2279  total_loss: 0.6893  loss_cls: 0.2842  loss_box_reg: 0.27  loss_rpn_cls: 0.02803  loss_rpn_loc: 0.05089  time: 1.2965  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:12:45 d2.utils.events]: \u001b[0m eta: 23:10:43  iter: 2299  total_loss: 0.6278  loss_cls: 0.2933  loss_box_reg: 0.2252  loss_rpn_cls: 0.03716  loss_rpn_loc: 0.04141  time: 1.2964  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:13:11 d2.utils.events]: \u001b[0m eta: 23:10:17  iter: 2319  total_loss: 0.5901  loss_cls: 0.2764  loss_box_reg: 0.2332  loss_rpn_cls: 0.02654  loss_rpn_loc: 0.03777  time: 1.2965  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:13:37 d2.utils.events]: \u001b[0m eta: 23:09:51  iter: 2339  total_loss: 0.7134  loss_cls: 0.3116  loss_box_reg: 0.2396  loss_rpn_cls: 0.02958  loss_rpn_loc: 0.06139  time: 1.2966  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:14:03 d2.utils.events]: \u001b[0m eta: 23:08:45  iter: 2359  total_loss: 0.64  loss_cls: 0.2951  loss_box_reg: 0.231  loss_rpn_cls: 0.03373  loss_rpn_loc: 0.06773  time: 1.2965  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:14:28 d2.utils.events]: \u001b[0m eta: 23:08:09  iter: 2379  total_loss: 0.579  loss_cls: 0.313  loss_box_reg: 0.2161  loss_rpn_cls: 0.03209  loss_rpn_loc: 0.05182  time: 1.2964  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:14:54 d2.utils.events]: \u001b[0m eta: 23:07:48  iter: 2399  total_loss: 0.5559  loss_cls: 0.2425  loss_box_reg: 0.211  loss_rpn_cls: 0.03392  loss_rpn_loc: 0.04622  time: 1.2964  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:15:20 d2.utils.events]: \u001b[0m eta: 23:07:22  iter: 2419  total_loss: 0.6341  loss_cls: 0.2536  loss_box_reg: 0.2544  loss_rpn_cls: 0.02993  loss_rpn_loc: 0.04395  time: 1.2964  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:15:46 d2.utils.events]: \u001b[0m eta: 23:06:37  iter: 2439  total_loss: 0.5399  loss_cls: 0.278  loss_box_reg: 0.1804  loss_rpn_cls: 0.03886  loss_rpn_loc: 0.05462  time: 1.2963  data_time: 0.0172  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:16:12 d2.utils.events]: \u001b[0m eta: 23:05:53  iter: 2459  total_loss: 0.7848  loss_cls: 0.333  loss_box_reg: 0.2462  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.07052  time: 1.2963  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:16:38 d2.utils.events]: \u001b[0m eta: 23:05:27  iter: 2479  total_loss: 0.6965  loss_cls: 0.295  loss_box_reg: 0.2365  loss_rpn_cls: 0.04313  loss_rpn_loc: 0.0586  time: 1.2964  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:17:04 d2.utils.events]: \u001b[0m eta: 23:04:56  iter: 2499  total_loss: 0.7492  loss_cls: 0.3145  loss_box_reg: 0.2711  loss_rpn_cls: 0.03436  loss_rpn_loc: 0.0699  time: 1.2964  data_time: 0.0173  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:17:30 d2.utils.events]: \u001b[0m eta: 23:04:26  iter: 2519  total_loss: 0.6168  loss_cls: 0.2601  loss_box_reg: 0.2011  loss_rpn_cls: 0.03343  loss_rpn_loc: 0.05466  time: 1.2964  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:17:56 d2.utils.events]: \u001b[0m eta: 23:03:12  iter: 2539  total_loss: 0.6522  loss_cls: 0.2619  loss_box_reg: 0.2127  loss_rpn_cls: 0.03134  loss_rpn_loc: 0.0633  time: 1.2964  data_time: 0.0168  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:18:21 d2.utils.events]: \u001b[0m eta: 23:01:53  iter: 2559  total_loss: 0.6141  loss_cls: 0.2779  loss_box_reg: 0.22  loss_rpn_cls: 0.03589  loss_rpn_loc: 0.05181  time: 1.2963  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:18:47 d2.utils.events]: \u001b[0m eta: 23:01:27  iter: 2579  total_loss: 0.6585  loss_cls: 0.3098  loss_box_reg: 0.2466  loss_rpn_cls: 0.03879  loss_rpn_loc: 0.05785  time: 1.2962  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:19:13 d2.utils.events]: \u001b[0m eta: 23:01:02  iter: 2599  total_loss: 0.616  loss_cls: 0.2412  loss_box_reg: 0.2757  loss_rpn_cls: 0.04185  loss_rpn_loc: 0.05221  time: 1.2963  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:19:39 d2.utils.events]: \u001b[0m eta: 23:00:36  iter: 2619  total_loss: 0.6648  loss_cls: 0.311  loss_box_reg: 0.2285  loss_rpn_cls: 0.03495  loss_rpn_loc: 0.0424  time: 1.2963  data_time: 0.0173  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:20:05 d2.utils.events]: \u001b[0m eta: 23:00:27  iter: 2639  total_loss: 0.6097  loss_cls: 0.253  loss_box_reg: 0.2215  loss_rpn_cls: 0.03943  loss_rpn_loc: 0.05007  time: 1.2963  data_time: 0.0168  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:20:31 d2.utils.events]: \u001b[0m eta: 23:00:18  iter: 2659  total_loss: 0.5884  loss_cls: 0.2433  loss_box_reg: 0.2169  loss_rpn_cls: 0.03385  loss_rpn_loc: 0.05103  time: 1.2964  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:20:57 d2.utils.events]: \u001b[0m eta: 22:59:28  iter: 2679  total_loss: 0.5409  loss_cls: 0.2481  loss_box_reg: 0.248  loss_rpn_cls: 0.02687  loss_rpn_loc: 0.03812  time: 1.2964  data_time: 0.0173  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:21:23 d2.utils.events]: \u001b[0m eta: 22:59:12  iter: 2699  total_loss: 0.6212  loss_cls: 0.3129  loss_box_reg: 0.2505  loss_rpn_cls: 0.02768  loss_rpn_loc: 0.04386  time: 1.2964  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:21:49 d2.utils.events]: \u001b[0m eta: 22:59:01  iter: 2719  total_loss: 0.5713  loss_cls: 0.2713  loss_box_reg: 0.2259  loss_rpn_cls: 0.03338  loss_rpn_loc: 0.03773  time: 1.2964  data_time: 0.0169  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:22:15 d2.utils.events]: \u001b[0m eta: 22:58:01  iter: 2739  total_loss: 0.637  loss_cls: 0.2596  loss_box_reg: 0.2536  loss_rpn_cls: 0.02876  loss_rpn_loc: 0.05058  time: 1.2964  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:22:41 d2.utils.events]: \u001b[0m eta: 22:57:35  iter: 2759  total_loss: 0.4366  loss_cls: 0.1653  loss_box_reg: 0.1676  loss_rpn_cls: 0.03651  loss_rpn_loc: 0.03609  time: 1.2963  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:23:07 d2.utils.events]: \u001b[0m eta: 22:56:45  iter: 2779  total_loss: 0.7476  loss_cls: 0.3332  loss_box_reg: 0.2725  loss_rpn_cls: 0.03544  loss_rpn_loc: 0.095  time: 1.2963  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:23:33 d2.utils.events]: \u001b[0m eta: 22:55:52  iter: 2799  total_loss: 0.5262  loss_cls: 0.219  loss_box_reg: 0.2193  loss_rpn_cls: 0.02985  loss_rpn_loc: 0.04403  time: 1.2963  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:23:59 d2.utils.events]: \u001b[0m eta: 22:55:27  iter: 2819  total_loss: 0.6852  loss_cls: 0.2522  loss_box_reg: 0.2393  loss_rpn_cls: 0.0413  loss_rpn_loc: 0.06215  time: 1.2963  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:24:24 d2.utils.events]: \u001b[0m eta: 22:54:14  iter: 2839  total_loss: 0.5224  loss_cls: 0.2486  loss_box_reg: 0.1854  loss_rpn_cls: 0.02009  loss_rpn_loc: 0.03986  time: 1.2962  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:24:50 d2.utils.events]: \u001b[0m eta: 22:53:05  iter: 2859  total_loss: 0.5918  loss_cls: 0.2032  loss_box_reg: 0.2303  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.05214  time: 1.2962  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:25:16 d2.utils.events]: \u001b[0m eta: 22:52:30  iter: 2879  total_loss: 0.6237  loss_cls: 0.2874  loss_box_reg: 0.2574  loss_rpn_cls: 0.04789  loss_rpn_loc: 0.06378  time: 1.2962  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:25:42 d2.utils.events]: \u001b[0m eta: 22:52:04  iter: 2899  total_loss: 0.5607  loss_cls: 0.2215  loss_box_reg: 0.1977  loss_rpn_cls: 0.02981  loss_rpn_loc: 0.04347  time: 1.2963  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:26:08 d2.utils.events]: \u001b[0m eta: 22:51:32  iter: 2919  total_loss: 0.7049  loss_cls: 0.3084  loss_box_reg: 0.2767  loss_rpn_cls: 0.02854  loss_rpn_loc: 0.0608  time: 1.2963  data_time: 0.0214  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:26:34 d2.utils.events]: \u001b[0m eta: 22:50:51  iter: 2939  total_loss: 0.688  loss_cls: 0.273  loss_box_reg: 0.2582  loss_rpn_cls: 0.04785  loss_rpn_loc: 0.06029  time: 1.2962  data_time: 0.0169  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:27:00 d2.utils.events]: \u001b[0m eta: 22:50:13  iter: 2959  total_loss: 0.7412  loss_cls: 0.3161  loss_box_reg: 0.3119  loss_rpn_cls: 0.02852  loss_rpn_loc: 0.06283  time: 1.2962  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:27:26 d2.utils.events]: \u001b[0m eta: 22:49:49  iter: 2979  total_loss: 0.674  loss_cls: 0.3032  loss_box_reg: 0.2576  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.04753  time: 1.2962  data_time: 0.0304  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:27:52 d2.utils.events]: \u001b[0m eta: 22:49:23  iter: 2999  total_loss: 0.6402  loss_cls: 0.2647  loss_box_reg: 0.2356  loss_rpn_cls: 0.0362  loss_rpn_loc: 0.06541  time: 1.2962  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:28:18 d2.utils.events]: \u001b[0m eta: 22:48:56  iter: 3019  total_loss: 0.4831  loss_cls: 0.1771  loss_box_reg: 0.1597  loss_rpn_cls: 0.03324  loss_rpn_loc: 0.05768  time: 1.2962  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:28:43 d2.utils.events]: \u001b[0m eta: 22:48:20  iter: 3039  total_loss: 0.7262  loss_cls: 0.3186  loss_box_reg: 0.2622  loss_rpn_cls: 0.03946  loss_rpn_loc: 0.06456  time: 1.2961  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:29:09 d2.utils.events]: \u001b[0m eta: 22:47:17  iter: 3059  total_loss: 0.5157  loss_cls: 0.2401  loss_box_reg: 0.2179  loss_rpn_cls: 0.0296  loss_rpn_loc: 0.04597  time: 1.2961  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:29:35 d2.utils.events]: \u001b[0m eta: 22:46:30  iter: 3079  total_loss: 0.6317  loss_cls: 0.279  loss_box_reg: 0.2533  loss_rpn_cls: 0.02482  loss_rpn_loc: 0.06612  time: 1.2961  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:30:01 d2.utils.events]: \u001b[0m eta: 22:46:05  iter: 3099  total_loss: 0.6242  loss_cls: 0.2494  loss_box_reg: 0.238  loss_rpn_cls: 0.03046  loss_rpn_loc: 0.04622  time: 1.2961  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:30:27 d2.utils.events]: \u001b[0m eta: 22:45:43  iter: 3119  total_loss: 0.5349  loss_cls: 0.2305  loss_box_reg: 0.2028  loss_rpn_cls: 0.0317  loss_rpn_loc: 0.04249  time: 1.2961  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:30:53 d2.utils.events]: \u001b[0m eta: 22:45:21  iter: 3139  total_loss: 0.7438  loss_cls: 0.3332  loss_box_reg: 0.2933  loss_rpn_cls: 0.0504  loss_rpn_loc: 0.06092  time: 1.2961  data_time: 0.0170  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:31:19 d2.utils.events]: \u001b[0m eta: 22:45:02  iter: 3159  total_loss: 0.5718  loss_cls: 0.2135  loss_box_reg: 0.2122  loss_rpn_cls: 0.02747  loss_rpn_loc: 0.03935  time: 1.2961  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:31:45 d2.utils.events]: \u001b[0m eta: 22:44:22  iter: 3179  total_loss: 0.6121  loss_cls: 0.2551  loss_box_reg: 0.263  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.04113  time: 1.2961  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:32:11 d2.utils.events]: \u001b[0m eta: 22:43:53  iter: 3199  total_loss: 0.7616  loss_cls: 0.2856  loss_box_reg: 0.2268  loss_rpn_cls: 0.03174  loss_rpn_loc: 0.06885  time: 1.2961  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:32:37 d2.utils.events]: \u001b[0m eta: 22:43:45  iter: 3219  total_loss: 0.721  loss_cls: 0.3174  loss_box_reg: 0.3073  loss_rpn_cls: 0.02645  loss_rpn_loc: 0.04019  time: 1.2962  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:33:03 d2.utils.events]: \u001b[0m eta: 22:44:03  iter: 3239  total_loss: 0.7282  loss_cls: 0.3342  loss_box_reg: 0.3007  loss_rpn_cls: 0.02827  loss_rpn_loc: 0.04957  time: 1.2963  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:33:30 d2.utils.events]: \u001b[0m eta: 22:43:41  iter: 3259  total_loss: 0.705  loss_cls: 0.3135  loss_box_reg: 0.2783  loss_rpn_cls: 0.0344  loss_rpn_loc: 0.05239  time: 1.2964  data_time: 0.0178  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:33:56 d2.utils.events]: \u001b[0m eta: 22:43:15  iter: 3279  total_loss: 0.6892  loss_cls: 0.3015  loss_box_reg: 0.2951  loss_rpn_cls: 0.0364  loss_rpn_loc: 0.06149  time: 1.2964  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:34:22 d2.utils.events]: \u001b[0m eta: 22:42:55  iter: 3299  total_loss: 0.6041  loss_cls: 0.2564  loss_box_reg: 0.2456  loss_rpn_cls: 0.03172  loss_rpn_loc: 0.05268  time: 1.2964  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:34:48 d2.utils.events]: \u001b[0m eta: 22:42:32  iter: 3319  total_loss: 0.7075  loss_cls: 0.3132  loss_box_reg: 0.275  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.05693  time: 1.2965  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:35:14 d2.utils.events]: \u001b[0m eta: 22:41:58  iter: 3339  total_loss: 0.7229  loss_cls: 0.2784  loss_box_reg: 0.2693  loss_rpn_cls: 0.02611  loss_rpn_loc: 0.05393  time: 1.2965  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:35:40 d2.utils.events]: \u001b[0m eta: 22:41:38  iter: 3359  total_loss: 0.7059  loss_cls: 0.2346  loss_box_reg: 0.2444  loss_rpn_cls: 0.04025  loss_rpn_loc: 0.06862  time: 1.2965  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:36:06 d2.utils.events]: \u001b[0m eta: 22:41:17  iter: 3379  total_loss: 0.6052  loss_cls: 0.2623  loss_box_reg: 0.2116  loss_rpn_cls: 0.02633  loss_rpn_loc: 0.06339  time: 1.2966  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:36:32 d2.utils.events]: \u001b[0m eta: 22:40:50  iter: 3399  total_loss: 0.7902  loss_cls: 0.3723  loss_box_reg: 0.3302  loss_rpn_cls: 0.02994  loss_rpn_loc: 0.06789  time: 1.2966  data_time: 0.0209  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:36:58 d2.utils.events]: \u001b[0m eta: 22:40:21  iter: 3419  total_loss: 0.6323  loss_cls: 0.2964  loss_box_reg: 0.2588  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.04839  time: 1.2965  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:37:24 d2.utils.events]: \u001b[0m eta: 22:39:59  iter: 3439  total_loss: 0.6896  loss_cls: 0.3152  loss_box_reg: 0.2717  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.057  time: 1.2965  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:37:50 d2.utils.events]: \u001b[0m eta: 22:39:53  iter: 3459  total_loss: 0.8113  loss_cls: 0.2806  loss_box_reg: 0.2917  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.07181  time: 1.2966  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:38:16 d2.utils.events]: \u001b[0m eta: 22:39:24  iter: 3479  total_loss: 0.6449  loss_cls: 0.2686  loss_box_reg: 0.2537  loss_rpn_cls: 0.02959  loss_rpn_loc: 0.08622  time: 1.2966  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:38:42 d2.utils.events]: \u001b[0m eta: 22:39:01  iter: 3499  total_loss: 0.465  loss_cls: 0.1961  loss_box_reg: 0.1734  loss_rpn_cls: 0.02378  loss_rpn_loc: 0.04094  time: 1.2967  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 707.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 09:39:07 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 09:39:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 09:39:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 09:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2749 s / img. ETA=0:04:29\n",
            "\u001b[32m[03/06 09:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2678 s / img. ETA=0:04:17\n",
            "\u001b[32m[03/06 09:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2691 s / img. ETA=0:04:11\n",
            "\u001b[32m[03/06 09:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2670 s / img. ETA=0:04:02\n",
            "\u001b[32m[03/06 09:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2646 s / img. ETA=0:03:55\n",
            "\u001b[32m[03/06 09:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2636 s / img. ETA=0:03:48\n",
            "\u001b[32m[03/06 09:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 117/878. 0.2631 s / img. ETA=0:03:41\n",
            "\u001b[32m[03/06 09:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 135/878. 0.2625 s / img. ETA=0:03:35\n",
            "\u001b[32m[03/06 09:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 153/878. 0.2623 s / img. ETA=0:03:29\n",
            "\u001b[32m[03/06 09:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 171/878. 0.2620 s / img. ETA=0:03:23\n",
            "\u001b[32m[03/06 09:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 189/878. 0.2617 s / img. ETA=0:03:18\n",
            "\u001b[32m[03/06 09:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 208/878. 0.2609 s / img. ETA=0:03:12\n",
            "\u001b[32m[03/06 09:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 226/878. 0.2607 s / img. ETA=0:03:06\n",
            "\u001b[32m[03/06 09:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 244/878. 0.2605 s / img. ETA=0:03:01\n",
            "\u001b[32m[03/06 09:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 263/878. 0.2600 s / img. ETA=0:02:55\n",
            "\u001b[32m[03/06 09:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 282/878. 0.2597 s / img. ETA=0:02:49\n",
            "\u001b[32m[03/06 09:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 300/878. 0.2597 s / img. ETA=0:02:44\n",
            "\u001b[32m[03/06 09:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 318/878. 0.2597 s / img. ETA=0:02:39\n",
            "\u001b[32m[03/06 09:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 336/878. 0.2598 s / img. ETA=0:02:34\n",
            "\u001b[32m[03/06 09:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 354/878. 0.2600 s / img. ETA=0:02:29\n",
            "\u001b[32m[03/06 09:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 372/878. 0.2599 s / img. ETA=0:02:23\n",
            "\u001b[32m[03/06 09:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 390/878. 0.2599 s / img. ETA=0:02:18\n",
            "\u001b[32m[03/06 09:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 408/878. 0.2598 s / img. ETA=0:02:13\n",
            "\u001b[32m[03/06 09:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 426/878. 0.2598 s / img. ETA=0:02:08\n",
            "\u001b[32m[03/06 09:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 444/878. 0.2598 s / img. ETA=0:02:03\n",
            "\u001b[32m[03/06 09:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 463/878. 0.2597 s / img. ETA=0:01:57\n",
            "\u001b[32m[03/06 09:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 481/878. 0.2597 s / img. ETA=0:01:52\n",
            "\u001b[32m[03/06 09:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 499/878. 0.2597 s / img. ETA=0:01:47\n",
            "\u001b[32m[03/06 09:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 517/878. 0.2597 s / img. ETA=0:01:42\n",
            "\u001b[32m[03/06 09:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 535/878. 0.2598 s / img. ETA=0:01:37\n",
            "\u001b[32m[03/06 09:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 553/878. 0.2598 s / img. ETA=0:01:32\n",
            "\u001b[32m[03/06 09:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 571/878. 0.2596 s / img. ETA=0:01:26\n",
            "\u001b[32m[03/06 09:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 589/878. 0.2596 s / img. ETA=0:01:21\n",
            "\u001b[32m[03/06 09:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 607/878. 0.2596 s / img. ETA=0:01:16\n",
            "\u001b[32m[03/06 09:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 626/878. 0.2594 s / img. ETA=0:01:11\n",
            "\u001b[32m[03/06 09:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 644/878. 0.2594 s / img. ETA=0:01:06\n",
            "\u001b[32m[03/06 09:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 662/878. 0.2593 s / img. ETA=0:01:01\n",
            "\u001b[32m[03/06 09:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 681/878. 0.2592 s / img. ETA=0:00:55\n",
            "\u001b[32m[03/06 09:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 699/878. 0.2592 s / img. ETA=0:00:50\n",
            "\u001b[32m[03/06 09:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 717/878. 0.2591 s / img. ETA=0:00:45\n",
            "\u001b[32m[03/06 09:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 735/878. 0.2591 s / img. ETA=0:00:40\n",
            "\u001b[32m[03/06 09:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 753/878. 0.2590 s / img. ETA=0:00:35\n",
            "\u001b[32m[03/06 09:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 771/878. 0.2590 s / img. ETA=0:00:30\n",
            "\u001b[32m[03/06 09:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 789/878. 0.2590 s / img. ETA=0:00:25\n",
            "\u001b[32m[03/06 09:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 807/878. 0.2590 s / img. ETA=0:00:20\n",
            "\u001b[32m[03/06 09:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 826/878. 0.2589 s / img. ETA=0:00:14\n",
            "\u001b[32m[03/06 09:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 844/878. 0.2588 s / img. ETA=0:00:09\n",
            "\u001b[32m[03/06 09:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 862/878. 0.2589 s / img. ETA=0:00:04\n",
            "\u001b[32m[03/06 09:43:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:06.387075 (0.282230 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 09:43:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.258745 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.21s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.79 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.14 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.200\n",
            "\u001b[32m[03/06 09:43:17 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 09:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 09:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 09:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3525,15.9382,20.5865,0.3051,4.7606,8.5848\n",
            "\u001b[32m[03/06 09:43:22 d2.utils.events]: \u001b[0m eta: 22:39:18  iter: 3519  total_loss: 0.6217  loss_cls: 0.2555  loss_box_reg: 0.2519  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.04034  time: 1.2967  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:43:48 d2.utils.events]: \u001b[0m eta: 22:39:01  iter: 3539  total_loss: 0.7916  loss_cls: 0.2963  loss_box_reg: 0.3074  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.06069  time: 1.2966  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:44:14 d2.utils.events]: \u001b[0m eta: 22:39:05  iter: 3559  total_loss: 0.5485  loss_cls: 0.2528  loss_box_reg: 0.2195  loss_rpn_cls: 0.03097  loss_rpn_loc: 0.06186  time: 1.2966  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:44:40 d2.utils.events]: \u001b[0m eta: 22:39:08  iter: 3579  total_loss: 0.5548  loss_cls: 0.2258  loss_box_reg: 0.2257  loss_rpn_cls: 0.02317  loss_rpn_loc: 0.03795  time: 1.2967  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:45:06 d2.utils.events]: \u001b[0m eta: 22:38:16  iter: 3599  total_loss: 0.5136  loss_cls: 0.241  loss_box_reg: 0.2181  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.04136  time: 1.2966  data_time: 0.0178  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:45:32 d2.utils.events]: \u001b[0m eta: 22:37:48  iter: 3619  total_loss: 0.6944  loss_cls: 0.2741  loss_box_reg: 0.2278  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.07581  time: 1.2966  data_time: 0.0234  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:45:58 d2.utils.events]: \u001b[0m eta: 22:37:31  iter: 3639  total_loss: 0.5696  loss_cls: 0.2887  loss_box_reg: 0.1927  loss_rpn_cls: 0.04787  loss_rpn_loc: 0.04248  time: 1.2967  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:46:24 d2.utils.events]: \u001b[0m eta: 22:36:56  iter: 3659  total_loss: 0.6013  loss_cls: 0.2949  loss_box_reg: 0.2536  loss_rpn_cls: 0.04078  loss_rpn_loc: 0.04867  time: 1.2966  data_time: 0.0173  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:46:50 d2.utils.events]: \u001b[0m eta: 22:36:35  iter: 3679  total_loss: 0.5103  loss_cls: 0.2374  loss_box_reg: 0.22  loss_rpn_cls: 0.03143  loss_rpn_loc: 0.03935  time: 1.2966  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:47:16 d2.utils.events]: \u001b[0m eta: 22:36:06  iter: 3699  total_loss: 0.5737  loss_cls: 0.206  loss_box_reg: 0.1542  loss_rpn_cls: 0.0352  loss_rpn_loc: 0.05555  time: 1.2966  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:47:42 d2.utils.events]: \u001b[0m eta: 22:35:43  iter: 3719  total_loss: 0.4933  loss_cls: 0.2173  loss_box_reg: 0.218  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.04106  time: 1.2966  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:48:08 d2.utils.events]: \u001b[0m eta: 22:35:36  iter: 3739  total_loss: 0.6322  loss_cls: 0.2571  loss_box_reg: 0.2339  loss_rpn_cls: 0.03073  loss_rpn_loc: 0.05476  time: 1.2966  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:48:33 d2.utils.events]: \u001b[0m eta: 22:35:11  iter: 3759  total_loss: 0.669  loss_cls: 0.3033  loss_box_reg: 0.2716  loss_rpn_cls: 0.03468  loss_rpn_loc: 0.05177  time: 1.2966  data_time: 0.0174  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:48:59 d2.utils.events]: \u001b[0m eta: 22:35:00  iter: 3779  total_loss: 0.4803  loss_cls: 0.2167  loss_box_reg: 0.2021  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.04213  time: 1.2966  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:49:26 d2.utils.events]: \u001b[0m eta: 22:34:48  iter: 3799  total_loss: 0.6904  loss_cls: 0.3164  loss_box_reg: 0.2525  loss_rpn_cls: 0.02729  loss_rpn_loc: 0.04925  time: 1.2966  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:49:52 d2.utils.events]: \u001b[0m eta: 22:34:38  iter: 3819  total_loss: 0.6945  loss_cls: 0.2821  loss_box_reg: 0.2564  loss_rpn_cls: 0.03869  loss_rpn_loc: 0.05225  time: 1.2967  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:50:18 d2.utils.events]: \u001b[0m eta: 22:34:17  iter: 3839  total_loss: 0.6801  loss_cls: 0.2654  loss_box_reg: 0.2277  loss_rpn_cls: 0.02415  loss_rpn_loc: 0.06473  time: 1.2967  data_time: 0.0174  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:50:44 d2.utils.events]: \u001b[0m eta: 22:34:27  iter: 3859  total_loss: 0.625  loss_cls: 0.2858  loss_box_reg: 0.2721  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.04485  time: 1.2968  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:51:10 d2.utils.events]: \u001b[0m eta: 22:33:32  iter: 3879  total_loss: 0.5229  loss_cls: 0.254  loss_box_reg: 0.1938  loss_rpn_cls: 0.02261  loss_rpn_loc: 0.05652  time: 1.2967  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:51:36 d2.utils.events]: \u001b[0m eta: 22:32:54  iter: 3899  total_loss: 0.6209  loss_cls: 0.2653  loss_box_reg: 0.2508  loss_rpn_cls: 0.02942  loss_rpn_loc: 0.06175  time: 1.2967  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:52:02 d2.utils.events]: \u001b[0m eta: 22:32:23  iter: 3919  total_loss: 0.5809  loss_cls: 0.2418  loss_box_reg: 0.2609  loss_rpn_cls: 0.03144  loss_rpn_loc: 0.04442  time: 1.2967  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:52:28 d2.utils.events]: \u001b[0m eta: 22:32:15  iter: 3939  total_loss: 0.5893  loss_cls: 0.2694  loss_box_reg: 0.24  loss_rpn_cls: 0.02983  loss_rpn_loc: 0.04481  time: 1.2967  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:52:53 d2.utils.events]: \u001b[0m eta: 22:32:06  iter: 3959  total_loss: 0.6088  loss_cls: 0.2435  loss_box_reg: 0.244  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.03897  time: 1.2967  data_time: 0.0232  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:53:19 d2.utils.events]: \u001b[0m eta: 22:31:28  iter: 3979  total_loss: 0.5414  loss_cls: 0.2821  loss_box_reg: 0.2109  loss_rpn_cls: 0.02399  loss_rpn_loc: 0.04172  time: 1.2967  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:53:45 d2.utils.events]: \u001b[0m eta: 22:30:53  iter: 3999  total_loss: 0.527  loss_cls: 0.2056  loss_box_reg: 0.2287  loss_rpn_cls: 0.03495  loss_rpn_loc: 0.06877  time: 1.2967  data_time: 0.0227  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:54:11 d2.utils.events]: \u001b[0m eta: 22:30:27  iter: 4019  total_loss: 0.5429  loss_cls: 0.2081  loss_box_reg: 0.2135  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.04948  time: 1.2966  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:54:37 d2.utils.events]: \u001b[0m eta: 22:30:35  iter: 4039  total_loss: 0.5716  loss_cls: 0.254  loss_box_reg: 0.2757  loss_rpn_cls: 0.02608  loss_rpn_loc: 0.03922  time: 1.2967  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:55:03 d2.utils.events]: \u001b[0m eta: 22:30:13  iter: 4059  total_loss: 0.7106  loss_cls: 0.2731  loss_box_reg: 0.2654  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.06513  time: 1.2967  data_time: 0.0214  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:55:29 d2.utils.events]: \u001b[0m eta: 22:30:07  iter: 4079  total_loss: 0.5227  loss_cls: 0.2464  loss_box_reg: 0.1795  loss_rpn_cls: 0.02568  loss_rpn_loc: 0.05453  time: 1.2966  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:55:55 d2.utils.events]: \u001b[0m eta: 22:29:33  iter: 4099  total_loss: 0.5236  loss_cls: 0.2326  loss_box_reg: 0.2378  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.03772  time: 1.2967  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:56:21 d2.utils.events]: \u001b[0m eta: 22:29:15  iter: 4119  total_loss: 0.805  loss_cls: 0.3025  loss_box_reg: 0.3094  loss_rpn_cls: 0.02662  loss_rpn_loc: 0.06079  time: 1.2968  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:56:47 d2.utils.events]: \u001b[0m eta: 22:28:50  iter: 4139  total_loss: 0.5958  loss_cls: 0.2099  loss_box_reg: 0.1794  loss_rpn_cls: 0.02771  loss_rpn_loc: 0.05682  time: 1.2968  data_time: 0.0216  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:57:13 d2.utils.events]: \u001b[0m eta: 22:28:24  iter: 4159  total_loss: 0.5366  loss_cls: 0.2398  loss_box_reg: 0.1923  loss_rpn_cls: 0.03293  loss_rpn_loc: 0.05889  time: 1.2968  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:57:39 d2.utils.events]: \u001b[0m eta: 22:28:29  iter: 4179  total_loss: 0.7423  loss_cls: 0.3248  loss_box_reg: 0.285  loss_rpn_cls: 0.03301  loss_rpn_loc: 0.05801  time: 1.2968  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:58:06 d2.utils.events]: \u001b[0m eta: 22:28:13  iter: 4199  total_loss: 0.7878  loss_cls: 0.352  loss_box_reg: 0.3061  loss_rpn_cls: 0.03431  loss_rpn_loc: 0.05092  time: 1.2969  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:58:32 d2.utils.events]: \u001b[0m eta: 22:27:26  iter: 4219  total_loss: 0.6432  loss_cls: 0.2599  loss_box_reg: 0.2469  loss_rpn_cls: 0.0262  loss_rpn_loc: 0.0603  time: 1.2969  data_time: 0.0218  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:58:57 d2.utils.events]: \u001b[0m eta: 22:26:32  iter: 4239  total_loss: 0.521  loss_cls: 0.2251  loss_box_reg: 0.208  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.03937  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:59:23 d2.utils.events]: \u001b[0m eta: 22:25:56  iter: 4259  total_loss: 0.6325  loss_cls: 0.2845  loss_box_reg: 0.2931  loss_rpn_cls: 0.02593  loss_rpn_loc: 0.04493  time: 1.2968  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 09:59:49 d2.utils.events]: \u001b[0m eta: 22:25:24  iter: 4279  total_loss: 0.6252  loss_cls: 0.2438  loss_box_reg: 0.2935  loss_rpn_cls: 0.02419  loss_rpn_loc: 0.05354  time: 1.2968  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:00:15 d2.utils.events]: \u001b[0m eta: 22:24:40  iter: 4299  total_loss: 0.7692  loss_cls: 0.2928  loss_box_reg: 0.2717  loss_rpn_cls: 0.03005  loss_rpn_loc: 0.06341  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:00:41 d2.utils.events]: \u001b[0m eta: 22:24:10  iter: 4319  total_loss: 0.5746  loss_cls: 0.2238  loss_box_reg: 0.2334  loss_rpn_cls: 0.02933  loss_rpn_loc: 0.04867  time: 1.2968  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:01:07 d2.utils.events]: \u001b[0m eta: 22:24:07  iter: 4339  total_loss: 0.6089  loss_cls: 0.2833  loss_box_reg: 0.2816  loss_rpn_cls: 0.02015  loss_rpn_loc: 0.06005  time: 1.2968  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:01:33 d2.utils.events]: \u001b[0m eta: 22:23:18  iter: 4359  total_loss: 0.6061  loss_cls: 0.2612  loss_box_reg: 0.2362  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.04566  time: 1.2968  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:01:59 d2.utils.events]: \u001b[0m eta: 22:22:43  iter: 4379  total_loss: 0.5937  loss_cls: 0.2057  loss_box_reg: 0.1893  loss_rpn_cls: 0.02962  loss_rpn_loc: 0.03858  time: 1.2967  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:02:25 d2.utils.events]: \u001b[0m eta: 22:22:14  iter: 4399  total_loss: 0.6712  loss_cls: 0.2919  loss_box_reg: 0.2739  loss_rpn_cls: 0.02608  loss_rpn_loc: 0.04835  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:02:51 d2.utils.events]: \u001b[0m eta: 22:22:14  iter: 4419  total_loss: 0.5783  loss_cls: 0.2063  loss_box_reg: 0.2232  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.05124  time: 1.2968  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:03:17 d2.utils.events]: \u001b[0m eta: 22:21:35  iter: 4439  total_loss: 0.7484  loss_cls: 0.3467  loss_box_reg: 0.3206  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.06078  time: 1.2968  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:03:43 d2.utils.events]: \u001b[0m eta: 22:21:05  iter: 4459  total_loss: 0.754  loss_cls: 0.3322  loss_box_reg: 0.3202  loss_rpn_cls: 0.02519  loss_rpn_loc: 0.07085  time: 1.2969  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:04:09 d2.utils.events]: \u001b[0m eta: 22:20:39  iter: 4479  total_loss: 0.6113  loss_cls: 0.2834  loss_box_reg: 0.2438  loss_rpn_cls: 0.03786  loss_rpn_loc: 0.04884  time: 1.2968  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:04:35 d2.utils.events]: \u001b[0m eta: 22:19:45  iter: 4499  total_loss: 0.5927  loss_cls: 0.2258  loss_box_reg: 0.2505  loss_rpn_cls: 0.02324  loss_rpn_loc: 0.05501  time: 1.2968  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:05:00 d2.utils.events]: \u001b[0m eta: 22:18:50  iter: 4519  total_loss: 0.6628  loss_cls: 0.2703  loss_box_reg: 0.2557  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.04405  time: 1.2968  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:05:26 d2.utils.events]: \u001b[0m eta: 22:18:26  iter: 4539  total_loss: 0.5788  loss_cls: 0.2444  loss_box_reg: 0.2327  loss_rpn_cls: 0.02898  loss_rpn_loc: 0.042  time: 1.2968  data_time: 0.0222  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:05:52 d2.utils.events]: \u001b[0m eta: 22:17:49  iter: 4559  total_loss: 0.5659  loss_cls: 0.3005  loss_box_reg: 0.2203  loss_rpn_cls: 0.03129  loss_rpn_loc: 0.04225  time: 1.2968  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:06:18 d2.utils.events]: \u001b[0m eta: 22:17:14  iter: 4579  total_loss: 0.5058  loss_cls: 0.2266  loss_box_reg: 0.2149  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.03374  time: 1.2968  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:06:44 d2.utils.events]: \u001b[0m eta: 22:16:57  iter: 4599  total_loss: 0.7628  loss_cls: 0.3191  loss_box_reg: 0.2952  loss_rpn_cls: 0.0323  loss_rpn_loc: 0.06113  time: 1.2968  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:07:10 d2.utils.events]: \u001b[0m eta: 22:16:31  iter: 4619  total_loss: 0.7434  loss_cls: 0.2805  loss_box_reg: 0.2529  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.06099  time: 1.2967  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:07:36 d2.utils.events]: \u001b[0m eta: 22:15:55  iter: 4639  total_loss: 0.657  loss_cls: 0.2932  loss_box_reg: 0.2623  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.04634  time: 1.2967  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:08:02 d2.utils.events]: \u001b[0m eta: 22:15:36  iter: 4659  total_loss: 0.5491  loss_cls: 0.1984  loss_box_reg: 0.2056  loss_rpn_cls: 0.02602  loss_rpn_loc: 0.04161  time: 1.2967  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:08:28 d2.utils.events]: \u001b[0m eta: 22:15:14  iter: 4679  total_loss: 0.5317  loss_cls: 0.2242  loss_box_reg: 0.2221  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.05764  time: 1.2968  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:08:54 d2.utils.events]: \u001b[0m eta: 22:14:49  iter: 4699  total_loss: 0.4338  loss_cls: 0.2024  loss_box_reg: 0.1827  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.0424  time: 1.2968  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:09:20 d2.utils.events]: \u001b[0m eta: 22:14:05  iter: 4719  total_loss: 0.679  loss_cls: 0.268  loss_box_reg: 0.2559  loss_rpn_cls: 0.02826  loss_rpn_loc: 0.06601  time: 1.2968  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:09:46 d2.utils.events]: \u001b[0m eta: 22:13:39  iter: 4739  total_loss: 0.6613  loss_cls: 0.2902  loss_box_reg: 0.2821  loss_rpn_cls: 0.03049  loss_rpn_loc: 0.07908  time: 1.2968  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:10:12 d2.utils.events]: \u001b[0m eta: 22:13:21  iter: 4759  total_loss: 0.6391  loss_cls: 0.2723  loss_box_reg: 0.2304  loss_rpn_cls: 0.02987  loss_rpn_loc: 0.04508  time: 1.2968  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:10:38 d2.utils.events]: \u001b[0m eta: 22:12:42  iter: 4779  total_loss: 0.5393  loss_cls: 0.2332  loss_box_reg: 0.2289  loss_rpn_cls: 0.02182  loss_rpn_loc: 0.04368  time: 1.2968  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:11:03 d2.utils.events]: \u001b[0m eta: 22:12:08  iter: 4799  total_loss: 0.5802  loss_cls: 0.2491  loss_box_reg: 0.234  loss_rpn_cls: 0.0265  loss_rpn_loc: 0.04713  time: 1.2967  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:11:29 d2.utils.events]: \u001b[0m eta: 22:11:39  iter: 4819  total_loss: 0.6704  loss_cls: 0.2758  loss_box_reg: 0.277  loss_rpn_cls: 0.03193  loss_rpn_loc: 0.04898  time: 1.2967  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:11:55 d2.utils.events]: \u001b[0m eta: 22:11:13  iter: 4839  total_loss: 0.8025  loss_cls: 0.3426  loss_box_reg: 0.2997  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.06991  time: 1.2967  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:12:21 d2.utils.events]: \u001b[0m eta: 22:10:37  iter: 4859  total_loss: 0.5155  loss_cls: 0.2213  loss_box_reg: 0.1947  loss_rpn_cls: 0.02457  loss_rpn_loc: 0.04532  time: 1.2967  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:12:47 d2.utils.events]: \u001b[0m eta: 22:10:25  iter: 4879  total_loss: 0.5091  loss_cls: 0.2366  loss_box_reg: 0.2101  loss_rpn_cls: 0.03015  loss_rpn_loc: 0.03911  time: 1.2968  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:13:13 d2.utils.events]: \u001b[0m eta: 22:10:10  iter: 4899  total_loss: 0.5724  loss_cls: 0.2097  loss_box_reg: 0.2357  loss_rpn_cls: 0.02361  loss_rpn_loc: 0.04221  time: 1.2968  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:13:39 d2.utils.events]: \u001b[0m eta: 22:09:59  iter: 4919  total_loss: 0.4104  loss_cls: 0.1787  loss_box_reg: 0.1891  loss_rpn_cls: 0.03969  loss_rpn_loc: 0.04494  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:14:05 d2.utils.events]: \u001b[0m eta: 22:09:37  iter: 4939  total_loss: 0.5704  loss_cls: 0.2429  loss_box_reg: 0.212  loss_rpn_cls: 0.04326  loss_rpn_loc: 0.06333  time: 1.2968  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:14:31 d2.utils.events]: \u001b[0m eta: 22:09:07  iter: 4959  total_loss: 0.659  loss_cls: 0.2832  loss_box_reg: 0.2463  loss_rpn_cls: 0.02836  loss_rpn_loc: 0.05804  time: 1.2968  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:14:57 d2.utils.events]: \u001b[0m eta: 22:08:51  iter: 4979  total_loss: 0.6833  loss_cls: 0.3026  loss_box_reg: 0.287  loss_rpn_cls: 0.03558  loss_rpn_loc: 0.05154  time: 1.2968  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:15:23 d2.utils.events]: \u001b[0m eta: 22:08:30  iter: 4999  total_loss: 0.5837  loss_cls: 0.2524  loss_box_reg: 0.2305  loss_rpn_cls: 0.03261  loss_rpn_loc: 0.0358  time: 1.2968  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:15:49 d2.utils.events]: \u001b[0m eta: 22:08:18  iter: 5019  total_loss: 0.6325  loss_cls: 0.2528  loss_box_reg: 0.2511  loss_rpn_cls: 0.029  loss_rpn_loc: 0.06975  time: 1.2968  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:16:15 d2.utils.events]: \u001b[0m eta: 22:08:13  iter: 5039  total_loss: 0.5461  loss_cls: 0.2309  loss_box_reg: 0.2246  loss_rpn_cls: 0.02652  loss_rpn_loc: 0.04636  time: 1.2969  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:16:41 d2.utils.events]: \u001b[0m eta: 22:07:54  iter: 5059  total_loss: 0.613  loss_cls: 0.2237  loss_box_reg: 0.2413  loss_rpn_cls: 0.02828  loss_rpn_loc: 0.06683  time: 1.2969  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:17:07 d2.utils.events]: \u001b[0m eta: 22:07:28  iter: 5079  total_loss: 0.6036  loss_cls: 0.2459  loss_box_reg: 0.2166  loss_rpn_cls: 0.02705  loss_rpn_loc: 0.05013  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:17:33 d2.utils.events]: \u001b[0m eta: 22:06:56  iter: 5099  total_loss: 0.6348  loss_cls: 0.2608  loss_box_reg: 0.2499  loss_rpn_cls: 0.03835  loss_rpn_loc: 0.0569  time: 1.2968  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:17:59 d2.utils.events]: \u001b[0m eta: 22:06:06  iter: 5119  total_loss: 0.5969  loss_cls: 0.2178  loss_box_reg: 0.2698  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.04609  time: 1.2968  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:18:25 d2.utils.events]: \u001b[0m eta: 22:05:27  iter: 5139  total_loss: 0.5916  loss_cls: 0.2462  loss_box_reg: 0.2682  loss_rpn_cls: 0.02631  loss_rpn_loc: 0.05694  time: 1.2968  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:18:51 d2.utils.events]: \u001b[0m eta: 22:05:09  iter: 5159  total_loss: 0.7303  loss_cls: 0.3129  loss_box_reg: 0.3123  loss_rpn_cls: 0.02168  loss_rpn_loc: 0.06246  time: 1.2968  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:19:17 d2.utils.events]: \u001b[0m eta: 22:05:01  iter: 5179  total_loss: 0.6119  loss_cls: 0.2511  loss_box_reg: 0.2434  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.05123  time: 1.2969  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:19:43 d2.utils.events]: \u001b[0m eta: 22:04:01  iter: 5199  total_loss: 0.6107  loss_cls: 0.2348  loss_box_reg: 0.2559  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.04854  time: 1.2969  data_time: 0.0222  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:20:09 d2.utils.events]: \u001b[0m eta: 22:03:33  iter: 5219  total_loss: 0.6247  loss_cls: 0.2806  loss_box_reg: 0.282  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.04711  time: 1.2969  data_time: 0.0174  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:20:35 d2.utils.events]: \u001b[0m eta: 22:03:11  iter: 5239  total_loss: 0.8756  loss_cls: 0.3739  loss_box_reg: 0.3328  loss_rpn_cls: 0.0326  loss_rpn_loc: 0.08193  time: 1.2969  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:21:01 d2.utils.events]: \u001b[0m eta: 22:02:34  iter: 5259  total_loss: 0.595  loss_cls: 0.2765  loss_box_reg: 0.2429  loss_rpn_cls: 0.02752  loss_rpn_loc: 0.04606  time: 1.2969  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 619.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 10:21:24 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/06 10:21:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 10:21:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 10:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2691 s / img. ETA=0:04:09\n",
            "\u001b[32m[03/06 10:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2742 s / img. ETA=0:04:16\n",
            "\u001b[32m[03/06 10:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2713 s / img. ETA=0:04:09\n",
            "\u001b[32m[03/06 10:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2667 s / img. ETA=0:03:59\n",
            "\u001b[32m[03/06 10:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2634 s / img. ETA=0:03:52\n",
            "\u001b[32m[03/06 10:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2628 s / img. ETA=0:03:46\n",
            "\u001b[32m[03/06 10:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 117/878. 0.2627 s / img. ETA=0:03:40\n",
            "\u001b[32m[03/06 10:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 135/878. 0.2624 s / img. ETA=0:03:33\n",
            "\u001b[32m[03/06 10:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 153/878. 0.2614 s / img. ETA=0:03:27\n",
            "\u001b[32m[03/06 10:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 171/878. 0.2611 s / img. ETA=0:03:21\n",
            "\u001b[32m[03/06 10:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 189/878. 0.2610 s / img. ETA=0:03:16\n",
            "\u001b[32m[03/06 10:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 208/878. 0.2608 s / img. ETA=0:03:10\n",
            "\u001b[32m[03/06 10:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 227/878. 0.2603 s / img. ETA=0:03:04\n",
            "\u001b[32m[03/06 10:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 245/878. 0.2602 s / img. ETA=0:02:59\n",
            "\u001b[32m[03/06 10:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 263/878. 0.2605 s / img. ETA=0:02:54\n",
            "\u001b[32m[03/06 10:22:44 d2.evaluation.evaluator]: \u001b[0mInference done 282/878. 0.2601 s / img. ETA=0:02:48\n",
            "\u001b[32m[03/06 10:22:49 d2.evaluation.evaluator]: \u001b[0mInference done 300/878. 0.2599 s / img. ETA=0:02:43\n",
            "\u001b[32m[03/06 10:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 318/878. 0.2599 s / img. ETA=0:02:38\n",
            "\u001b[32m[03/06 10:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 336/878. 0.2599 s / img. ETA=0:02:33\n",
            "\u001b[32m[03/06 10:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 354/878. 0.2600 s / img. ETA=0:02:28\n",
            "\u001b[32m[03/06 10:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 373/878. 0.2596 s / img. ETA=0:02:22\n",
            "\u001b[32m[03/06 10:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 391/878. 0.2594 s / img. ETA=0:02:17\n",
            "\u001b[32m[03/06 10:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 409/878. 0.2592 s / img. ETA=0:02:12\n",
            "\u001b[32m[03/06 10:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 427/878. 0.2592 s / img. ETA=0:02:07\n",
            "\u001b[32m[03/06 10:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 445/878. 0.2592 s / img. ETA=0:02:02\n",
            "\u001b[32m[03/06 10:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 463/878. 0.2592 s / img. ETA=0:01:57\n",
            "\u001b[32m[03/06 10:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 481/878. 0.2592 s / img. ETA=0:01:52\n",
            "\u001b[32m[03/06 10:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 499/878. 0.2591 s / img. ETA=0:01:47\n",
            "\u001b[32m[03/06 10:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 517/878. 0.2592 s / img. ETA=0:01:41\n",
            "\u001b[32m[03/06 10:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 535/878. 0.2592 s / img. ETA=0:01:36\n",
            "\u001b[32m[03/06 10:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 553/878. 0.2592 s / img. ETA=0:01:31\n",
            "\u001b[32m[03/06 10:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 571/878. 0.2593 s / img. ETA=0:01:26\n",
            "\u001b[32m[03/06 10:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 589/878. 0.2594 s / img. ETA=0:01:21\n",
            "\u001b[32m[03/06 10:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 607/878. 0.2593 s / img. ETA=0:01:16\n",
            "\u001b[32m[03/06 10:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 626/878. 0.2592 s / img. ETA=0:01:11\n",
            "\u001b[32m[03/06 10:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 644/878. 0.2591 s / img. ETA=0:01:06\n",
            "\u001b[32m[03/06 10:24:32 d2.evaluation.evaluator]: \u001b[0mInference done 662/878. 0.2591 s / img. ETA=0:01:01\n",
            "\u001b[32m[03/06 10:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 681/878. 0.2590 s / img. ETA=0:00:55\n",
            "\u001b[32m[03/06 10:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 699/878. 0.2589 s / img. ETA=0:00:50\n",
            "\u001b[32m[03/06 10:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 717/878. 0.2590 s / img. ETA=0:00:45\n",
            "\u001b[32m[03/06 10:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 735/878. 0.2589 s / img. ETA=0:00:40\n",
            "\u001b[32m[03/06 10:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 753/878. 0.2589 s / img. ETA=0:00:35\n",
            "\u001b[32m[03/06 10:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 771/878. 0.2589 s / img. ETA=0:00:30\n",
            "\u001b[32m[03/06 10:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 789/878. 0.2588 s / img. ETA=0:00:25\n",
            "\u001b[32m[03/06 10:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 807/878. 0.2589 s / img. ETA=0:00:20\n",
            "\u001b[32m[03/06 10:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 825/878. 0.2588 s / img. ETA=0:00:14\n",
            "\u001b[32m[03/06 10:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 843/878. 0.2588 s / img. ETA=0:00:09\n",
            "\u001b[32m[03/06 10:25:28 d2.evaluation.evaluator]: \u001b[0mInference done 861/878. 0.2590 s / img. ETA=0:00:04\n",
            "\u001b[32m[03/06 10:25:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:06.695341 (0.282583 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 10:25:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.258842 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.78 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.13 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.206\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.208\n",
            "\u001b[32m[03/06 10:25:34 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 10:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 10:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 10:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9645,17.1043,21.9591,2.8601,6.9983,9.2905\n",
            "\u001b[32m[03/06 10:25:42 d2.utils.events]: \u001b[0m eta: 22:02:16  iter: 5279  total_loss: 0.569  loss_cls: 0.2339  loss_box_reg: 0.2426  loss_rpn_cls: 0.03225  loss_rpn_loc: 0.06112  time: 1.2969  data_time: 0.0220  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:26:07 d2.utils.events]: \u001b[0m eta: 22:01:50  iter: 5299  total_loss: 0.5892  loss_cls: 0.2439  loss_box_reg: 0.2384  loss_rpn_cls: 0.0264  loss_rpn_loc: 0.07069  time: 1.2968  data_time: 0.0213  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:26:34 d2.utils.events]: \u001b[0m eta: 22:01:24  iter: 5319  total_loss: 0.6729  loss_cls: 0.2926  loss_box_reg: 0.2737  loss_rpn_cls: 0.02324  loss_rpn_loc: 0.04886  time: 1.2968  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:26:59 d2.utils.events]: \u001b[0m eta: 22:00:43  iter: 5339  total_loss: 0.5907  loss_cls: 0.2666  loss_box_reg: 0.2671  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.04212  time: 1.2968  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:27:25 d2.utils.events]: \u001b[0m eta: 22:00:32  iter: 5359  total_loss: 0.5969  loss_cls: 0.2514  loss_box_reg: 0.2925  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.03995  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:27:51 d2.utils.events]: \u001b[0m eta: 22:00:11  iter: 5379  total_loss: 0.5484  loss_cls: 0.2336  loss_box_reg: 0.2444  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.04949  time: 1.2968  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:28:17 d2.utils.events]: \u001b[0m eta: 21:59:41  iter: 5399  total_loss: 0.7489  loss_cls: 0.3106  loss_box_reg: 0.2988  loss_rpn_cls: 0.03185  loss_rpn_loc: 0.06555  time: 1.2968  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:28:43 d2.utils.events]: \u001b[0m eta: 21:58:58  iter: 5419  total_loss: 0.6021  loss_cls: 0.2501  loss_box_reg: 0.2362  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.04983  time: 1.2968  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:29:09 d2.utils.events]: \u001b[0m eta: 21:58:38  iter: 5439  total_loss: 0.5538  loss_cls: 0.2416  loss_box_reg: 0.2275  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.03328  time: 1.2968  data_time: 0.0174  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:29:35 d2.utils.events]: \u001b[0m eta: 21:58:12  iter: 5459  total_loss: 0.7432  loss_cls: 0.2993  loss_box_reg: 0.2954  loss_rpn_cls: 0.02358  loss_rpn_loc: 0.05928  time: 1.2968  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:30:01 d2.utils.events]: \u001b[0m eta: 21:57:44  iter: 5479  total_loss: 0.6938  loss_cls: 0.2828  loss_box_reg: 0.2926  loss_rpn_cls: 0.02931  loss_rpn_loc: 0.0539  time: 1.2968  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:30:27 d2.utils.events]: \u001b[0m eta: 21:57:26  iter: 5499  total_loss: 0.6223  loss_cls: 0.2564  loss_box_reg: 0.2054  loss_rpn_cls: 0.02745  loss_rpn_loc: 0.06691  time: 1.2968  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:30:53 d2.utils.events]: \u001b[0m eta: 21:57:14  iter: 5519  total_loss: 0.706  loss_cls: 0.2667  loss_box_reg: 0.2507  loss_rpn_cls: 0.03315  loss_rpn_loc: 0.07406  time: 1.2968  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:31:19 d2.utils.events]: \u001b[0m eta: 21:56:42  iter: 5539  total_loss: 0.554  loss_cls: 0.2113  loss_box_reg: 0.2232  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.05051  time: 1.2968  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:31:44 d2.utils.events]: \u001b[0m eta: 21:56:03  iter: 5559  total_loss: 0.7355  loss_cls: 0.2916  loss_box_reg: 0.3122  loss_rpn_cls: 0.02889  loss_rpn_loc: 0.06253  time: 1.2967  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:32:10 d2.utils.events]: \u001b[0m eta: 21:55:36  iter: 5579  total_loss: 0.6309  loss_cls: 0.2769  loss_box_reg: 0.2601  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.05427  time: 1.2967  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:32:36 d2.utils.events]: \u001b[0m eta: 21:55:10  iter: 5599  total_loss: 0.4225  loss_cls: 0.1872  loss_box_reg: 0.2008  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.03595  time: 1.2967  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:33:02 d2.utils.events]: \u001b[0m eta: 21:54:46  iter: 5619  total_loss: 0.7864  loss_cls: 0.3103  loss_box_reg: 0.3232  loss_rpn_cls: 0.02472  loss_rpn_loc: 0.05784  time: 1.2967  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:33:28 d2.utils.events]: \u001b[0m eta: 21:54:31  iter: 5639  total_loss: 0.7454  loss_cls: 0.3532  loss_box_reg: 0.2728  loss_rpn_cls: 0.02507  loss_rpn_loc: 0.05585  time: 1.2967  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:33:54 d2.utils.events]: \u001b[0m eta: 21:54:12  iter: 5659  total_loss: 0.7923  loss_cls: 0.3198  loss_box_reg: 0.3399  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.06211  time: 1.2968  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:34:21 d2.utils.events]: \u001b[0m eta: 21:53:46  iter: 5679  total_loss: 0.7144  loss_cls: 0.274  loss_box_reg: 0.2573  loss_rpn_cls: 0.02492  loss_rpn_loc: 0.06842  time: 1.2968  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:34:47 d2.utils.events]: \u001b[0m eta: 21:53:30  iter: 5699  total_loss: 0.5912  loss_cls: 0.2445  loss_box_reg: 0.2219  loss_rpn_cls: 0.02617  loss_rpn_loc: 0.0581  time: 1.2969  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:35:13 d2.utils.events]: \u001b[0m eta: 21:53:05  iter: 5719  total_loss: 0.4638  loss_cls: 0.2144  loss_box_reg: 0.1822  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.03816  time: 1.2969  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:35:39 d2.utils.events]: \u001b[0m eta: 21:52:34  iter: 5739  total_loss: 0.5519  loss_cls: 0.2145  loss_box_reg: 0.264  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.04198  time: 1.2969  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:36:05 d2.utils.events]: \u001b[0m eta: 21:52:04  iter: 5759  total_loss: 0.5748  loss_cls: 0.2358  loss_box_reg: 0.1988  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.03304  time: 1.2969  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:36:31 d2.utils.events]: \u001b[0m eta: 21:51:52  iter: 5779  total_loss: 0.6705  loss_cls: 0.2701  loss_box_reg: 0.2592  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.05935  time: 1.2969  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:36:57 d2.utils.events]: \u001b[0m eta: 21:51:56  iter: 5799  total_loss: 0.6685  loss_cls: 0.314  loss_box_reg: 0.2269  loss_rpn_cls: 0.04606  loss_rpn_loc: 0.07242  time: 1.2969  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:37:23 d2.utils.events]: \u001b[0m eta: 21:51:26  iter: 5819  total_loss: 0.4398  loss_cls: 0.1594  loss_box_reg: 0.195  loss_rpn_cls: 0.04643  loss_rpn_loc: 0.03593  time: 1.2970  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:37:49 d2.utils.events]: \u001b[0m eta: 21:51:05  iter: 5839  total_loss: 0.5723  loss_cls: 0.2529  loss_box_reg: 0.2032  loss_rpn_cls: 0.02098  loss_rpn_loc: 0.03825  time: 1.2970  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:38:15 d2.utils.events]: \u001b[0m eta: 21:50:40  iter: 5859  total_loss: 0.6886  loss_cls: 0.3207  loss_box_reg: 0.2775  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.06939  time: 1.2970  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:38:41 d2.utils.events]: \u001b[0m eta: 21:49:59  iter: 5879  total_loss: 0.6296  loss_cls: 0.3052  loss_box_reg: 0.28  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.03749  time: 1.2970  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:39:07 d2.utils.events]: \u001b[0m eta: 21:49:47  iter: 5899  total_loss: 0.6735  loss_cls: 0.2944  loss_box_reg: 0.2922  loss_rpn_cls: 0.0286  loss_rpn_loc: 0.04016  time: 1.2970  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:39:33 d2.utils.events]: \u001b[0m eta: 21:49:17  iter: 5919  total_loss: 0.6996  loss_cls: 0.2623  loss_box_reg: 0.2517  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.05891  time: 1.2970  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:39:59 d2.utils.events]: \u001b[0m eta: 21:48:31  iter: 5939  total_loss: 0.503  loss_cls: 0.2245  loss_box_reg: 0.2083  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.03541  time: 1.2970  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:40:25 d2.utils.events]: \u001b[0m eta: 21:48:38  iter: 5959  total_loss: 0.4649  loss_cls: 0.1961  loss_box_reg: 0.2245  loss_rpn_cls: 0.02669  loss_rpn_loc: 0.0484  time: 1.2970  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:40:51 d2.utils.events]: \u001b[0m eta: 21:48:18  iter: 5979  total_loss: 0.6979  loss_cls: 0.3045  loss_box_reg: 0.2882  loss_rpn_cls: 0.02933  loss_rpn_loc: 0.05302  time: 1.2971  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:41:17 d2.utils.events]: \u001b[0m eta: 21:47:53  iter: 5999  total_loss: 0.7633  loss_cls: 0.3011  loss_box_reg: 0.2741  loss_rpn_cls: 0.02485  loss_rpn_loc: 0.04982  time: 1.2971  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:41:43 d2.utils.events]: \u001b[0m eta: 21:47:29  iter: 6019  total_loss: 0.6284  loss_cls: 0.2291  loss_box_reg: 0.2465  loss_rpn_cls: 0.0289  loss_rpn_loc: 0.07128  time: 1.2971  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:42:09 d2.utils.events]: \u001b[0m eta: 21:47:03  iter: 6039  total_loss: 0.5563  loss_cls: 0.2441  loss_box_reg: 0.2339  loss_rpn_cls: 0.02697  loss_rpn_loc: 0.04794  time: 1.2971  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:42:35 d2.utils.events]: \u001b[0m eta: 21:46:37  iter: 6059  total_loss: 0.5146  loss_cls: 0.2123  loss_box_reg: 0.2246  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.03103  time: 1.2971  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:43:01 d2.utils.events]: \u001b[0m eta: 21:46:15  iter: 6079  total_loss: 0.5253  loss_cls: 0.229  loss_box_reg: 0.2274  loss_rpn_cls: 0.03088  loss_rpn_loc: 0.04283  time: 1.2971  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:43:27 d2.utils.events]: \u001b[0m eta: 21:45:54  iter: 6099  total_loss: 0.689  loss_cls: 0.304  loss_box_reg: 0.2875  loss_rpn_cls: 0.02581  loss_rpn_loc: 0.05666  time: 1.2971  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:43:54 d2.utils.events]: \u001b[0m eta: 21:45:41  iter: 6119  total_loss: 0.6984  loss_cls: 0.283  loss_box_reg: 0.2478  loss_rpn_cls: 0.03265  loss_rpn_loc: 0.06949  time: 1.2971  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:44:20 d2.utils.events]: \u001b[0m eta: 21:45:12  iter: 6139  total_loss: 0.5997  loss_cls: 0.2866  loss_box_reg: 0.2482  loss_rpn_cls: 0.0286  loss_rpn_loc: 0.04623  time: 1.2972  data_time: 0.0227  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:44:46 d2.utils.events]: \u001b[0m eta: 21:44:55  iter: 6159  total_loss: 0.9313  loss_cls: 0.3913  loss_box_reg: 0.3813  loss_rpn_cls: 0.03453  loss_rpn_loc: 0.07862  time: 1.2972  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:45:11 d2.utils.events]: \u001b[0m eta: 21:44:08  iter: 6179  total_loss: 0.6066  loss_cls: 0.2781  loss_box_reg: 0.2667  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.05662  time: 1.2972  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:45:37 d2.utils.events]: \u001b[0m eta: 21:43:55  iter: 6199  total_loss: 0.6272  loss_cls: 0.2742  loss_box_reg: 0.2799  loss_rpn_cls: 0.0259  loss_rpn_loc: 0.04535  time: 1.2972  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:46:03 d2.utils.events]: \u001b[0m eta: 21:43:29  iter: 6219  total_loss: 0.708  loss_cls: 0.2786  loss_box_reg: 0.2645  loss_rpn_cls: 0.02608  loss_rpn_loc: 0.06576  time: 1.2972  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:46:30 d2.utils.events]: \u001b[0m eta: 21:43:29  iter: 6239  total_loss: 0.5807  loss_cls: 0.2415  loss_box_reg: 0.2395  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.05465  time: 1.2972  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:46:55 d2.utils.events]: \u001b[0m eta: 21:43:17  iter: 6259  total_loss: 0.5271  loss_cls: 0.2126  loss_box_reg: 0.201  loss_rpn_cls: 0.02038  loss_rpn_loc: 0.05408  time: 1.2972  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:47:21 d2.utils.events]: \u001b[0m eta: 21:42:29  iter: 6279  total_loss: 0.5799  loss_cls: 0.2271  loss_box_reg: 0.2315  loss_rpn_cls: 0.02948  loss_rpn_loc: 0.07222  time: 1.2972  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:47:47 d2.utils.events]: \u001b[0m eta: 21:42:07  iter: 6299  total_loss: 0.5606  loss_cls: 0.24  loss_box_reg: 0.2578  loss_rpn_cls: 0.02256  loss_rpn_loc: 0.04933  time: 1.2971  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:48:13 d2.utils.events]: \u001b[0m eta: 21:41:20  iter: 6319  total_loss: 0.61  loss_cls: 0.2661  loss_box_reg: 0.2714  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.04481  time: 1.2971  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:48:39 d2.utils.events]: \u001b[0m eta: 21:40:57  iter: 6339  total_loss: 0.7987  loss_cls: 0.3074  loss_box_reg: 0.2909  loss_rpn_cls: 0.02895  loss_rpn_loc: 0.08386  time: 1.2972  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:49:05 d2.utils.events]: \u001b[0m eta: 21:40:51  iter: 6359  total_loss: 0.5083  loss_cls: 0.2142  loss_box_reg: 0.2092  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.03598  time: 1.2972  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:49:31 d2.utils.events]: \u001b[0m eta: 21:40:30  iter: 6379  total_loss: 0.5535  loss_cls: 0.2477  loss_box_reg: 0.2378  loss_rpn_cls: 0.0206  loss_rpn_loc: 0.03184  time: 1.2972  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:49:57 d2.utils.events]: \u001b[0m eta: 21:40:22  iter: 6399  total_loss: 0.6236  loss_cls: 0.2769  loss_box_reg: 0.2609  loss_rpn_cls: 0.02781  loss_rpn_loc: 0.05078  time: 1.2972  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:50:23 d2.utils.events]: \u001b[0m eta: 21:40:07  iter: 6419  total_loss: 0.6005  loss_cls: 0.2732  loss_box_reg: 0.2482  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.04168  time: 1.2972  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:50:49 d2.utils.events]: \u001b[0m eta: 21:39:41  iter: 6439  total_loss: 0.5416  loss_cls: 0.2056  loss_box_reg: 0.2398  loss_rpn_cls: 0.02787  loss_rpn_loc: 0.04661  time: 1.2972  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:51:15 d2.utils.events]: \u001b[0m eta: 21:38:58  iter: 6459  total_loss: 0.4783  loss_cls: 0.2238  loss_box_reg: 0.2176  loss_rpn_cls: 0.0236  loss_rpn_loc: 0.03988  time: 1.2972  data_time: 0.0241  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:51:41 d2.utils.events]: \u001b[0m eta: 21:38:34  iter: 6479  total_loss: 0.6253  loss_cls: 0.2778  loss_box_reg: 0.2633  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.06117  time: 1.2972  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:52:07 d2.utils.events]: \u001b[0m eta: 21:38:18  iter: 6499  total_loss: 0.6495  loss_cls: 0.2577  loss_box_reg: 0.2286  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.05881  time: 1.2972  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:52:33 d2.utils.events]: \u001b[0m eta: 21:37:47  iter: 6519  total_loss: 0.5984  loss_cls: 0.2252  loss_box_reg: 0.2453  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.0537  time: 1.2972  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:52:59 d2.utils.events]: \u001b[0m eta: 21:38:15  iter: 6539  total_loss: 0.5199  loss_cls: 0.2349  loss_box_reg: 0.2459  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.04189  time: 1.2973  data_time: 0.0223  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:53:25 d2.utils.events]: \u001b[0m eta: 21:38:02  iter: 6559  total_loss: 0.7273  loss_cls: 0.2862  loss_box_reg: 0.2685  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.04499  time: 1.2973  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:53:52 d2.utils.events]: \u001b[0m eta: 21:37:56  iter: 6579  total_loss: 0.8333  loss_cls: 0.3627  loss_box_reg: 0.2963  loss_rpn_cls: 0.02788  loss_rpn_loc: 0.07512  time: 1.2973  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:54:17 d2.utils.events]: \u001b[0m eta: 21:37:30  iter: 6599  total_loss: 0.5385  loss_cls: 0.2101  loss_box_reg: 0.2094  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.0428  time: 1.2973  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:54:43 d2.utils.events]: \u001b[0m eta: 21:37:19  iter: 6619  total_loss: 0.5779  loss_cls: 0.2573  loss_box_reg: 0.2277  loss_rpn_cls: 0.02863  loss_rpn_loc: 0.04857  time: 1.2973  data_time: 0.0214  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:55:09 d2.utils.events]: \u001b[0m eta: 21:36:44  iter: 6639  total_loss: 0.6989  loss_cls: 0.2902  loss_box_reg: 0.2671  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.05116  time: 1.2972  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:55:35 d2.utils.events]: \u001b[0m eta: 21:35:44  iter: 6659  total_loss: 0.682  loss_cls: 0.2905  loss_box_reg: 0.2836  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.04989  time: 1.2972  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:56:01 d2.utils.events]: \u001b[0m eta: 21:35:08  iter: 6679  total_loss: 0.6874  loss_cls: 0.288  loss_box_reg: 0.2594  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.04983  time: 1.2972  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:56:27 d2.utils.events]: \u001b[0m eta: 21:34:23  iter: 6699  total_loss: 0.7651  loss_cls: 0.3377  loss_box_reg: 0.2742  loss_rpn_cls: 0.03  loss_rpn_loc: 0.07057  time: 1.2972  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:56:53 d2.utils.events]: \u001b[0m eta: 21:33:40  iter: 6719  total_loss: 0.6605  loss_cls: 0.2709  loss_box_reg: 0.2787  loss_rpn_cls: 0.03448  loss_rpn_loc: 0.05186  time: 1.2972  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:57:19 d2.utils.events]: \u001b[0m eta: 21:33:43  iter: 6739  total_loss: 0.5164  loss_cls: 0.2254  loss_box_reg: 0.1752  loss_rpn_cls: 0.02607  loss_rpn_loc: 0.05249  time: 1.2972  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:57:45 d2.utils.events]: \u001b[0m eta: 21:33:28  iter: 6759  total_loss: 0.6578  loss_cls: 0.2757  loss_box_reg: 0.2452  loss_rpn_cls: 0.02445  loss_rpn_loc: 0.0548  time: 1.2972  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:58:11 d2.utils.events]: \u001b[0m eta: 21:32:39  iter: 6779  total_loss: 0.5561  loss_cls: 0.2512  loss_box_reg: 0.2738  loss_rpn_cls: 0.01744  loss_rpn_loc: 0.03587  time: 1.2972  data_time: 0.0216  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:58:37 d2.utils.events]: \u001b[0m eta: 21:31:50  iter: 6799  total_loss: 0.5871  loss_cls: 0.2601  loss_box_reg: 0.2563  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.04623  time: 1.2972  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:59:03 d2.utils.events]: \u001b[0m eta: 21:31:24  iter: 6819  total_loss: 0.5631  loss_cls: 0.2746  loss_box_reg: 0.261  loss_rpn_cls: 0.02192  loss_rpn_loc: 0.04602  time: 1.2972  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:59:29 d2.utils.events]: \u001b[0m eta: 21:31:01  iter: 6839  total_loss: 0.6466  loss_cls: 0.2539  loss_box_reg: 0.2738  loss_rpn_cls: 0.02283  loss_rpn_loc: 0.03951  time: 1.2972  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 10:59:55 d2.utils.events]: \u001b[0m eta: 21:30:33  iter: 6859  total_loss: 0.6492  loss_cls: 0.2565  loss_box_reg: 0.2783  loss_rpn_cls: 0.03016  loss_rpn_loc: 0.05014  time: 1.2973  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:00:21 d2.utils.events]: \u001b[0m eta: 21:30:46  iter: 6879  total_loss: 0.4753  loss_cls: 0.238  loss_box_reg: 0.2333  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.03546  time: 1.2973  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:00:47 d2.utils.events]: \u001b[0m eta: 21:29:38  iter: 6899  total_loss: 0.5195  loss_cls: 0.1972  loss_box_reg: 0.2266  loss_rpn_cls: 0.02112  loss_rpn_loc: 0.03709  time: 1.2972  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:01:12 d2.utils.events]: \u001b[0m eta: 21:28:59  iter: 6919  total_loss: 0.7863  loss_cls: 0.3581  loss_box_reg: 0.2814  loss_rpn_cls: 0.03736  loss_rpn_loc: 0.08595  time: 1.2972  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:01:38 d2.utils.events]: \u001b[0m eta: 21:28:35  iter: 6939  total_loss: 0.5487  loss_cls: 0.2788  loss_box_reg: 0.2204  loss_rpn_cls: 0.02503  loss_rpn_loc: 0.03871  time: 1.2972  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:02:04 d2.utils.events]: \u001b[0m eta: 21:27:58  iter: 6959  total_loss: 0.5415  loss_cls: 0.2407  loss_box_reg: 0.2759  loss_rpn_cls: 0.02601  loss_rpn_loc: 0.04579  time: 1.2973  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:02:30 d2.utils.events]: \u001b[0m eta: 21:27:19  iter: 6979  total_loss: 0.5242  loss_cls: 0.2132  loss_box_reg: 0.2579  loss_rpn_cls: 0.02324  loss_rpn_loc: 0.03864  time: 1.2972  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:02:56 d2.utils.events]: \u001b[0m eta: 21:26:45  iter: 6999  total_loss: 0.6351  loss_cls: 0.2803  loss_box_reg: 0.2713  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.06226  time: 1.2972  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:03:22 d2.utils.events]: \u001b[0m eta: 21:26:20  iter: 7019  total_loss: 0.7997  loss_cls: 0.2956  loss_box_reg: 0.3291  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.0631  time: 1.2972  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 695.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 11:03:42 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 11:03:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 11:03:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 11:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2659 s / img. ETA=0:04:16\n",
            "\u001b[32m[03/06 11:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2739 s / img. ETA=0:04:17\n",
            "\u001b[32m[03/06 11:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2709 s / img. ETA=0:04:11\n",
            "\u001b[32m[03/06 11:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2671 s / img. ETA=0:04:01\n",
            "\u001b[32m[03/06 11:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2655 s / img. ETA=0:03:54\n",
            "\u001b[32m[03/06 11:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2648 s / img. ETA=0:03:48\n",
            "\u001b[32m[03/06 11:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 117/878. 0.2640 s / img. ETA=0:03:42\n",
            "\u001b[32m[03/06 11:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 135/878. 0.2642 s / img. ETA=0:03:36\n",
            "\u001b[32m[03/06 11:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 153/878. 0.2633 s / img. ETA=0:03:30\n",
            "\u001b[32m[03/06 11:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 171/878. 0.2633 s / img. ETA=0:03:24\n",
            "\u001b[32m[03/06 11:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 189/878. 0.2623 s / img. ETA=0:03:18\n",
            "\u001b[32m[03/06 11:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 207/878. 0.2617 s / img. ETA=0:03:13\n",
            "\u001b[32m[03/06 11:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 225/878. 0.2612 s / img. ETA=0:03:07\n",
            "\u001b[32m[03/06 11:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 243/878. 0.2608 s / img. ETA=0:03:02\n",
            "\u001b[32m[03/06 11:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 262/878. 0.2603 s / img. ETA=0:02:56\n",
            "\u001b[32m[03/06 11:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 280/878. 0.2601 s / img. ETA=0:02:50\n",
            "\u001b[32m[03/06 11:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 298/878. 0.2599 s / img. ETA=0:02:45\n",
            "\u001b[32m[03/06 11:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 316/878. 0.2600 s / img. ETA=0:02:40\n",
            "\u001b[32m[03/06 11:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 334/878. 0.2600 s / img. ETA=0:02:35\n",
            "\u001b[32m[03/06 11:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 352/878. 0.2600 s / img. ETA=0:02:29\n",
            "\u001b[32m[03/06 11:05:29 d2.evaluation.evaluator]: \u001b[0mInference done 370/878. 0.2599 s / img. ETA=0:02:24\n",
            "\u001b[32m[03/06 11:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 388/878. 0.2601 s / img. ETA=0:02:19\n",
            "\u001b[32m[03/06 11:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 406/878. 0.2599 s / img. ETA=0:02:14\n",
            "\u001b[32m[03/06 11:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 424/878. 0.2599 s / img. ETA=0:02:09\n",
            "\u001b[32m[03/06 11:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 442/878. 0.2598 s / img. ETA=0:02:04\n",
            "\u001b[32m[03/06 11:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 460/878. 0.2598 s / img. ETA=0:01:58\n",
            "\u001b[32m[03/06 11:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 478/878. 0.2597 s / img. ETA=0:01:53\n",
            "\u001b[32m[03/06 11:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 496/878. 0.2595 s / img. ETA=0:01:48\n",
            "\u001b[32m[03/06 11:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 514/878. 0.2597 s / img. ETA=0:01:43\n",
            "\u001b[32m[03/06 11:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 532/878. 0.2597 s / img. ETA=0:01:38\n",
            "\u001b[32m[03/06 11:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 550/878. 0.2596 s / img. ETA=0:01:33\n",
            "\u001b[32m[03/06 11:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 568/878. 0.2598 s / img. ETA=0:01:28\n",
            "\u001b[32m[03/06 11:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 587/878. 0.2597 s / img. ETA=0:01:22\n",
            "\u001b[32m[03/06 11:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 605/878. 0.2596 s / img. ETA=0:01:17\n",
            "\u001b[32m[03/06 11:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 624/878. 0.2594 s / img. ETA=0:01:12\n",
            "\u001b[32m[03/06 11:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 642/878. 0.2594 s / img. ETA=0:01:06\n",
            "\u001b[32m[03/06 11:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 660/878. 0.2592 s / img. ETA=0:01:01\n",
            "\u001b[32m[03/06 11:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 679/878. 0.2591 s / img. ETA=0:00:56\n",
            "\u001b[32m[03/06 11:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 697/878. 0.2592 s / img. ETA=0:00:51\n",
            "\u001b[32m[03/06 11:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 715/878. 0.2592 s / img. ETA=0:00:46\n",
            "\u001b[32m[03/06 11:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 733/878. 0.2592 s / img. ETA=0:00:41\n",
            "\u001b[32m[03/06 11:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 751/878. 0.2592 s / img. ETA=0:00:36\n",
            "\u001b[32m[03/06 11:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 769/878. 0.2592 s / img. ETA=0:00:30\n",
            "\u001b[32m[03/06 11:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 787/878. 0.2591 s / img. ETA=0:00:25\n",
            "\u001b[32m[03/06 11:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 805/878. 0.2590 s / img. ETA=0:00:20\n",
            "\u001b[32m[03/06 11:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 823/878. 0.2590 s / img. ETA=0:00:15\n",
            "\u001b[32m[03/06 11:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 841/878. 0.2590 s / img. ETA=0:00:10\n",
            "\u001b[32m[03/06 11:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 859/878. 0.2589 s / img. ETA=0:00:05\n",
            "\u001b[32m[03/06 11:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 877/878. 0.2588 s / img. ETA=0:00:00\n",
            "\u001b[32m[03/06 11:07:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:07.518305 (0.283526 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 11:07:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.258730 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.22s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.74 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.15 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.235\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.202\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.217\n",
            "\u001b[32m[03/06 11:07:54 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 11:07:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 11:07:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 11:07:54 d2.evaluation.testing]: \u001b[0mcopypaste: 9.7737,18.6414,23.5205,0.8847,6.6665,9.9331\n",
            "\u001b[32m[03/06 11:08:04 d2.utils.events]: \u001b[0m eta: 21:25:35  iter: 7039  total_loss: 0.4763  loss_cls: 0.1676  loss_box_reg: 0.2087  loss_rpn_cls: 0.02499  loss_rpn_loc: 0.05342  time: 1.2972  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:08:30 d2.utils.events]: \u001b[0m eta: 21:25:14  iter: 7059  total_loss: 0.6881  loss_cls: 0.2467  loss_box_reg: 0.2605  loss_rpn_cls: 0.02493  loss_rpn_loc: 0.06386  time: 1.2972  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:08:56 d2.utils.events]: \u001b[0m eta: 21:24:34  iter: 7079  total_loss: 0.5954  loss_cls: 0.2706  loss_box_reg: 0.2432  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.03751  time: 1.2972  data_time: 0.0213  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:09:22 d2.utils.events]: \u001b[0m eta: 21:23:57  iter: 7099  total_loss: 0.5594  loss_cls: 0.2404  loss_box_reg: 0.2272  loss_rpn_cls: 0.01666  loss_rpn_loc: 0.03328  time: 1.2972  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:09:48 d2.utils.events]: \u001b[0m eta: 21:22:58  iter: 7119  total_loss: 0.6534  loss_cls: 0.2808  loss_box_reg: 0.2826  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.05591  time: 1.2972  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:10:14 d2.utils.events]: \u001b[0m eta: 21:22:58  iter: 7139  total_loss: 0.5726  loss_cls: 0.2293  loss_box_reg: 0.2579  loss_rpn_cls: 0.02475  loss_rpn_loc: 0.0452  time: 1.2972  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:10:40 d2.utils.events]: \u001b[0m eta: 21:22:26  iter: 7159  total_loss: 0.6287  loss_cls: 0.2652  loss_box_reg: 0.2363  loss_rpn_cls: 0.03132  loss_rpn_loc: 0.05266  time: 1.2972  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:11:06 d2.utils.events]: \u001b[0m eta: 21:22:11  iter: 7179  total_loss: 0.6437  loss_cls: 0.2762  loss_box_reg: 0.2629  loss_rpn_cls: 0.03342  loss_rpn_loc: 0.05184  time: 1.2972  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:11:32 d2.utils.events]: \u001b[0m eta: 21:21:45  iter: 7199  total_loss: 0.655  loss_cls: 0.2944  loss_box_reg: 0.2734  loss_rpn_cls: 0.02666  loss_rpn_loc: 0.04144  time: 1.2972  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:11:58 d2.utils.events]: \u001b[0m eta: 21:21:32  iter: 7219  total_loss: 0.8896  loss_cls: 0.3734  loss_box_reg: 0.3921  loss_rpn_cls: 0.02928  loss_rpn_loc: 0.06865  time: 1.2973  data_time: 0.0175  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:12:24 d2.utils.events]: \u001b[0m eta: 21:20:18  iter: 7239  total_loss: 0.6308  loss_cls: 0.2772  loss_box_reg: 0.2713  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.03333  time: 1.2973  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:12:50 d2.utils.events]: \u001b[0m eta: 21:19:53  iter: 7259  total_loss: 0.7109  loss_cls: 0.2903  loss_box_reg: 0.341  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.04864  time: 1.2973  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:13:16 d2.utils.events]: \u001b[0m eta: 21:20:01  iter: 7279  total_loss: 0.5726  loss_cls: 0.2401  loss_box_reg: 0.2264  loss_rpn_cls: 0.02818  loss_rpn_loc: 0.05279  time: 1.2973  data_time: 0.0225  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:13:42 d2.utils.events]: \u001b[0m eta: 21:19:35  iter: 7299  total_loss: 0.7544  loss_cls: 0.3092  loss_box_reg: 0.2905  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.04536  time: 1.2973  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:14:08 d2.utils.events]: \u001b[0m eta: 21:19:17  iter: 7319  total_loss: 0.7145  loss_cls: 0.2874  loss_box_reg: 0.319  loss_rpn_cls: 0.02284  loss_rpn_loc: 0.06393  time: 1.2973  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:14:34 d2.utils.events]: \u001b[0m eta: 21:18:52  iter: 7339  total_loss: 0.7087  loss_cls: 0.3004  loss_box_reg: 0.3113  loss_rpn_cls: 0.01948  loss_rpn_loc: 0.05079  time: 1.2973  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:15:00 d2.utils.events]: \u001b[0m eta: 21:18:21  iter: 7359  total_loss: 0.7842  loss_cls: 0.3068  loss_box_reg: 0.2966  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.06065  time: 1.2973  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:15:26 d2.utils.events]: \u001b[0m eta: 21:17:58  iter: 7379  total_loss: 0.6528  loss_cls: 0.2664  loss_box_reg: 0.2497  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.04945  time: 1.2973  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:15:52 d2.utils.events]: \u001b[0m eta: 21:17:12  iter: 7399  total_loss: 0.6499  loss_cls: 0.2575  loss_box_reg: 0.2776  loss_rpn_cls: 0.02836  loss_rpn_loc: 0.0664  time: 1.2973  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:16:18 d2.utils.events]: \u001b[0m eta: 21:16:38  iter: 7419  total_loss: 0.5119  loss_cls: 0.2266  loss_box_reg: 0.2182  loss_rpn_cls: 0.02939  loss_rpn_loc: 0.04121  time: 1.2973  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:16:44 d2.utils.events]: \u001b[0m eta: 21:16:17  iter: 7439  total_loss: 0.6525  loss_cls: 0.2811  loss_box_reg: 0.257  loss_rpn_cls: 0.02602  loss_rpn_loc: 0.05717  time: 1.2973  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:17:09 d2.utils.events]: \u001b[0m eta: 21:16:09  iter: 7459  total_loss: 0.5173  loss_cls: 0.2538  loss_box_reg: 0.2036  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.03251  time: 1.2973  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:17:36 d2.utils.events]: \u001b[0m eta: 21:15:43  iter: 7479  total_loss: 0.6309  loss_cls: 0.2512  loss_box_reg: 0.2717  loss_rpn_cls: 0.0325  loss_rpn_loc: 0.0407  time: 1.2973  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:18:02 d2.utils.events]: \u001b[0m eta: 21:15:03  iter: 7499  total_loss: 0.6801  loss_cls: 0.2664  loss_box_reg: 0.2588  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.0483  time: 1.2973  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:18:27 d2.utils.events]: \u001b[0m eta: 21:14:29  iter: 7519  total_loss: 0.6619  loss_cls: 0.2942  loss_box_reg: 0.2695  loss_rpn_cls: 0.02113  loss_rpn_loc: 0.04294  time: 1.2973  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:18:53 d2.utils.events]: \u001b[0m eta: 21:13:20  iter: 7539  total_loss: 0.5395  loss_cls: 0.2324  loss_box_reg: 0.2447  loss_rpn_cls: 0.02539  loss_rpn_loc: 0.0441  time: 1.2972  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:19:19 d2.utils.events]: \u001b[0m eta: 21:12:45  iter: 7559  total_loss: 0.4733  loss_cls: 0.2026  loss_box_reg: 0.2054  loss_rpn_cls: 0.0199  loss_rpn_loc: 0.04018  time: 1.2972  data_time: 0.0240  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:19:45 d2.utils.events]: \u001b[0m eta: 21:12:26  iter: 7579  total_loss: 0.5287  loss_cls: 0.241  loss_box_reg: 0.2223  loss_rpn_cls: 0.02714  loss_rpn_loc: 0.05186  time: 1.2972  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:20:11 d2.utils.events]: \u001b[0m eta: 21:12:13  iter: 7599  total_loss: 0.6394  loss_cls: 0.2753  loss_box_reg: 0.2582  loss_rpn_cls: 0.02226  loss_rpn_loc: 0.04583  time: 1.2972  data_time: 0.0227  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:20:37 d2.utils.events]: \u001b[0m eta: 21:11:34  iter: 7619  total_loss: 0.643  loss_cls: 0.2608  loss_box_reg: 0.2676  loss_rpn_cls: 0.02494  loss_rpn_loc: 0.04123  time: 1.2972  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:21:02 d2.utils.events]: \u001b[0m eta: 21:11:03  iter: 7639  total_loss: 0.7418  loss_cls: 0.3104  loss_box_reg: 0.2851  loss_rpn_cls: 0.02861  loss_rpn_loc: 0.05771  time: 1.2972  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:21:29 d2.utils.events]: \u001b[0m eta: 21:10:55  iter: 7659  total_loss: 0.6371  loss_cls: 0.2819  loss_box_reg: 0.2536  loss_rpn_cls: 0.02396  loss_rpn_loc: 0.0587  time: 1.2972  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:21:55 d2.utils.events]: \u001b[0m eta: 21:10:37  iter: 7679  total_loss: 0.4771  loss_cls: 0.2018  loss_box_reg: 0.2394  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.02992  time: 1.2972  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:22:21 d2.utils.events]: \u001b[0m eta: 21:10:15  iter: 7699  total_loss: 0.6611  loss_cls: 0.2892  loss_box_reg: 0.2867  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.04721  time: 1.2972  data_time: 0.0209  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:22:47 d2.utils.events]: \u001b[0m eta: 21:09:56  iter: 7719  total_loss: 0.5379  loss_cls: 0.228  loss_box_reg: 0.2392  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.04506  time: 1.2972  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:23:13 d2.utils.events]: \u001b[0m eta: 21:09:19  iter: 7739  total_loss: 0.6691  loss_cls: 0.2463  loss_box_reg: 0.2685  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.04835  time: 1.2972  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:23:39 d2.utils.events]: \u001b[0m eta: 21:08:57  iter: 7759  total_loss: 0.6688  loss_cls: 0.2724  loss_box_reg: 0.2396  loss_rpn_cls: 0.02072  loss_rpn_loc: 0.05164  time: 1.2972  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:24:05 d2.utils.events]: \u001b[0m eta: 21:08:39  iter: 7779  total_loss: 0.7449  loss_cls: 0.3394  loss_box_reg: 0.3329  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.08702  time: 1.2973  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:24:31 d2.utils.events]: \u001b[0m eta: 21:08:33  iter: 7799  total_loss: 0.6918  loss_cls: 0.2629  loss_box_reg: 0.2505  loss_rpn_cls: 0.03223  loss_rpn_loc: 0.055  time: 1.2973  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:24:57 d2.utils.events]: \u001b[0m eta: 21:08:25  iter: 7819  total_loss: 0.6939  loss_cls: 0.2953  loss_box_reg: 0.2344  loss_rpn_cls: 0.03122  loss_rpn_loc: 0.05477  time: 1.2973  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:25:23 d2.utils.events]: \u001b[0m eta: 21:07:32  iter: 7839  total_loss: 0.7054  loss_cls: 0.2913  loss_box_reg: 0.2783  loss_rpn_cls: 0.0292  loss_rpn_loc: 0.04833  time: 1.2973  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:25:49 d2.utils.events]: \u001b[0m eta: 21:07:15  iter: 7859  total_loss: 0.7102  loss_cls: 0.2932  loss_box_reg: 0.2665  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.05427  time: 1.2973  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:26:15 d2.utils.events]: \u001b[0m eta: 21:06:53  iter: 7879  total_loss: 0.6575  loss_cls: 0.2505  loss_box_reg: 0.2449  loss_rpn_cls: 0.03836  loss_rpn_loc: 0.06167  time: 1.2973  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:26:41 d2.utils.events]: \u001b[0m eta: 21:06:44  iter: 7899  total_loss: 0.7792  loss_cls: 0.3189  loss_box_reg: 0.3344  loss_rpn_cls: 0.02856  loss_rpn_loc: 0.0783  time: 1.2974  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:27:07 d2.utils.events]: \u001b[0m eta: 21:06:22  iter: 7919  total_loss: 0.5852  loss_cls: 0.2328  loss_box_reg: 0.255  loss_rpn_cls: 0.02495  loss_rpn_loc: 0.04813  time: 1.2974  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:27:34 d2.utils.events]: \u001b[0m eta: 21:06:32  iter: 7939  total_loss: 0.5431  loss_cls: 0.2486  loss_box_reg: 0.2313  loss_rpn_cls: 0.02399  loss_rpn_loc: 0.04502  time: 1.2974  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:28:00 d2.utils.events]: \u001b[0m eta: 21:05:32  iter: 7959  total_loss: 0.6312  loss_cls: 0.2489  loss_box_reg: 0.2192  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.04546  time: 1.2974  data_time: 0.0209  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:28:25 d2.utils.events]: \u001b[0m eta: 21:04:53  iter: 7979  total_loss: 0.627  loss_cls: 0.2814  loss_box_reg: 0.2237  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.04429  time: 1.2974  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:28:51 d2.utils.events]: \u001b[0m eta: 21:04:41  iter: 7999  total_loss: 0.7279  loss_cls: 0.2931  loss_box_reg: 0.2888  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.065  time: 1.2974  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:29:17 d2.utils.events]: \u001b[0m eta: 21:04:49  iter: 8019  total_loss: 0.5794  loss_cls: 0.2139  loss_box_reg: 0.2193  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.06581  time: 1.2974  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:29:43 d2.utils.events]: \u001b[0m eta: 21:04:26  iter: 8039  total_loss: 0.5368  loss_cls: 0.2504  loss_box_reg: 0.2073  loss_rpn_cls: 0.02002  loss_rpn_loc: 0.04787  time: 1.2973  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:30:09 d2.utils.events]: \u001b[0m eta: 21:03:53  iter: 8059  total_loss: 0.7226  loss_cls: 0.3138  loss_box_reg: 0.3319  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.04749  time: 1.2973  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:30:35 d2.utils.events]: \u001b[0m eta: 21:03:32  iter: 8079  total_loss: 0.7344  loss_cls: 0.3066  loss_box_reg: 0.278  loss_rpn_cls: 0.02514  loss_rpn_loc: 0.03823  time: 1.2973  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:31:01 d2.utils.events]: \u001b[0m eta: 21:03:02  iter: 8099  total_loss: 0.7274  loss_cls: 0.2902  loss_box_reg: 0.2849  loss_rpn_cls: 0.03048  loss_rpn_loc: 0.06026  time: 1.2973  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:31:27 d2.utils.events]: \u001b[0m eta: 21:02:43  iter: 8119  total_loss: 0.5447  loss_cls: 0.2216  loss_box_reg: 0.2571  loss_rpn_cls: 0.018  loss_rpn_loc: 0.0491  time: 1.2973  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:31:53 d2.utils.events]: \u001b[0m eta: 21:01:42  iter: 8139  total_loss: 0.7202  loss_cls: 0.32  loss_box_reg: 0.2757  loss_rpn_cls: 0.03449  loss_rpn_loc: 0.05934  time: 1.2973  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:32:19 d2.utils.events]: \u001b[0m eta: 21:01:09  iter: 8159  total_loss: 0.5546  loss_cls: 0.2356  loss_box_reg: 0.2389  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.06374  time: 1.2973  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:32:45 d2.utils.events]: \u001b[0m eta: 21:00:22  iter: 8179  total_loss: 0.5924  loss_cls: 0.2675  loss_box_reg: 0.2323  loss_rpn_cls: 0.02181  loss_rpn_loc: 0.0369  time: 1.2973  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:33:11 d2.utils.events]: \u001b[0m eta: 21:00:17  iter: 8199  total_loss: 0.6163  loss_cls: 0.2365  loss_box_reg: 0.2317  loss_rpn_cls: 0.02433  loss_rpn_loc: 0.04268  time: 1.2973  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:33:37 d2.utils.events]: \u001b[0m eta: 20:59:42  iter: 8219  total_loss: 0.531  loss_cls: 0.2498  loss_box_reg: 0.2086  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.04302  time: 1.2974  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:34:03 d2.utils.events]: \u001b[0m eta: 20:59:48  iter: 8239  total_loss: 0.5396  loss_cls: 0.2156  loss_box_reg: 0.2237  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.05215  time: 1.2974  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:34:29 d2.utils.events]: \u001b[0m eta: 20:59:54  iter: 8259  total_loss: 0.6331  loss_cls: 0.2774  loss_box_reg: 0.2862  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.0479  time: 1.2974  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:34:55 d2.utils.events]: \u001b[0m eta: 20:58:57  iter: 8279  total_loss: 0.6283  loss_cls: 0.2492  loss_box_reg: 0.2356  loss_rpn_cls: 0.02192  loss_rpn_loc: 0.04599  time: 1.2974  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:35:21 d2.utils.events]: \u001b[0m eta: 20:58:49  iter: 8299  total_loss: 0.5526  loss_cls: 0.2451  loss_box_reg: 0.2206  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.04518  time: 1.2974  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:35:47 d2.utils.events]: \u001b[0m eta: 20:57:52  iter: 8319  total_loss: 0.7193  loss_cls: 0.3412  loss_box_reg: 0.3023  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.05477  time: 1.2974  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:36:13 d2.utils.events]: \u001b[0m eta: 20:57:17  iter: 8339  total_loss: 0.6325  loss_cls: 0.2777  loss_box_reg: 0.2995  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.04483  time: 1.2974  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:36:39 d2.utils.events]: \u001b[0m eta: 20:56:38  iter: 8359  total_loss: 0.6991  loss_cls: 0.3077  loss_box_reg: 0.2708  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.04887  time: 1.2974  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:37:05 d2.utils.events]: \u001b[0m eta: 20:56:12  iter: 8379  total_loss: 0.8341  loss_cls: 0.349  loss_box_reg: 0.3064  loss_rpn_cls: 0.03484  loss_rpn_loc: 0.1047  time: 1.2974  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:37:31 d2.utils.events]: \u001b[0m eta: 20:56:40  iter: 8399  total_loss: 0.6198  loss_cls: 0.2448  loss_box_reg: 0.2571  loss_rpn_cls: 0.03541  loss_rpn_loc: 0.05338  time: 1.2974  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:37:57 d2.utils.events]: \u001b[0m eta: 20:55:58  iter: 8419  total_loss: 0.6145  loss_cls: 0.2708  loss_box_reg: 0.2491  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.05002  time: 1.2974  data_time: 0.0177  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:38:23 d2.utils.events]: \u001b[0m eta: 20:55:16  iter: 8439  total_loss: 0.5679  loss_cls: 0.2501  loss_box_reg: 0.2584  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.05306  time: 1.2974  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:38:49 d2.utils.events]: \u001b[0m eta: 20:54:51  iter: 8459  total_loss: 0.559  loss_cls: 0.2339  loss_box_reg: 0.2528  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.03528  time: 1.2974  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:39:15 d2.utils.events]: \u001b[0m eta: 20:54:24  iter: 8479  total_loss: 0.6067  loss_cls: 0.2491  loss_box_reg: 0.2375  loss_rpn_cls: 0.02225  loss_rpn_loc: 0.03825  time: 1.2975  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:39:41 d2.utils.events]: \u001b[0m eta: 20:53:58  iter: 8499  total_loss: 0.656  loss_cls: 0.2785  loss_box_reg: 0.3098  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.04352  time: 1.2974  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:40:07 d2.utils.events]: \u001b[0m eta: 20:53:28  iter: 8519  total_loss: 0.5921  loss_cls: 0.2442  loss_box_reg: 0.2293  loss_rpn_cls: 0.02182  loss_rpn_loc: 0.04674  time: 1.2974  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:40:33 d2.utils.events]: \u001b[0m eta: 20:53:39  iter: 8539  total_loss: 0.5315  loss_cls: 0.2166  loss_box_reg: 0.2131  loss_rpn_cls: 0.0199  loss_rpn_loc: 0.04108  time: 1.2974  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:40:58 d2.utils.events]: \u001b[0m eta: 20:52:57  iter: 8559  total_loss: 0.6867  loss_cls: 0.2768  loss_box_reg: 0.2721  loss_rpn_cls: 0.02111  loss_rpn_loc: 0.05968  time: 1.2974  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:41:24 d2.utils.events]: \u001b[0m eta: 20:52:56  iter: 8579  total_loss: 0.511  loss_cls: 0.2355  loss_box_reg: 0.2169  loss_rpn_cls: 0.02429  loss_rpn_loc: 0.03244  time: 1.2974  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:41:51 d2.utils.events]: \u001b[0m eta: 20:52:46  iter: 8599  total_loss: 0.7408  loss_cls: 0.3354  loss_box_reg: 0.2934  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.04595  time: 1.2974  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:42:17 d2.utils.events]: \u001b[0m eta: 20:52:21  iter: 8619  total_loss: 0.662  loss_cls: 0.2407  loss_box_reg: 0.2816  loss_rpn_cls: 0.02427  loss_rpn_loc: 0.0417  time: 1.2974  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:42:43 d2.utils.events]: \u001b[0m eta: 20:52:40  iter: 8639  total_loss: 0.5328  loss_cls: 0.2331  loss_box_reg: 0.2357  loss_rpn_cls: 0.02469  loss_rpn_loc: 0.0395  time: 1.2975  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:43:09 d2.utils.events]: \u001b[0m eta: 20:52:21  iter: 8659  total_loss: 0.7493  loss_cls: 0.2657  loss_box_reg: 0.2794  loss_rpn_cls: 0.03232  loss_rpn_loc: 0.07989  time: 1.2975  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:43:35 d2.utils.events]: \u001b[0m eta: 20:51:48  iter: 8679  total_loss: 0.4793  loss_cls: 0.1916  loss_box_reg: 0.2408  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.03454  time: 1.2975  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:44:01 d2.utils.events]: \u001b[0m eta: 20:51:04  iter: 8699  total_loss: 0.4689  loss_cls: 0.1965  loss_box_reg: 0.2006  loss_rpn_cls: 0.02375  loss_rpn_loc: 0.04133  time: 1.2975  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:44:27 d2.utils.events]: \u001b[0m eta: 20:51:11  iter: 8719  total_loss: 0.645  loss_cls: 0.2943  loss_box_reg: 0.2585  loss_rpn_cls: 0.02657  loss_rpn_loc: 0.05505  time: 1.2975  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:44:53 d2.utils.events]: \u001b[0m eta: 20:50:49  iter: 8739  total_loss: 0.6359  loss_cls: 0.2805  loss_box_reg: 0.2613  loss_rpn_cls: 0.02724  loss_rpn_loc: 0.05171  time: 1.2975  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:45:19 d2.utils.events]: \u001b[0m eta: 20:50:19  iter: 8759  total_loss: 0.5856  loss_cls: 0.2341  loss_box_reg: 0.2568  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.04544  time: 1.2975  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:45:45 d2.utils.events]: \u001b[0m eta: 20:49:53  iter: 8779  total_loss: 0.6805  loss_cls: 0.288  loss_box_reg: 0.2572  loss_rpn_cls: 0.02968  loss_rpn_loc: 0.04551  time: 1.2975  data_time: 0.0219  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 700.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 11:46:02 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 11:46:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 11:46:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 11:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2724 s / img. ETA=0:04:30\n",
            "\u001b[32m[03/06 11:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2674 s / img. ETA=0:04:15\n",
            "\u001b[32m[03/06 11:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2668 s / img. ETA=0:04:08\n",
            "\u001b[32m[03/06 11:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2649 s / img. ETA=0:04:00\n",
            "\u001b[32m[03/06 11:46:27 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2629 s / img. ETA=0:03:53\n",
            "\u001b[32m[03/06 11:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2626 s / img. ETA=0:03:47\n",
            "\u001b[32m[03/06 11:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 118/878. 0.2614 s / img. ETA=0:03:40\n",
            "\u001b[32m[03/06 11:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 136/878. 0.2617 s / img. ETA=0:03:34\n",
            "\u001b[32m[03/06 11:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 154/878. 0.2608 s / img. ETA=0:03:28\n",
            "\u001b[32m[03/06 11:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 172/878. 0.2604 s / img. ETA=0:03:23\n",
            "\u001b[32m[03/06 11:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 190/878. 0.2602 s / img. ETA=0:03:18\n",
            "\u001b[32m[03/06 11:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 208/878. 0.2600 s / img. ETA=0:03:12\n",
            "\u001b[32m[03/06 11:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 226/878. 0.2599 s / img. ETA=0:03:06\n",
            "\u001b[32m[03/06 11:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 244/878. 0.2598 s / img. ETA=0:03:01\n",
            "\u001b[32m[03/06 11:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 262/878. 0.2600 s / img. ETA=0:02:56\n",
            "\u001b[32m[03/06 11:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 280/878. 0.2598 s / img. ETA=0:02:50\n",
            "\u001b[32m[03/06 11:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 298/878. 0.2601 s / img. ETA=0:02:45\n",
            "\u001b[32m[03/06 11:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 316/878. 0.2600 s / img. ETA=0:02:40\n",
            "\u001b[32m[03/06 11:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 334/878. 0.2597 s / img. ETA=0:02:35\n",
            "\u001b[32m[03/06 11:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 352/878. 0.2596 s / img. ETA=0:02:30\n",
            "\u001b[32m[03/06 11:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 370/878. 0.2596 s / img. ETA=0:02:25\n",
            "\u001b[32m[03/06 11:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 388/878. 0.2599 s / img. ETA=0:02:20\n",
            "\u001b[32m[03/06 11:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 406/878. 0.2601 s / img. ETA=0:02:14\n",
            "\u001b[32m[03/06 11:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 424/878. 0.2600 s / img. ETA=0:02:09\n",
            "\u001b[32m[03/06 11:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 442/878. 0.2599 s / img. ETA=0:02:04\n",
            "\u001b[32m[03/06 11:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 460/878. 0.2599 s / img. ETA=0:01:59\n",
            "\u001b[32m[03/06 11:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 479/878. 0.2597 s / img. ETA=0:01:53\n",
            "\u001b[32m[03/06 11:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 498/878. 0.2595 s / img. ETA=0:01:48\n",
            "\u001b[32m[03/06 11:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 516/878. 0.2597 s / img. ETA=0:01:43\n",
            "\u001b[32m[03/06 11:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 534/878. 0.2598 s / img. ETA=0:01:38\n",
            "\u001b[32m[03/06 11:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 552/878. 0.2598 s / img. ETA=0:01:33\n",
            "\u001b[32m[03/06 11:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 570/878. 0.2599 s / img. ETA=0:01:27\n",
            "\u001b[32m[03/06 11:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 588/878. 0.2599 s / img. ETA=0:01:22\n",
            "\u001b[32m[03/06 11:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 606/878. 0.2597 s / img. ETA=0:01:17\n",
            "\u001b[32m[03/06 11:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 624/878. 0.2597 s / img. ETA=0:01:12\n",
            "\u001b[32m[03/06 11:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 642/878. 0.2597 s / img. ETA=0:01:07\n",
            "\u001b[32m[03/06 11:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 660/878. 0.2596 s / img. ETA=0:01:02\n",
            "\u001b[32m[03/06 11:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 678/878. 0.2597 s / img. ETA=0:00:56\n",
            "\u001b[32m[03/06 11:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 696/878. 0.2597 s / img. ETA=0:00:51\n",
            "\u001b[32m[03/06 11:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 714/878. 0.2596 s / img. ETA=0:00:46\n",
            "\u001b[32m[03/06 11:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 732/878. 0.2596 s / img. ETA=0:00:41\n",
            "\u001b[32m[03/06 11:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 750/878. 0.2596 s / img. ETA=0:00:36\n",
            "\u001b[32m[03/06 11:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 768/878. 0.2596 s / img. ETA=0:00:31\n",
            "\u001b[32m[03/06 11:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 786/878. 0.2596 s / img. ETA=0:00:26\n",
            "\u001b[32m[03/06 11:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 804/878. 0.2595 s / img. ETA=0:00:21\n",
            "\u001b[32m[03/06 11:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 823/878. 0.2595 s / img. ETA=0:00:15\n",
            "\u001b[32m[03/06 11:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 841/878. 0.2594 s / img. ETA=0:00:10\n",
            "\u001b[32m[03/06 11:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 859/878. 0.2595 s / img. ETA=0:00:05\n",
            "\u001b[32m[03/06 11:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 877/878. 0.2594 s / img. ETA=0:00:00\n",
            "\u001b[32m[03/06 11:50:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:08.575616 (0.284737 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 11:50:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:46 (0.259329 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.23s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 1.10 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.16 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.261\n",
            "\u001b[32m[03/06 11:50:15 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 11:50:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 11:50:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 11:50:15 d2.evaluation.testing]: \u001b[0mcopypaste: 10.2910,19.1228,24.9960,1.0487,5.9162,10.5369\n",
            "\u001b[32m[03/06 11:50:28 d2.utils.events]: \u001b[0m eta: 20:48:30  iter: 8799  total_loss: 0.4293  loss_cls: 0.1824  loss_box_reg: 0.2077  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.03236  time: 1.2975  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:50:54 d2.utils.events]: \u001b[0m eta: 20:48:04  iter: 8819  total_loss: 0.6571  loss_cls: 0.2549  loss_box_reg: 0.2681  loss_rpn_cls: 0.02697  loss_rpn_loc: 0.06406  time: 1.2975  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:51:20 d2.utils.events]: \u001b[0m eta: 20:47:50  iter: 8839  total_loss: 0.5086  loss_cls: 0.2022  loss_box_reg: 0.185  loss_rpn_cls: 0.0225  loss_rpn_loc: 0.04143  time: 1.2975  data_time: 0.0250  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:51:46 d2.utils.events]: \u001b[0m eta: 20:47:08  iter: 8859  total_loss: 0.5618  loss_cls: 0.2543  loss_box_reg: 0.2447  loss_rpn_cls: 0.02458  loss_rpn_loc: 0.06311  time: 1.2975  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:52:12 d2.utils.events]: \u001b[0m eta: 20:46:46  iter: 8879  total_loss: 0.548  loss_cls: 0.2314  loss_box_reg: 0.2358  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.04695  time: 1.2975  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:52:39 d2.utils.events]: \u001b[0m eta: 20:46:20  iter: 8899  total_loss: 0.5315  loss_cls: 0.2445  loss_box_reg: 0.2439  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.04715  time: 1.2976  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:53:04 d2.utils.events]: \u001b[0m eta: 20:45:56  iter: 8919  total_loss: 0.5951  loss_cls: 0.2628  loss_box_reg: 0.2621  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.03611  time: 1.2975  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:53:30 d2.utils.events]: \u001b[0m eta: 20:45:20  iter: 8939  total_loss: 0.6336  loss_cls: 0.2378  loss_box_reg: 0.2742  loss_rpn_cls: 0.02772  loss_rpn_loc: 0.06803  time: 1.2976  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:53:56 d2.utils.events]: \u001b[0m eta: 20:44:54  iter: 8959  total_loss: 0.5955  loss_cls: 0.2415  loss_box_reg: 0.2759  loss_rpn_cls: 0.02383  loss_rpn_loc: 0.04714  time: 1.2975  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:54:22 d2.utils.events]: \u001b[0m eta: 20:45:17  iter: 8979  total_loss: 0.5769  loss_cls: 0.2223  loss_box_reg: 0.241  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.04124  time: 1.2976  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:54:48 d2.utils.events]: \u001b[0m eta: 20:45:07  iter: 8999  total_loss: 0.7386  loss_cls: 0.2933  loss_box_reg: 0.2839  loss_rpn_cls: 0.02339  loss_rpn_loc: 0.06398  time: 1.2976  data_time: 0.0214  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:55:14 d2.utils.events]: \u001b[0m eta: 20:43:48  iter: 9019  total_loss: 0.707  loss_cls: 0.2732  loss_box_reg: 0.2606  loss_rpn_cls: 0.03402  loss_rpn_loc: 0.07021  time: 1.2976  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:55:40 d2.utils.events]: \u001b[0m eta: 20:43:22  iter: 9039  total_loss: 0.6014  loss_cls: 0.2662  loss_box_reg: 0.2258  loss_rpn_cls: 0.02425  loss_rpn_loc: 0.05342  time: 1.2975  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:56:06 d2.utils.events]: \u001b[0m eta: 20:43:40  iter: 9059  total_loss: 0.7227  loss_cls: 0.2918  loss_box_reg: 0.2901  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.03999  time: 1.2975  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:56:32 d2.utils.events]: \u001b[0m eta: 20:42:31  iter: 9079  total_loss: 0.6913  loss_cls: 0.3168  loss_box_reg: 0.28  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.05207  time: 1.2975  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:56:58 d2.utils.events]: \u001b[0m eta: 20:42:59  iter: 9099  total_loss: 0.8157  loss_cls: 0.381  loss_box_reg: 0.3609  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.06879  time: 1.2976  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:57:24 d2.utils.events]: \u001b[0m eta: 20:42:34  iter: 9119  total_loss: 0.5839  loss_cls: 0.252  loss_box_reg: 0.247  loss_rpn_cls: 0.023  loss_rpn_loc: 0.04455  time: 1.2976  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:57:50 d2.utils.events]: \u001b[0m eta: 20:42:24  iter: 9139  total_loss: 0.4565  loss_cls: 0.1912  loss_box_reg: 0.207  loss_rpn_cls: 0.02137  loss_rpn_loc: 0.04697  time: 1.2976  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:58:16 d2.utils.events]: \u001b[0m eta: 20:41:46  iter: 9159  total_loss: 0.8407  loss_cls: 0.3493  loss_box_reg: 0.3704  loss_rpn_cls: 0.0271  loss_rpn_loc: 0.06205  time: 1.2975  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:58:42 d2.utils.events]: \u001b[0m eta: 20:41:42  iter: 9179  total_loss: 0.5924  loss_cls: 0.2699  loss_box_reg: 0.2369  loss_rpn_cls: 0.02776  loss_rpn_loc: 0.08688  time: 1.2976  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:59:08 d2.utils.events]: \u001b[0m eta: 20:40:50  iter: 9199  total_loss: 0.5881  loss_cls: 0.2142  loss_box_reg: 0.2299  loss_rpn_cls: 0.02851  loss_rpn_loc: 0.05177  time: 1.2976  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 11:59:34 d2.utils.events]: \u001b[0m eta: 20:40:27  iter: 9219  total_loss: 0.4651  loss_cls: 0.2123  loss_box_reg: 0.1953  loss_rpn_cls: 0.0223  loss_rpn_loc: 0.05311  time: 1.2976  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:00:00 d2.utils.events]: \u001b[0m eta: 20:39:59  iter: 9239  total_loss: 0.5278  loss_cls: 0.2093  loss_box_reg: 0.2071  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.04485  time: 1.2976  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:00:26 d2.utils.events]: \u001b[0m eta: 20:39:22  iter: 9259  total_loss: 0.552  loss_cls: 0.2444  loss_box_reg: 0.2487  loss_rpn_cls: 0.02554  loss_rpn_loc: 0.04417  time: 1.2976  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:00:53 d2.utils.events]: \u001b[0m eta: 20:39:07  iter: 9279  total_loss: 0.5542  loss_cls: 0.2333  loss_box_reg: 0.2525  loss_rpn_cls: 0.02618  loss_rpn_loc: 0.05791  time: 1.2976  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:01:18 d2.utils.events]: \u001b[0m eta: 20:38:11  iter: 9299  total_loss: 0.5753  loss_cls: 0.2216  loss_box_reg: 0.2235  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.04064  time: 1.2976  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:01:45 d2.utils.events]: \u001b[0m eta: 20:38:15  iter: 9319  total_loss: 0.5214  loss_cls: 0.1999  loss_box_reg: 0.2449  loss_rpn_cls: 0.02209  loss_rpn_loc: 0.05619  time: 1.2976  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:02:11 d2.utils.events]: \u001b[0m eta: 20:37:56  iter: 9339  total_loss: 0.458  loss_cls: 0.2228  loss_box_reg: 0.2106  loss_rpn_cls: 0.02175  loss_rpn_loc: 0.0381  time: 1.2977  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:02:37 d2.utils.events]: \u001b[0m eta: 20:37:26  iter: 9359  total_loss: 0.6616  loss_cls: 0.3065  loss_box_reg: 0.274  loss_rpn_cls: 0.02493  loss_rpn_loc: 0.04291  time: 1.2977  data_time: 0.0209  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:03:03 d2.utils.events]: \u001b[0m eta: 20:37:01  iter: 9379  total_loss: 0.6083  loss_cls: 0.2532  loss_box_reg: 0.2251  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.04809  time: 1.2977  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:03:29 d2.utils.events]: \u001b[0m eta: 20:36:23  iter: 9399  total_loss: 0.72  loss_cls: 0.3216  loss_box_reg: 0.3038  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.04689  time: 1.2977  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:03:55 d2.utils.events]: \u001b[0m eta: 20:36:23  iter: 9419  total_loss: 0.5564  loss_cls: 0.2635  loss_box_reg: 0.2443  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.04108  time: 1.2977  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:04:21 d2.utils.events]: \u001b[0m eta: 20:36:40  iter: 9439  total_loss: 0.6857  loss_cls: 0.3073  loss_box_reg: 0.2797  loss_rpn_cls: 0.02048  loss_rpn_loc: 0.05793  time: 1.2977  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:04:47 d2.utils.events]: \u001b[0m eta: 20:36:15  iter: 9459  total_loss: 0.5835  loss_cls: 0.2586  loss_box_reg: 0.2014  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.03357  time: 1.2977  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:05:13 d2.utils.events]: \u001b[0m eta: 20:35:26  iter: 9479  total_loss: 0.5876  loss_cls: 0.2349  loss_box_reg: 0.2518  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.04295  time: 1.2977  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:05:39 d2.utils.events]: \u001b[0m eta: 20:35:25  iter: 9499  total_loss: 0.7267  loss_cls: 0.2839  loss_box_reg: 0.2949  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.0551  time: 1.2977  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:06:05 d2.utils.events]: \u001b[0m eta: 20:35:17  iter: 9519  total_loss: 0.6086  loss_cls: 0.2542  loss_box_reg: 0.2753  loss_rpn_cls: 0.0291  loss_rpn_loc: 0.03442  time: 1.2977  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:06:30 d2.utils.events]: \u001b[0m eta: 20:34:38  iter: 9539  total_loss: 0.5019  loss_cls: 0.1812  loss_box_reg: 0.2139  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.03789  time: 1.2977  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:06:56 d2.utils.events]: \u001b[0m eta: 20:34:17  iter: 9559  total_loss: 0.6157  loss_cls: 0.267  loss_box_reg: 0.2608  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.04661  time: 1.2976  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:07:22 d2.utils.events]: \u001b[0m eta: 20:34:07  iter: 9579  total_loss: 0.562  loss_cls: 0.2257  loss_box_reg: 0.2513  loss_rpn_cls: 0.02353  loss_rpn_loc: 0.06408  time: 1.2977  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:07:48 d2.utils.events]: \u001b[0m eta: 20:33:17  iter: 9599  total_loss: 0.5747  loss_cls: 0.2429  loss_box_reg: 0.2671  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.05095  time: 1.2977  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:08:14 d2.utils.events]: \u001b[0m eta: 20:32:48  iter: 9619  total_loss: 0.5087  loss_cls: 0.2257  loss_box_reg: 0.2534  loss_rpn_cls: 0.02167  loss_rpn_loc: 0.04141  time: 1.2977  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:08:41 d2.utils.events]: \u001b[0m eta: 20:32:21  iter: 9639  total_loss: 0.6357  loss_cls: 0.2941  loss_box_reg: 0.2834  loss_rpn_cls: 0.02169  loss_rpn_loc: 0.05577  time: 1.2977  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:09:07 d2.utils.events]: \u001b[0m eta: 20:31:49  iter: 9659  total_loss: 0.7323  loss_cls: 0.3143  loss_box_reg: 0.2921  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.04998  time: 1.2977  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:09:33 d2.utils.events]: \u001b[0m eta: 20:30:22  iter: 9679  total_loss: 0.78  loss_cls: 0.3058  loss_box_reg: 0.3523  loss_rpn_cls: 0.02555  loss_rpn_loc: 0.05496  time: 1.2977  data_time: 0.0257  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:09:58 d2.utils.events]: \u001b[0m eta: 20:29:56  iter: 9699  total_loss: 0.5721  loss_cls: 0.2651  loss_box_reg: 0.2337  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.04312  time: 1.2977  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:10:24 d2.utils.events]: \u001b[0m eta: 20:29:12  iter: 9719  total_loss: 0.6702  loss_cls: 0.2761  loss_box_reg: 0.3247  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.04488  time: 1.2977  data_time: 0.0176  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:10:50 d2.utils.events]: \u001b[0m eta: 20:28:14  iter: 9739  total_loss: 0.7456  loss_cls: 0.2981  loss_box_reg: 0.3391  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.04962  time: 1.2977  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:11:16 d2.utils.events]: \u001b[0m eta: 20:27:48  iter: 9759  total_loss: 0.6073  loss_cls: 0.252  loss_box_reg: 0.2575  loss_rpn_cls: 0.02136  loss_rpn_loc: 0.04399  time: 1.2977  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:11:42 d2.utils.events]: \u001b[0m eta: 20:27:08  iter: 9779  total_loss: 0.594  loss_cls: 0.2335  loss_box_reg: 0.2914  loss_rpn_cls: 0.02079  loss_rpn_loc: 0.05629  time: 1.2977  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:12:08 d2.utils.events]: \u001b[0m eta: 20:27:29  iter: 9799  total_loss: 0.4583  loss_cls: 0.2377  loss_box_reg: 0.2288  loss_rpn_cls: 0.01906  loss_rpn_loc: 0.04732  time: 1.2977  data_time: 0.0230  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:12:34 d2.utils.events]: \u001b[0m eta: 20:26:54  iter: 9819  total_loss: 0.5428  loss_cls: 0.2346  loss_box_reg: 0.2343  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.05133  time: 1.2977  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:13:00 d2.utils.events]: \u001b[0m eta: 20:25:45  iter: 9839  total_loss: 0.5668  loss_cls: 0.2467  loss_box_reg: 0.2548  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.03919  time: 1.2976  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:13:26 d2.utils.events]: \u001b[0m eta: 20:25:54  iter: 9859  total_loss: 0.5411  loss_cls: 0.2098  loss_box_reg: 0.2096  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.04431  time: 1.2976  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:13:52 d2.utils.events]: \u001b[0m eta: 20:25:28  iter: 9879  total_loss: 0.4819  loss_cls: 0.2012  loss_box_reg: 0.2159  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.04435  time: 1.2977  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:14:18 d2.utils.events]: \u001b[0m eta: 20:25:02  iter: 9899  total_loss: 0.6539  loss_cls: 0.269  loss_box_reg: 0.2617  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.05826  time: 1.2977  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:14:44 d2.utils.events]: \u001b[0m eta: 20:24:45  iter: 9919  total_loss: 0.6382  loss_cls: 0.2534  loss_box_reg: 0.2645  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.03775  time: 1.2977  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:15:10 d2.utils.events]: \u001b[0m eta: 20:24:19  iter: 9939  total_loss: 0.7312  loss_cls: 0.3104  loss_box_reg: 0.3058  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.04981  time: 1.2977  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:15:36 d2.utils.events]: \u001b[0m eta: 20:23:52  iter: 9959  total_loss: 0.5572  loss_cls: 0.2344  loss_box_reg: 0.2078  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.04745  time: 1.2977  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:16:02 d2.utils.events]: \u001b[0m eta: 20:23:18  iter: 9979  total_loss: 0.5014  loss_cls: 0.2046  loss_box_reg: 0.2253  loss_rpn_cls: 0.02427  loss_rpn_loc: 0.04658  time: 1.2977  data_time: 0.0179  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:16:28 d2.utils.events]: \u001b[0m eta: 20:22:58  iter: 9999  total_loss: 0.7955  loss_cls: 0.3602  loss_box_reg: 0.2838  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.05752  time: 1.2977  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:16:54 d2.utils.events]: \u001b[0m eta: 20:22:08  iter: 10019  total_loss: 0.7889  loss_cls: 0.3152  loss_box_reg: 0.3054  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.04755  time: 1.2976  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:17:20 d2.utils.events]: \u001b[0m eta: 20:21:24  iter: 10039  total_loss: 0.7096  loss_cls: 0.2796  loss_box_reg: 0.3081  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.03896  time: 1.2976  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:17:46 d2.utils.events]: \u001b[0m eta: 20:20:58  iter: 10059  total_loss: 0.5872  loss_cls: 0.2528  loss_box_reg: 0.2608  loss_rpn_cls: 0.02723  loss_rpn_loc: 0.05161  time: 1.2976  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:18:11 d2.utils.events]: \u001b[0m eta: 20:20:32  iter: 10079  total_loss: 0.723  loss_cls: 0.3266  loss_box_reg: 0.2793  loss_rpn_cls: 0.03186  loss_rpn_loc: 0.04314  time: 1.2976  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:18:38 d2.utils.events]: \u001b[0m eta: 20:20:04  iter: 10099  total_loss: 0.5895  loss_cls: 0.2476  loss_box_reg: 0.2395  loss_rpn_cls: 0.0221  loss_rpn_loc: 0.04652  time: 1.2977  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:19:04 d2.utils.events]: \u001b[0m eta: 20:20:14  iter: 10119  total_loss: 0.616  loss_cls: 0.3025  loss_box_reg: 0.2618  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.04956  time: 1.2977  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:19:30 d2.utils.events]: \u001b[0m eta: 20:19:48  iter: 10139  total_loss: 0.6833  loss_cls: 0.3086  loss_box_reg: 0.2952  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.04495  time: 1.2977  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:19:56 d2.utils.events]: \u001b[0m eta: 20:19:37  iter: 10159  total_loss: 0.7868  loss_cls: 0.2981  loss_box_reg: 0.3037  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.06781  time: 1.2977  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:20:22 d2.utils.events]: \u001b[0m eta: 20:19:17  iter: 10179  total_loss: 0.5876  loss_cls: 0.2722  loss_box_reg: 0.2543  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.04995  time: 1.2977  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:20:48 d2.utils.events]: \u001b[0m eta: 20:19:03  iter: 10199  total_loss: 0.8088  loss_cls: 0.3599  loss_box_reg: 0.3751  loss_rpn_cls: 0.02727  loss_rpn_loc: 0.08289  time: 1.2977  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:21:14 d2.utils.events]: \u001b[0m eta: 20:18:35  iter: 10219  total_loss: 0.6161  loss_cls: 0.2478  loss_box_reg: 0.2478  loss_rpn_cls: 0.02647  loss_rpn_loc: 0.03935  time: 1.2978  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:21:40 d2.utils.events]: \u001b[0m eta: 20:18:05  iter: 10239  total_loss: 0.5139  loss_cls: 0.1947  loss_box_reg: 0.2191  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.04979  time: 1.2978  data_time: 0.0216  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:22:06 d2.utils.events]: \u001b[0m eta: 20:17:45  iter: 10259  total_loss: 0.7303  loss_cls: 0.2775  loss_box_reg: 0.3033  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.05099  time: 1.2978  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:22:32 d2.utils.events]: \u001b[0m eta: 20:17:20  iter: 10279  total_loss: 0.6591  loss_cls: 0.3272  loss_box_reg: 0.2604  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.04848  time: 1.2978  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:22:58 d2.utils.events]: \u001b[0m eta: 20:17:06  iter: 10299  total_loss: 0.7281  loss_cls: 0.3055  loss_box_reg: 0.3218  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.05654  time: 1.2978  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:23:25 d2.utils.events]: \u001b[0m eta: 20:16:40  iter: 10319  total_loss: 0.6231  loss_cls: 0.2178  loss_box_reg: 0.2772  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.06404  time: 1.2978  data_time: 0.0219  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:23:51 d2.utils.events]: \u001b[0m eta: 20:16:11  iter: 10339  total_loss: 0.5649  loss_cls: 0.2278  loss_box_reg: 0.2659  loss_rpn_cls: 0.03009  loss_rpn_loc: 0.03431  time: 1.2978  data_time: 0.0178  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:24:16 d2.utils.events]: \u001b[0m eta: 20:15:34  iter: 10359  total_loss: 0.6103  loss_cls: 0.2506  loss_box_reg: 0.2544  loss_rpn_cls: 0.02222  loss_rpn_loc: 0.05521  time: 1.2978  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:24:42 d2.utils.events]: \u001b[0m eta: 20:14:59  iter: 10379  total_loss: 0.6267  loss_cls: 0.2772  loss_box_reg: 0.2786  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.04747  time: 1.2978  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:25:08 d2.utils.events]: \u001b[0m eta: 20:14:28  iter: 10399  total_loss: 0.5795  loss_cls: 0.2286  loss_box_reg: 0.2168  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.04478  time: 1.2978  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:25:34 d2.utils.events]: \u001b[0m eta: 20:14:03  iter: 10419  total_loss: 0.4639  loss_cls: 0.1955  loss_box_reg: 0.2304  loss_rpn_cls: 0.0223  loss_rpn_loc: 0.0443  time: 1.2978  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:26:01 d2.utils.events]: \u001b[0m eta: 20:13:38  iter: 10439  total_loss: 0.6044  loss_cls: 0.2656  loss_box_reg: 0.261  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.04265  time: 1.2978  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:26:27 d2.utils.events]: \u001b[0m eta: 20:13:15  iter: 10459  total_loss: 0.4577  loss_cls: 0.2037  loss_box_reg: 0.1898  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.04125  time: 1.2978  data_time: 0.0209  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:26:53 d2.utils.events]: \u001b[0m eta: 20:12:46  iter: 10479  total_loss: 0.6853  loss_cls: 0.2644  loss_box_reg: 0.296  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.04335  time: 1.2978  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:27:18 d2.utils.events]: \u001b[0m eta: 20:12:15  iter: 10499  total_loss: 0.7029  loss_cls: 0.2867  loss_box_reg: 0.2818  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.05046  time: 1.2978  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:27:44 d2.utils.events]: \u001b[0m eta: 20:11:37  iter: 10519  total_loss: 0.7068  loss_cls: 0.274  loss_box_reg: 0.26  loss_rpn_cls: 0.023  loss_rpn_loc: 0.05081  time: 1.2978  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:28:11 d2.utils.events]: \u001b[0m eta: 20:11:27  iter: 10539  total_loss: 0.5658  loss_cls: 0.2423  loss_box_reg: 0.2337  loss_rpn_cls: 0.02785  loss_rpn_loc: 0.03638  time: 1.2978  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 673.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 12:28:26 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/06 12:28:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 12:28:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 12:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2648 s / img. ETA=0:04:08\n",
            "\u001b[32m[03/06 12:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2731 s / img. ETA=0:04:17\n",
            "\u001b[32m[03/06 12:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2724 s / img. ETA=0:04:14\n",
            "\u001b[32m[03/06 12:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2694 s / img. ETA=0:04:05\n",
            "\u001b[32m[03/06 12:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2667 s / img. ETA=0:03:55\n",
            "\u001b[32m[03/06 12:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2644 s / img. ETA=0:03:48\n",
            "\u001b[32m[03/06 12:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 117/878. 0.2635 s / img. ETA=0:03:41\n",
            "\u001b[32m[03/06 12:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 135/878. 0.2630 s / img. ETA=0:03:35\n",
            "\u001b[32m[03/06 12:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 154/878. 0.2626 s / img. ETA=0:03:28\n",
            "\u001b[32m[03/06 12:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 172/878. 0.2622 s / img. ETA=0:03:23\n",
            "\u001b[32m[03/06 12:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 190/878. 0.2618 s / img. ETA=0:03:17\n",
            "\u001b[32m[03/06 12:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 209/878. 0.2610 s / img. ETA=0:03:11\n",
            "\u001b[32m[03/06 12:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 227/878. 0.2608 s / img. ETA=0:03:06\n",
            "\u001b[32m[03/06 12:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 245/878. 0.2607 s / img. ETA=0:03:00\n",
            "\u001b[32m[03/06 12:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 263/878. 0.2606 s / img. ETA=0:02:55\n",
            "\u001b[32m[03/06 12:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 281/878. 0.2603 s / img. ETA=0:02:50\n",
            "\u001b[32m[03/06 12:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 299/878. 0.2603 s / img. ETA=0:02:44\n",
            "\u001b[32m[03/06 12:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 317/878. 0.2599 s / img. ETA=0:02:39\n",
            "\u001b[32m[03/06 12:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 335/878. 0.2600 s / img. ETA=0:02:34\n",
            "\u001b[32m[03/06 12:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 353/878. 0.2602 s / img. ETA=0:02:29\n",
            "\u001b[32m[03/06 12:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 372/878. 0.2600 s / img. ETA=0:02:24\n",
            "\u001b[32m[03/06 12:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 390/878. 0.2601 s / img. ETA=0:02:19\n",
            "\u001b[32m[03/06 12:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 409/878. 0.2597 s / img. ETA=0:02:13\n",
            "\u001b[32m[03/06 12:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 427/878. 0.2599 s / img. ETA=0:02:08\n",
            "\u001b[32m[03/06 12:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 445/878. 0.2599 s / img. ETA=0:02:03\n",
            "\u001b[32m[03/06 12:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 464/878. 0.2596 s / img. ETA=0:01:57\n",
            "\u001b[32m[03/06 12:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 482/878. 0.2594 s / img. ETA=0:01:52\n",
            "\u001b[32m[03/06 12:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 501/878. 0.2591 s / img. ETA=0:01:47\n",
            "\u001b[32m[03/06 12:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 519/878. 0.2590 s / img. ETA=0:01:41\n",
            "\u001b[32m[03/06 12:30:59 d2.evaluation.evaluator]: \u001b[0mInference done 537/878. 0.2590 s / img. ETA=0:01:36\n",
            "\u001b[32m[03/06 12:31:04 d2.evaluation.evaluator]: \u001b[0mInference done 555/878. 0.2591 s / img. ETA=0:01:31\n",
            "\u001b[32m[03/06 12:31:09 d2.evaluation.evaluator]: \u001b[0mInference done 573/878. 0.2590 s / img. ETA=0:01:26\n",
            "\u001b[32m[03/06 12:31:14 d2.evaluation.evaluator]: \u001b[0mInference done 591/878. 0.2589 s / img. ETA=0:01:21\n",
            "\u001b[32m[03/06 12:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 609/878. 0.2589 s / img. ETA=0:01:16\n",
            "\u001b[32m[03/06 12:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 628/878. 0.2587 s / img. ETA=0:01:10\n",
            "\u001b[32m[03/06 12:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 646/878. 0.2587 s / img. ETA=0:01:05\n",
            "\u001b[32m[03/06 12:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 665/878. 0.2586 s / img. ETA=0:01:00\n",
            "\u001b[32m[03/06 12:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 683/878. 0.2586 s / img. ETA=0:00:55\n",
            "\u001b[32m[03/06 12:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 701/878. 0.2585 s / img. ETA=0:00:50\n",
            "\u001b[32m[03/06 12:31:50 d2.evaluation.evaluator]: \u001b[0mInference done 719/878. 0.2585 s / img. ETA=0:00:45\n",
            "\u001b[32m[03/06 12:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 737/878. 0.2586 s / img. ETA=0:00:39\n",
            "\u001b[32m[03/06 12:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 755/878. 0.2585 s / img. ETA=0:00:34\n",
            "\u001b[32m[03/06 12:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 773/878. 0.2585 s / img. ETA=0:00:29\n",
            "\u001b[32m[03/06 12:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 791/878. 0.2585 s / img. ETA=0:00:24\n",
            "\u001b[32m[03/06 12:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 809/878. 0.2586 s / img. ETA=0:00:19\n",
            "\u001b[32m[03/06 12:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 828/878. 0.2585 s / img. ETA=0:00:14\n",
            "\u001b[32m[03/06 12:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 846/878. 0.2586 s / img. ETA=0:00:09\n",
            "\u001b[32m[03/06 12:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 864/878. 0.2587 s / img. ETA=0:00:03\n",
            "\u001b[32m[03/06 12:32:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:07.535127 (0.283545 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 12:32:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.258655 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 1.24 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.20 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.021\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.274\n",
            "\u001b[32m[03/06 12:32:38 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 12:32:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 12:32:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 12:32:38 d2.evaluation.testing]: \u001b[0mcopypaste: 10.9108,20.7813,27.2660,2.1240,6.7320,11.2650\n",
            "\u001b[32m[03/06 12:32:53 d2.utils.events]: \u001b[0m eta: 20:10:58  iter: 10559  total_loss: 0.6796  loss_cls: 0.2761  loss_box_reg: 0.2913  loss_rpn_cls: 0.02464  loss_rpn_loc: 0.0479  time: 1.2978  data_time: 0.0233  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:33:19 d2.utils.events]: \u001b[0m eta: 20:10:14  iter: 10579  total_loss: 0.4586  loss_cls: 0.1978  loss_box_reg: 0.2117  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.02581  time: 1.2978  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:33:45 d2.utils.events]: \u001b[0m eta: 20:09:59  iter: 10599  total_loss: 0.5413  loss_cls: 0.253  loss_box_reg: 0.2443  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.04485  time: 1.2978  data_time: 0.0246  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:34:11 d2.utils.events]: \u001b[0m eta: 20:09:22  iter: 10619  total_loss: 0.619  loss_cls: 0.2442  loss_box_reg: 0.2678  loss_rpn_cls: 0.02707  loss_rpn_loc: 0.053  time: 1.2978  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:34:37 d2.utils.events]: \u001b[0m eta: 20:08:41  iter: 10639  total_loss: 0.6584  loss_cls: 0.2907  loss_box_reg: 0.2775  loss_rpn_cls: 0.02547  loss_rpn_loc: 0.07033  time: 1.2978  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:35:03 d2.utils.events]: \u001b[0m eta: 20:08:14  iter: 10659  total_loss: 0.6338  loss_cls: 0.2717  loss_box_reg: 0.2589  loss_rpn_cls: 0.02714  loss_rpn_loc: 0.0528  time: 1.2978  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:35:29 d2.utils.events]: \u001b[0m eta: 20:08:23  iter: 10679  total_loss: 0.6386  loss_cls: 0.273  loss_box_reg: 0.2801  loss_rpn_cls: 0.02088  loss_rpn_loc: 0.03394  time: 1.2978  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:35:55 d2.utils.events]: \u001b[0m eta: 20:08:04  iter: 10699  total_loss: 0.5828  loss_cls: 0.2234  loss_box_reg: 0.2459  loss_rpn_cls: 0.02791  loss_rpn_loc: 0.03967  time: 1.2978  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:36:21 d2.utils.events]: \u001b[0m eta: 20:07:35  iter: 10719  total_loss: 0.5923  loss_cls: 0.2455  loss_box_reg: 0.2272  loss_rpn_cls: 0.02542  loss_rpn_loc: 0.04895  time: 1.2978  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:36:48 d2.utils.events]: \u001b[0m eta: 20:07:42  iter: 10739  total_loss: 0.4966  loss_cls: 0.2164  loss_box_reg: 0.2266  loss_rpn_cls: 0.02262  loss_rpn_loc: 0.04448  time: 1.2979  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:37:14 d2.utils.events]: \u001b[0m eta: 20:07:19  iter: 10759  total_loss: 0.4422  loss_cls: 0.1838  loss_box_reg: 0.191  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.03807  time: 1.2979  data_time: 0.0222  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:37:40 d2.utils.events]: \u001b[0m eta: 20:06:57  iter: 10779  total_loss: 0.6408  loss_cls: 0.2349  loss_box_reg: 0.2587  loss_rpn_cls: 0.024  loss_rpn_loc: 0.06976  time: 1.2979  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:38:06 d2.utils.events]: \u001b[0m eta: 20:06:24  iter: 10799  total_loss: 0.4822  loss_cls: 0.208  loss_box_reg: 0.2174  loss_rpn_cls: 0.02042  loss_rpn_loc: 0.04103  time: 1.2979  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:38:32 d2.utils.events]: \u001b[0m eta: 20:06:17  iter: 10819  total_loss: 0.5633  loss_cls: 0.2527  loss_box_reg: 0.2391  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.04566  time: 1.2979  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:38:58 d2.utils.events]: \u001b[0m eta: 20:06:25  iter: 10839  total_loss: 0.7107  loss_cls: 0.3099  loss_box_reg: 0.3035  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.03933  time: 1.2979  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:39:24 d2.utils.events]: \u001b[0m eta: 20:06:03  iter: 10859  total_loss: 0.6153  loss_cls: 0.2888  loss_box_reg: 0.2531  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.04589  time: 1.2979  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:39:50 d2.utils.events]: \u001b[0m eta: 20:05:22  iter: 10879  total_loss: 0.6561  loss_cls: 0.2488  loss_box_reg: 0.2733  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.05285  time: 1.2979  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:40:16 d2.utils.events]: \u001b[0m eta: 20:05:07  iter: 10899  total_loss: 0.6744  loss_cls: 0.3226  loss_box_reg: 0.3136  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.04881  time: 1.2979  data_time: 0.0222  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:40:42 d2.utils.events]: \u001b[0m eta: 20:04:39  iter: 10919  total_loss: 0.6147  loss_cls: 0.2587  loss_box_reg: 0.2559  loss_rpn_cls: 0.02113  loss_rpn_loc: 0.04417  time: 1.2979  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:41:08 d2.utils.events]: \u001b[0m eta: 20:04:16  iter: 10939  total_loss: 0.4962  loss_cls: 0.2398  loss_box_reg: 0.2027  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.0426  time: 1.2979  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:41:34 d2.utils.events]: \u001b[0m eta: 20:04:27  iter: 10959  total_loss: 0.6489  loss_cls: 0.2906  loss_box_reg: 0.2597  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.03673  time: 1.2980  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:42:00 d2.utils.events]: \u001b[0m eta: 20:03:54  iter: 10979  total_loss: 0.5077  loss_cls: 0.2437  loss_box_reg: 0.2318  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.03797  time: 1.2980  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:42:27 d2.utils.events]: \u001b[0m eta: 20:03:02  iter: 10999  total_loss: 0.7527  loss_cls: 0.2865  loss_box_reg: 0.3314  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.05407  time: 1.2980  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:42:53 d2.utils.events]: \u001b[0m eta: 20:02:51  iter: 11019  total_loss: 0.5879  loss_cls: 0.2657  loss_box_reg: 0.2449  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.04741  time: 1.2980  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:43:19 d2.utils.events]: \u001b[0m eta: 20:02:45  iter: 11039  total_loss: 0.6588  loss_cls: 0.2944  loss_box_reg: 0.3053  loss_rpn_cls: 0.02514  loss_rpn_loc: 0.04325  time: 1.2980  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:43:45 d2.utils.events]: \u001b[0m eta: 20:02:58  iter: 11059  total_loss: 0.4403  loss_cls: 0.1614  loss_box_reg: 0.2089  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.03215  time: 1.2980  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:44:11 d2.utils.events]: \u001b[0m eta: 20:02:57  iter: 11079  total_loss: 0.6859  loss_cls: 0.331  loss_box_reg: 0.2924  loss_rpn_cls: 0.02032  loss_rpn_loc: 0.05213  time: 1.2980  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:44:37 d2.utils.events]: \u001b[0m eta: 20:02:13  iter: 11099  total_loss: 0.7294  loss_cls: 0.3169  loss_box_reg: 0.3148  loss_rpn_cls: 0.02033  loss_rpn_loc: 0.06163  time: 1.2981  data_time: 0.0228  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:45:04 d2.utils.events]: \u001b[0m eta: 20:02:20  iter: 11119  total_loss: 0.8243  loss_cls: 0.359  loss_box_reg: 0.3694  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.05568  time: 1.2981  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:45:30 d2.utils.events]: \u001b[0m eta: 20:01:47  iter: 11139  total_loss: 0.6899  loss_cls: 0.2478  loss_box_reg: 0.2342  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.0566  time: 1.2981  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:45:56 d2.utils.events]: \u001b[0m eta: 20:01:35  iter: 11159  total_loss: 0.579  loss_cls: 0.239  loss_box_reg: 0.2684  loss_rpn_cls: 0.0347  loss_rpn_loc: 0.04077  time: 1.2981  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:46:22 d2.utils.events]: \u001b[0m eta: 20:00:36  iter: 11179  total_loss: 0.689  loss_cls: 0.2756  loss_box_reg: 0.2709  loss_rpn_cls: 0.0276  loss_rpn_loc: 0.06366  time: 1.2981  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:46:48 d2.utils.events]: \u001b[0m eta: 19:59:49  iter: 11199  total_loss: 0.5604  loss_cls: 0.2385  loss_box_reg: 0.2411  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.04478  time: 1.2981  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:47:14 d2.utils.events]: \u001b[0m eta: 19:59:24  iter: 11219  total_loss: 0.5669  loss_cls: 0.2115  loss_box_reg: 0.2171  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.05406  time: 1.2981  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:47:40 d2.utils.events]: \u001b[0m eta: 19:58:58  iter: 11239  total_loss: 0.6018  loss_cls: 0.1856  loss_box_reg: 0.2262  loss_rpn_cls: 0.02999  loss_rpn_loc: 0.05156  time: 1.2981  data_time: 0.0229  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:48:06 d2.utils.events]: \u001b[0m eta: 19:58:22  iter: 11259  total_loss: 0.6593  loss_cls: 0.2493  loss_box_reg: 0.242  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.05906  time: 1.2981  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:48:32 d2.utils.events]: \u001b[0m eta: 19:58:09  iter: 11279  total_loss: 0.6321  loss_cls: 0.2668  loss_box_reg: 0.2807  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.05468  time: 1.2981  data_time: 0.0220  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:48:58 d2.utils.events]: \u001b[0m eta: 19:57:40  iter: 11299  total_loss: 0.6834  loss_cls: 0.2702  loss_box_reg: 0.2274  loss_rpn_cls: 0.0201  loss_rpn_loc: 0.05316  time: 1.2982  data_time: 0.0216  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:49:24 d2.utils.events]: \u001b[0m eta: 19:56:55  iter: 11319  total_loss: 0.5362  loss_cls: 0.2122  loss_box_reg: 0.1976  loss_rpn_cls: 0.02572  loss_rpn_loc: 0.04173  time: 1.2982  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:49:50 d2.utils.events]: \u001b[0m eta: 19:56:25  iter: 11339  total_loss: 0.7047  loss_cls: 0.3003  loss_box_reg: 0.3061  loss_rpn_cls: 0.02894  loss_rpn_loc: 0.04138  time: 1.2982  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:50:16 d2.utils.events]: \u001b[0m eta: 19:56:25  iter: 11359  total_loss: 0.5482  loss_cls: 0.2577  loss_box_reg: 0.2161  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.05134  time: 1.2982  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:50:42 d2.utils.events]: \u001b[0m eta: 19:55:46  iter: 11379  total_loss: 0.5465  loss_cls: 0.242  loss_box_reg: 0.2353  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.02972  time: 1.2981  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:51:08 d2.utils.events]: \u001b[0m eta: 19:55:04  iter: 11399  total_loss: 0.6385  loss_cls: 0.2771  loss_box_reg: 0.264  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.04815  time: 1.2981  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:51:34 d2.utils.events]: \u001b[0m eta: 19:54:37  iter: 11419  total_loss: 0.6452  loss_cls: 0.2769  loss_box_reg: 0.3048  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.05558  time: 1.2982  data_time: 0.0228  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:52:00 d2.utils.events]: \u001b[0m eta: 19:54:20  iter: 11439  total_loss: 0.5785  loss_cls: 0.2551  loss_box_reg: 0.279  loss_rpn_cls: 0.02121  loss_rpn_loc: 0.04319  time: 1.2982  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:52:26 d2.utils.events]: \u001b[0m eta: 19:53:30  iter: 11459  total_loss: 0.5525  loss_cls: 0.2427  loss_box_reg: 0.2368  loss_rpn_cls: 0.01977  loss_rpn_loc: 0.03956  time: 1.2982  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:52:52 d2.utils.events]: \u001b[0m eta: 19:53:19  iter: 11479  total_loss: 0.6837  loss_cls: 0.2849  loss_box_reg: 0.3113  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.06383  time: 1.2982  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:53:18 d2.utils.events]: \u001b[0m eta: 19:52:53  iter: 11499  total_loss: 0.7318  loss_cls: 0.3095  loss_box_reg: 0.3102  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.05229  time: 1.2981  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:53:44 d2.utils.events]: \u001b[0m eta: 19:52:17  iter: 11519  total_loss: 0.6766  loss_cls: 0.2872  loss_box_reg: 0.2902  loss_rpn_cls: 0.03486  loss_rpn_loc: 0.07208  time: 1.2981  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:54:10 d2.utils.events]: \u001b[0m eta: 19:51:33  iter: 11539  total_loss: 0.4873  loss_cls: 0.2011  loss_box_reg: 0.2311  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.03279  time: 1.2981  data_time: 0.0213  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:54:35 d2.utils.events]: \u001b[0m eta: 19:51:27  iter: 11559  total_loss: 0.6606  loss_cls: 0.3071  loss_box_reg: 0.301  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.04458  time: 1.2981  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:55:01 d2.utils.events]: \u001b[0m eta: 19:51:01  iter: 11579  total_loss: 0.5643  loss_cls: 0.2589  loss_box_reg: 0.2658  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.05201  time: 1.2981  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:55:27 d2.utils.events]: \u001b[0m eta: 19:50:29  iter: 11599  total_loss: 0.6667  loss_cls: 0.293  loss_box_reg: 0.286  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.06802  time: 1.2981  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:55:53 d2.utils.events]: \u001b[0m eta: 19:49:49  iter: 11619  total_loss: 0.7202  loss_cls: 0.2498  loss_box_reg: 0.283  loss_rpn_cls: 0.02743  loss_rpn_loc: 0.04841  time: 1.2981  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:56:19 d2.utils.events]: \u001b[0m eta: 19:49:14  iter: 11639  total_loss: 0.6642  loss_cls: 0.2608  loss_box_reg: 0.2813  loss_rpn_cls: 0.01783  loss_rpn_loc: 0.05825  time: 1.2981  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:56:45 d2.utils.events]: \u001b[0m eta: 19:48:40  iter: 11659  total_loss: 0.5998  loss_cls: 0.2189  loss_box_reg: 0.2518  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.03784  time: 1.2981  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:57:11 d2.utils.events]: \u001b[0m eta: 19:47:58  iter: 11679  total_loss: 0.5353  loss_cls: 0.2133  loss_box_reg: 0.2504  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.05351  time: 1.2981  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:57:37 d2.utils.events]: \u001b[0m eta: 19:47:32  iter: 11699  total_loss: 0.6685  loss_cls: 0.2721  loss_box_reg: 0.2733  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.05488  time: 1.2981  data_time: 0.0213  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:58:03 d2.utils.events]: \u001b[0m eta: 19:47:06  iter: 11719  total_loss: 0.6128  loss_cls: 0.2308  loss_box_reg: 0.2666  loss_rpn_cls: 0.02246  loss_rpn_loc: 0.03967  time: 1.2981  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:58:29 d2.utils.events]: \u001b[0m eta: 19:46:37  iter: 11739  total_loss: 0.588  loss_cls: 0.2344  loss_box_reg: 0.2485  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.04577  time: 1.2981  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:58:55 d2.utils.events]: \u001b[0m eta: 19:46:09  iter: 11759  total_loss: 0.7785  loss_cls: 0.3274  loss_box_reg: 0.3112  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.05661  time: 1.2981  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:59:22 d2.utils.events]: \u001b[0m eta: 19:45:49  iter: 11779  total_loss: 0.6644  loss_cls: 0.2756  loss_box_reg: 0.2755  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.0546  time: 1.2981  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 12:59:48 d2.utils.events]: \u001b[0m eta: 19:45:17  iter: 11799  total_loss: 0.5591  loss_cls: 0.2355  loss_box_reg: 0.2696  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.05047  time: 1.2982  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:00:14 d2.utils.events]: \u001b[0m eta: 19:44:24  iter: 11819  total_loss: 0.807  loss_cls: 0.3305  loss_box_reg: 0.336  loss_rpn_cls: 0.02281  loss_rpn_loc: 0.06536  time: 1.2982  data_time: 0.0261  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:00:39 d2.utils.events]: \u001b[0m eta: 19:43:36  iter: 11839  total_loss: 0.6062  loss_cls: 0.2591  loss_box_reg: 0.2438  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.04984  time: 1.2981  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:01:05 d2.utils.events]: \u001b[0m eta: 19:42:55  iter: 11859  total_loss: 0.639  loss_cls: 0.2511  loss_box_reg: 0.2809  loss_rpn_cls: 0.02023  loss_rpn_loc: 0.04989  time: 1.2981  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:01:31 d2.utils.events]: \u001b[0m eta: 19:42:41  iter: 11879  total_loss: 0.5143  loss_cls: 0.1758  loss_box_reg: 0.2132  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.04478  time: 1.2981  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:01:58 d2.utils.events]: \u001b[0m eta: 19:42:23  iter: 11899  total_loss: 0.6503  loss_cls: 0.2621  loss_box_reg: 0.2589  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.04201  time: 1.2982  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:02:24 d2.utils.events]: \u001b[0m eta: 19:42:01  iter: 11919  total_loss: 0.5697  loss_cls: 0.2619  loss_box_reg: 0.2527  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.04531  time: 1.2982  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:02:50 d2.utils.events]: \u001b[0m eta: 19:41:23  iter: 11939  total_loss: 0.6668  loss_cls: 0.2863  loss_box_reg: 0.3004  loss_rpn_cls: 0.01762  loss_rpn_loc: 0.0398  time: 1.2982  data_time: 0.0213  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:03:16 d2.utils.events]: \u001b[0m eta: 19:41:04  iter: 11959  total_loss: 0.6856  loss_cls: 0.2739  loss_box_reg: 0.3008  loss_rpn_cls: 0.02535  loss_rpn_loc: 0.0434  time: 1.2982  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:03:42 d2.utils.events]: \u001b[0m eta: 19:40:39  iter: 11979  total_loss: 0.636  loss_cls: 0.2617  loss_box_reg: 0.2379  loss_rpn_cls: 0.02228  loss_rpn_loc: 0.04751  time: 1.2982  data_time: 0.0248  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:04:08 d2.utils.events]: \u001b[0m eta: 19:40:31  iter: 11999  total_loss: 0.7506  loss_cls: 0.3011  loss_box_reg: 0.3075  loss_rpn_cls: 0.01721  loss_rpn_loc: 0.06419  time: 1.2982  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:04:34 d2.utils.events]: \u001b[0m eta: 19:40:05  iter: 12019  total_loss: 0.6744  loss_cls: 0.3126  loss_box_reg: 0.307  loss_rpn_cls: 0.02647  loss_rpn_loc: 0.05321  time: 1.2982  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:05:00 d2.utils.events]: \u001b[0m eta: 19:39:33  iter: 12039  total_loss: 0.6608  loss_cls: 0.2813  loss_box_reg: 0.2951  loss_rpn_cls: 0.03006  loss_rpn_loc: 0.05161  time: 1.2982  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:05:26 d2.utils.events]: \u001b[0m eta: 19:38:46  iter: 12059  total_loss: 0.6783  loss_cls: 0.2728  loss_box_reg: 0.3002  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.05127  time: 1.2982  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:05:52 d2.utils.events]: \u001b[0m eta: 19:38:21  iter: 12079  total_loss: 0.6841  loss_cls: 0.288  loss_box_reg: 0.267  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.04001  time: 1.2982  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:06:18 d2.utils.events]: \u001b[0m eta: 19:38:00  iter: 12099  total_loss: 0.7417  loss_cls: 0.2648  loss_box_reg: 0.2802  loss_rpn_cls: 0.02032  loss_rpn_loc: 0.06256  time: 1.2982  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:06:44 d2.utils.events]: \u001b[0m eta: 19:37:24  iter: 12119  total_loss: 0.6412  loss_cls: 0.2705  loss_box_reg: 0.2547  loss_rpn_cls: 0.02535  loss_rpn_loc: 0.06265  time: 1.2982  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:07:10 d2.utils.events]: \u001b[0m eta: 19:36:54  iter: 12139  total_loss: 0.5478  loss_cls: 0.2638  loss_box_reg: 0.2133  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.06216  time: 1.2982  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:07:36 d2.utils.events]: \u001b[0m eta: 19:36:16  iter: 12159  total_loss: 0.514  loss_cls: 0.1988  loss_box_reg: 0.2068  loss_rpn_cls: 0.02827  loss_rpn_loc: 0.04123  time: 1.2982  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:08:02 d2.utils.events]: \u001b[0m eta: 19:35:20  iter: 12179  total_loss: 0.6091  loss_cls: 0.2624  loss_box_reg: 0.2692  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.04302  time: 1.2982  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:08:28 d2.utils.events]: \u001b[0m eta: 19:35:15  iter: 12199  total_loss: 0.6317  loss_cls: 0.2714  loss_box_reg: 0.2384  loss_rpn_cls: 0.02653  loss_rpn_loc: 0.04928  time: 1.2982  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:08:54 d2.utils.events]: \u001b[0m eta: 19:34:32  iter: 12219  total_loss: 0.4858  loss_cls: 0.211  loss_box_reg: 0.2056  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.036  time: 1.2983  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:09:20 d2.utils.events]: \u001b[0m eta: 19:33:58  iter: 12239  total_loss: 0.5953  loss_cls: 0.2316  loss_box_reg: 0.282  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.04268  time: 1.2982  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:09:46 d2.utils.events]: \u001b[0m eta: 19:33:24  iter: 12259  total_loss: 0.6434  loss_cls: 0.2618  loss_box_reg: 0.2507  loss_rpn_cls: 0.01872  loss_rpn_loc: 0.05199  time: 1.2982  data_time: 0.0213  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:10:12 d2.utils.events]: \u001b[0m eta: 19:32:45  iter: 12279  total_loss: 0.66  loss_cls: 0.251  loss_box_reg: 0.2913  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.0425  time: 1.2982  data_time: 0.0225  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:10:38 d2.utils.events]: \u001b[0m eta: 19:32:13  iter: 12299  total_loss: 0.7317  loss_cls: 0.3167  loss_box_reg: 0.2749  loss_rpn_cls: 0.02935  loss_rpn_loc: 0.06434  time: 1.2982  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 691.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 13:10:50 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 13:10:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 13:10:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 13:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2685 s / img. ETA=0:04:20\n",
            "\u001b[32m[03/06 13:11:00 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2684 s / img. ETA=0:04:16\n",
            "\u001b[32m[03/06 13:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2700 s / img. ETA=0:04:13\n",
            "\u001b[32m[03/06 13:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2676 s / img. ETA=0:04:04\n",
            "\u001b[32m[03/06 13:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2665 s / img. ETA=0:03:55\n",
            "\u001b[32m[03/06 13:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2654 s / img. ETA=0:03:49\n",
            "\u001b[32m[03/06 13:11:26 d2.evaluation.evaluator]: \u001b[0mInference done 118/878. 0.2633 s / img. ETA=0:03:41\n",
            "\u001b[32m[03/06 13:11:31 d2.evaluation.evaluator]: \u001b[0mInference done 136/878. 0.2630 s / img. ETA=0:03:35\n",
            "\u001b[32m[03/06 13:11:36 d2.evaluation.evaluator]: \u001b[0mInference done 155/878. 0.2623 s / img. ETA=0:03:28\n",
            "\u001b[32m[03/06 13:11:41 d2.evaluation.evaluator]: \u001b[0mInference done 173/878. 0.2621 s / img. ETA=0:03:22\n",
            "\u001b[32m[03/06 13:11:46 d2.evaluation.evaluator]: \u001b[0mInference done 191/878. 0.2621 s / img. ETA=0:03:17\n",
            "\u001b[32m[03/06 13:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 210/878. 0.2614 s / img. ETA=0:03:11\n",
            "\u001b[32m[03/06 13:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 228/878. 0.2611 s / img. ETA=0:03:05\n",
            "\u001b[32m[03/06 13:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 246/878. 0.2608 s / img. ETA=0:03:00\n",
            "\u001b[32m[03/06 13:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 264/878. 0.2606 s / img. ETA=0:02:55\n",
            "\u001b[32m[03/06 13:12:12 d2.evaluation.evaluator]: \u001b[0mInference done 282/878. 0.2605 s / img. ETA=0:02:50\n",
            "\u001b[32m[03/06 13:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 300/878. 0.2603 s / img. ETA=0:02:45\n",
            "\u001b[32m[03/06 13:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 318/878. 0.2601 s / img. ETA=0:02:40\n",
            "\u001b[32m[03/06 13:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 336/878. 0.2602 s / img. ETA=0:02:34\n",
            "\u001b[32m[03/06 13:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 354/878. 0.2604 s / img. ETA=0:02:29\n",
            "\u001b[32m[03/06 13:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 372/878. 0.2604 s / img. ETA=0:02:24\n",
            "\u001b[32m[03/06 13:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 390/878. 0.2602 s / img. ETA=0:02:19\n",
            "\u001b[32m[03/06 13:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 408/878. 0.2601 s / img. ETA=0:02:14\n",
            "\u001b[32m[03/06 13:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 426/878. 0.2602 s / img. ETA=0:02:09\n",
            "\u001b[32m[03/06 13:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 444/878. 0.2602 s / img. ETA=0:02:03\n",
            "\u001b[32m[03/06 13:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 462/878. 0.2600 s / img. ETA=0:01:58\n",
            "\u001b[32m[03/06 13:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 480/878. 0.2597 s / img. ETA=0:01:53\n",
            "\u001b[32m[03/06 13:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 498/878. 0.2596 s / img. ETA=0:01:48\n",
            "\u001b[32m[03/06 13:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 516/878. 0.2598 s / img. ETA=0:01:43\n",
            "\u001b[32m[03/06 13:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 534/878. 0.2596 s / img. ETA=0:01:38\n",
            "\u001b[32m[03/06 13:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 552/878. 0.2598 s / img. ETA=0:01:32\n",
            "\u001b[32m[03/06 13:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 570/878. 0.2597 s / img. ETA=0:01:27\n",
            "\u001b[32m[03/06 13:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 588/878. 0.2597 s / img. ETA=0:01:22\n",
            "\u001b[32m[03/06 13:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 606/878. 0.2597 s / img. ETA=0:01:17\n",
            "\u001b[32m[03/06 13:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 624/878. 0.2596 s / img. ETA=0:01:12\n",
            "\u001b[32m[03/06 13:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 642/878. 0.2597 s / img. ETA=0:01:07\n",
            "\u001b[32m[03/06 13:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 660/878. 0.2596 s / img. ETA=0:01:02\n",
            "\u001b[32m[03/06 13:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 678/878. 0.2596 s / img. ETA=0:00:56\n",
            "\u001b[32m[03/06 13:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 695/878. 0.2597 s / img. ETA=0:00:52\n",
            "\u001b[32m[03/06 13:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 712/878. 0.2598 s / img. ETA=0:00:47\n",
            "\u001b[32m[03/06 13:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 731/878. 0.2597 s / img. ETA=0:00:41\n",
            "\u001b[32m[03/06 13:14:25 d2.evaluation.evaluator]: \u001b[0mInference done 749/878. 0.2596 s / img. ETA=0:00:36\n",
            "\u001b[32m[03/06 13:14:30 d2.evaluation.evaluator]: \u001b[0mInference done 767/878. 0.2596 s / img. ETA=0:00:31\n",
            "\u001b[32m[03/06 13:14:35 d2.evaluation.evaluator]: \u001b[0mInference done 785/878. 0.2595 s / img. ETA=0:00:26\n",
            "\u001b[32m[03/06 13:14:40 d2.evaluation.evaluator]: \u001b[0mInference done 803/878. 0.2594 s / img. ETA=0:00:21\n",
            "\u001b[32m[03/06 13:14:45 d2.evaluation.evaluator]: \u001b[0mInference done 821/878. 0.2594 s / img. ETA=0:00:16\n",
            "\u001b[32m[03/06 13:14:50 d2.evaluation.evaluator]: \u001b[0mInference done 839/878. 0.2595 s / img. ETA=0:00:11\n",
            "\u001b[32m[03/06 13:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 857/878. 0.2596 s / img. ETA=0:00:05\n",
            "\u001b[32m[03/06 13:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 875/878. 0.2596 s / img. ETA=0:00:00\n",
            "\u001b[32m[03/06 13:15:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:08.720570 (0.284903 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 13:15:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:46 (0.259525 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 1.23 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.22 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.289\n",
            "\u001b[32m[03/06 13:15:04 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 13:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 13:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 13:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: 12.0284,22.9732,29.5783,3.9638,7.9074,12.3424\n",
            "\u001b[32m[03/06 13:15:22 d2.utils.events]: \u001b[0m eta: 19:31:55  iter: 12319  total_loss: 0.6311  loss_cls: 0.2776  loss_box_reg: 0.2844  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.03823  time: 1.2982  data_time: 0.0220  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:15:48 d2.utils.events]: \u001b[0m eta: 19:31:25  iter: 12339  total_loss: 0.5686  loss_cls: 0.2394  loss_box_reg: 0.2913  loss_rpn_cls: 0.01658  loss_rpn_loc: 0.03236  time: 1.2982  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:16:14 d2.utils.events]: \u001b[0m eta: 19:30:59  iter: 12359  total_loss: 0.6658  loss_cls: 0.286  loss_box_reg: 0.2988  loss_rpn_cls: 0.02499  loss_rpn_loc: 0.06042  time: 1.2982  data_time: 0.0324  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:16:40 d2.utils.events]: \u001b[0m eta: 19:30:44  iter: 12379  total_loss: 0.6544  loss_cls: 0.2369  loss_box_reg: 0.2518  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.03953  time: 1.2982  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:17:06 d2.utils.events]: \u001b[0m eta: 19:30:40  iter: 12399  total_loss: 0.634  loss_cls: 0.2569  loss_box_reg: 0.2363  loss_rpn_cls: 0.03041  loss_rpn_loc: 0.03872  time: 1.2983  data_time: 0.0209  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:17:32 d2.utils.events]: \u001b[0m eta: 19:30:09  iter: 12419  total_loss: 0.7218  loss_cls: 0.2347  loss_box_reg: 0.2474  loss_rpn_cls: 0.02944  loss_rpn_loc: 0.08797  time: 1.2983  data_time: 0.0219  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:17:58 d2.utils.events]: \u001b[0m eta: 19:29:40  iter: 12439  total_loss: 0.4805  loss_cls: 0.1891  loss_box_reg: 0.2281  loss_rpn_cls: 0.02169  loss_rpn_loc: 0.03609  time: 1.2982  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:18:24 d2.utils.events]: \u001b[0m eta: 19:29:41  iter: 12459  total_loss: 0.5431  loss_cls: 0.2261  loss_box_reg: 0.2472  loss_rpn_cls: 0.02329  loss_rpn_loc: 0.04109  time: 1.2983  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:18:50 d2.utils.events]: \u001b[0m eta: 19:29:03  iter: 12479  total_loss: 0.6565  loss_cls: 0.284  loss_box_reg: 0.2643  loss_rpn_cls: 0.02022  loss_rpn_loc: 0.0491  time: 1.2983  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:19:16 d2.utils.events]: \u001b[0m eta: 19:28:32  iter: 12499  total_loss: 0.7724  loss_cls: 0.3027  loss_box_reg: 0.3242  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.0561  time: 1.2982  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:19:42 d2.utils.events]: \u001b[0m eta: 19:28:18  iter: 12519  total_loss: 0.6212  loss_cls: 0.262  loss_box_reg: 0.2718  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.05078  time: 1.2982  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:20:08 d2.utils.events]: \u001b[0m eta: 19:28:01  iter: 12539  total_loss: 0.7633  loss_cls: 0.3013  loss_box_reg: 0.3191  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.05228  time: 1.2983  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:20:34 d2.utils.events]: \u001b[0m eta: 19:27:02  iter: 12559  total_loss: 0.6422  loss_cls: 0.2663  loss_box_reg: 0.3059  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.04807  time: 1.2983  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:21:00 d2.utils.events]: \u001b[0m eta: 19:27:01  iter: 12579  total_loss: 0.5961  loss_cls: 0.236  loss_box_reg: 0.2624  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.05088  time: 1.2983  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:21:26 d2.utils.events]: \u001b[0m eta: 19:26:52  iter: 12599  total_loss: 0.7391  loss_cls: 0.3023  loss_box_reg: 0.2966  loss_rpn_cls: 0.02415  loss_rpn_loc: 0.05657  time: 1.2983  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:21:52 d2.utils.events]: \u001b[0m eta: 19:26:26  iter: 12619  total_loss: 0.6739  loss_cls: 0.283  loss_box_reg: 0.2798  loss_rpn_cls: 0.02968  loss_rpn_loc: 0.05493  time: 1.2983  data_time: 0.0218  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:22:18 d2.utils.events]: \u001b[0m eta: 19:26:17  iter: 12639  total_loss: 0.6806  loss_cls: 0.258  loss_box_reg: 0.2845  loss_rpn_cls: 0.02603  loss_rpn_loc: 0.05118  time: 1.2983  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:22:44 d2.utils.events]: \u001b[0m eta: 19:26:11  iter: 12659  total_loss: 0.6139  loss_cls: 0.2415  loss_box_reg: 0.2554  loss_rpn_cls: 0.02151  loss_rpn_loc: 0.0541  time: 1.2983  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:23:10 d2.utils.events]: \u001b[0m eta: 19:25:46  iter: 12679  total_loss: 0.6129  loss_cls: 0.2563  loss_box_reg: 0.2573  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.05372  time: 1.2983  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:23:36 d2.utils.events]: \u001b[0m eta: 19:25:09  iter: 12699  total_loss: 0.632  loss_cls: 0.3033  loss_box_reg: 0.2954  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.04492  time: 1.2983  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:24:02 d2.utils.events]: \u001b[0m eta: 19:24:45  iter: 12719  total_loss: 0.664  loss_cls: 0.2978  loss_box_reg: 0.3039  loss_rpn_cls: 0.0203  loss_rpn_loc: 0.04849  time: 1.2983  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:24:28 d2.utils.events]: \u001b[0m eta: 19:23:56  iter: 12739  total_loss: 0.7166  loss_cls: 0.3036  loss_box_reg: 0.3157  loss_rpn_cls: 0.02776  loss_rpn_loc: 0.04804  time: 1.2983  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:24:54 d2.utils.events]: \u001b[0m eta: 19:23:20  iter: 12759  total_loss: 0.6592  loss_cls: 0.2276  loss_box_reg: 0.2564  loss_rpn_cls: 0.02936  loss_rpn_loc: 0.09516  time: 1.2982  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:25:20 d2.utils.events]: \u001b[0m eta: 19:23:04  iter: 12779  total_loss: 0.7442  loss_cls: 0.3052  loss_box_reg: 0.3427  loss_rpn_cls: 0.01763  loss_rpn_loc: 0.04631  time: 1.2983  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:25:46 d2.utils.events]: \u001b[0m eta: 19:22:43  iter: 12799  total_loss: 0.5896  loss_cls: 0.2368  loss_box_reg: 0.2724  loss_rpn_cls: 0.02688  loss_rpn_loc: 0.068  time: 1.2983  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:26:12 d2.utils.events]: \u001b[0m eta: 19:22:31  iter: 12819  total_loss: 0.5303  loss_cls: 0.2184  loss_box_reg: 0.2472  loss_rpn_cls: 0.02254  loss_rpn_loc: 0.03911  time: 1.2983  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:26:38 d2.utils.events]: \u001b[0m eta: 19:22:13  iter: 12839  total_loss: 0.5644  loss_cls: 0.2433  loss_box_reg: 0.2628  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.03555  time: 1.2983  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:27:04 d2.utils.events]: \u001b[0m eta: 19:21:39  iter: 12859  total_loss: 0.5764  loss_cls: 0.2523  loss_box_reg: 0.2525  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.0305  time: 1.2983  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:27:30 d2.utils.events]: \u001b[0m eta: 19:20:55  iter: 12879  total_loss: 0.4776  loss_cls: 0.247  loss_box_reg: 0.2211  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.04106  time: 1.2983  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:27:56 d2.utils.events]: \u001b[0m eta: 19:20:17  iter: 12899  total_loss: 0.6392  loss_cls: 0.2451  loss_box_reg: 0.2861  loss_rpn_cls: 0.02611  loss_rpn_loc: 0.0673  time: 1.2983  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:28:22 d2.utils.events]: \u001b[0m eta: 19:19:39  iter: 12919  total_loss: 0.5314  loss_cls: 0.2004  loss_box_reg: 0.2257  loss_rpn_cls: 0.02002  loss_rpn_loc: 0.03481  time: 1.2983  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:28:48 d2.utils.events]: \u001b[0m eta: 19:18:58  iter: 12939  total_loss: 0.6866  loss_cls: 0.2981  loss_box_reg: 0.3025  loss_rpn_cls: 0.02359  loss_rpn_loc: 0.06166  time: 1.2983  data_time: 0.0225  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:29:13 d2.utils.events]: \u001b[0m eta: 19:18:02  iter: 12959  total_loss: 0.4961  loss_cls: 0.1974  loss_box_reg: 0.214  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.04777  time: 1.2982  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:29:39 d2.utils.events]: \u001b[0m eta: 19:17:37  iter: 12979  total_loss: 0.7183  loss_cls: 0.3296  loss_box_reg: 0.3024  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.04463  time: 1.2982  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:30:05 d2.utils.events]: \u001b[0m eta: 19:16:41  iter: 12999  total_loss: 0.6748  loss_cls: 0.2889  loss_box_reg: 0.2708  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.05182  time: 1.2982  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:30:31 d2.utils.events]: \u001b[0m eta: 19:16:22  iter: 13019  total_loss: 0.622  loss_cls: 0.2844  loss_box_reg: 0.2993  loss_rpn_cls: 0.02311  loss_rpn_loc: 0.05049  time: 1.2983  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:30:57 d2.utils.events]: \u001b[0m eta: 19:16:04  iter: 13039  total_loss: 0.6088  loss_cls: 0.2609  loss_box_reg: 0.2628  loss_rpn_cls: 0.02798  loss_rpn_loc: 0.03844  time: 1.2982  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:31:24 d2.utils.events]: \u001b[0m eta: 19:15:59  iter: 13059  total_loss: 0.6987  loss_cls: 0.3415  loss_box_reg: 0.2695  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.05657  time: 1.2983  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:31:49 d2.utils.events]: \u001b[0m eta: 19:15:25  iter: 13079  total_loss: 0.5941  loss_cls: 0.2687  loss_box_reg: 0.2215  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.04578  time: 1.2983  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:32:15 d2.utils.events]: \u001b[0m eta: 19:14:32  iter: 13099  total_loss: 0.5533  loss_cls: 0.1966  loss_box_reg: 0.2462  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.03978  time: 1.2982  data_time: 0.0239  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:32:41 d2.utils.events]: \u001b[0m eta: 19:14:03  iter: 13119  total_loss: 0.6848  loss_cls: 0.2945  loss_box_reg: 0.2906  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.036  time: 1.2982  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:33:07 d2.utils.events]: \u001b[0m eta: 19:13:35  iter: 13139  total_loss: 0.6671  loss_cls: 0.2627  loss_box_reg: 0.2755  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.04489  time: 1.2982  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:33:33 d2.utils.events]: \u001b[0m eta: 19:13:10  iter: 13159  total_loss: 0.6427  loss_cls: 0.2585  loss_box_reg: 0.3212  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.05496  time: 1.2982  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:33:59 d2.utils.events]: \u001b[0m eta: 19:13:06  iter: 13179  total_loss: 0.517  loss_cls: 0.2166  loss_box_reg: 0.2372  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.04624  time: 1.2982  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:34:25 d2.utils.events]: \u001b[0m eta: 19:12:50  iter: 13199  total_loss: 0.6735  loss_cls: 0.3144  loss_box_reg: 0.2581  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.04513  time: 1.2982  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:34:51 d2.utils.events]: \u001b[0m eta: 19:12:15  iter: 13219  total_loss: 0.6428  loss_cls: 0.3078  loss_box_reg: 0.264  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.0348  time: 1.2982  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:35:17 d2.utils.events]: \u001b[0m eta: 19:12:03  iter: 13239  total_loss: 0.6005  loss_cls: 0.2368  loss_box_reg: 0.2004  loss_rpn_cls: 0.02443  loss_rpn_loc: 0.04572  time: 1.2982  data_time: 0.0245  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:35:43 d2.utils.events]: \u001b[0m eta: 19:11:33  iter: 13259  total_loss: 0.7122  loss_cls: 0.2671  loss_box_reg: 0.3187  loss_rpn_cls: 0.02537  loss_rpn_loc: 0.05029  time: 1.2982  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:36:09 d2.utils.events]: \u001b[0m eta: 19:11:07  iter: 13279  total_loss: 0.7007  loss_cls: 0.2897  loss_box_reg: 0.2985  loss_rpn_cls: 0.02754  loss_rpn_loc: 0.05461  time: 1.2982  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:36:35 d2.utils.events]: \u001b[0m eta: 19:10:59  iter: 13299  total_loss: 0.6552  loss_cls: 0.2738  loss_box_reg: 0.2581  loss_rpn_cls: 0.02865  loss_rpn_loc: 0.05223  time: 1.2983  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:37:01 d2.utils.events]: \u001b[0m eta: 19:10:29  iter: 13319  total_loss: 0.6367  loss_cls: 0.3058  loss_box_reg: 0.2747  loss_rpn_cls: 0.02234  loss_rpn_loc: 0.04109  time: 1.2983  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:37:27 d2.utils.events]: \u001b[0m eta: 19:10:16  iter: 13339  total_loss: 0.6216  loss_cls: 0.2688  loss_box_reg: 0.286  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.03177  time: 1.2983  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:37:53 d2.utils.events]: \u001b[0m eta: 19:09:52  iter: 13359  total_loss: 0.6272  loss_cls: 0.2722  loss_box_reg: 0.2633  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.04377  time: 1.2983  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:38:19 d2.utils.events]: \u001b[0m eta: 19:09:21  iter: 13379  total_loss: 0.7154  loss_cls: 0.3349  loss_box_reg: 0.3101  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.04161  time: 1.2983  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:38:46 d2.utils.events]: \u001b[0m eta: 19:08:50  iter: 13399  total_loss: 0.557  loss_cls: 0.2527  loss_box_reg: 0.257  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.04212  time: 1.2983  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:39:12 d2.utils.events]: \u001b[0m eta: 19:08:20  iter: 13419  total_loss: 0.698  loss_cls: 0.3122  loss_box_reg: 0.291  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.08379  time: 1.2983  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:39:38 d2.utils.events]: \u001b[0m eta: 19:08:06  iter: 13439  total_loss: 0.521  loss_cls: 0.2495  loss_box_reg: 0.256  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.03218  time: 1.2983  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:40:04 d2.utils.events]: \u001b[0m eta: 19:07:37  iter: 13459  total_loss: 0.6036  loss_cls: 0.2611  loss_box_reg: 0.2724  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.04003  time: 1.2983  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:40:30 d2.utils.events]: \u001b[0m eta: 19:07:17  iter: 13479  total_loss: 0.5808  loss_cls: 0.2377  loss_box_reg: 0.2816  loss_rpn_cls: 0.0216  loss_rpn_loc: 0.04619  time: 1.2983  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:40:56 d2.utils.events]: \u001b[0m eta: 19:07:02  iter: 13499  total_loss: 0.7746  loss_cls: 0.3441  loss_box_reg: 0.3507  loss_rpn_cls: 0.02031  loss_rpn_loc: 0.05442  time: 1.2984  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:41:22 d2.utils.events]: \u001b[0m eta: 19:06:39  iter: 13519  total_loss: 0.5921  loss_cls: 0.2566  loss_box_reg: 0.2647  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.03834  time: 1.2984  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:41:48 d2.utils.events]: \u001b[0m eta: 19:06:11  iter: 13539  total_loss: 0.6412  loss_cls: 0.2655  loss_box_reg: 0.2845  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.0603  time: 1.2984  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:42:14 d2.utils.events]: \u001b[0m eta: 19:05:47  iter: 13559  total_loss: 0.5923  loss_cls: 0.2399  loss_box_reg: 0.2921  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.03976  time: 1.2984  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:42:41 d2.utils.events]: \u001b[0m eta: 19:05:33  iter: 13579  total_loss: 0.592  loss_cls: 0.2437  loss_box_reg: 0.245  loss_rpn_cls: 0.02378  loss_rpn_loc: 0.03994  time: 1.2984  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:43:07 d2.utils.events]: \u001b[0m eta: 19:04:53  iter: 13599  total_loss: 0.6312  loss_cls: 0.2426  loss_box_reg: 0.2707  loss_rpn_cls: 0.03174  loss_rpn_loc: 0.06448  time: 1.2984  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:43:33 d2.utils.events]: \u001b[0m eta: 19:04:35  iter: 13619  total_loss: 0.4778  loss_cls: 0.2038  loss_box_reg: 0.2168  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.04865  time: 1.2984  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:43:59 d2.utils.events]: \u001b[0m eta: 19:04:04  iter: 13639  total_loss: 0.4685  loss_cls: 0.2127  loss_box_reg: 0.2154  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.04787  time: 1.2984  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:44:25 d2.utils.events]: \u001b[0m eta: 19:03:36  iter: 13659  total_loss: 0.4165  loss_cls: 0.1838  loss_box_reg: 0.2053  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.04157  time: 1.2984  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:44:50 d2.utils.events]: \u001b[0m eta: 19:03:08  iter: 13679  total_loss: 0.6858  loss_cls: 0.3056  loss_box_reg: 0.2734  loss_rpn_cls: 0.02273  loss_rpn_loc: 0.05052  time: 1.2984  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:45:17 d2.utils.events]: \u001b[0m eta: 19:02:47  iter: 13699  total_loss: 0.5635  loss_cls: 0.2404  loss_box_reg: 0.2554  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.08119  time: 1.2984  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:45:43 d2.utils.events]: \u001b[0m eta: 19:02:18  iter: 13719  total_loss: 0.6781  loss_cls: 0.2994  loss_box_reg: 0.3142  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.06129  time: 1.2984  data_time: 0.0230  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:46:09 d2.utils.events]: \u001b[0m eta: 19:02:18  iter: 13739  total_loss: 0.6728  loss_cls: 0.286  loss_box_reg: 0.2494  loss_rpn_cls: 0.02077  loss_rpn_loc: 0.06181  time: 1.2984  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:46:35 d2.utils.events]: \u001b[0m eta: 19:01:59  iter: 13759  total_loss: 0.5456  loss_cls: 0.2079  loss_box_reg: 0.2582  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.04045  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:47:00 d2.utils.events]: \u001b[0m eta: 19:01:01  iter: 13779  total_loss: 0.6079  loss_cls: 0.2553  loss_box_reg: 0.2687  loss_rpn_cls: 0.02731  loss_rpn_loc: 0.0393  time: 1.2984  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:47:26 d2.utils.events]: \u001b[0m eta: 19:01:07  iter: 13799  total_loss: 0.6467  loss_cls: 0.2728  loss_box_reg: 0.2881  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.04218  time: 1.2984  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:47:52 d2.utils.events]: \u001b[0m eta: 19:00:20  iter: 13819  total_loss: 0.5359  loss_cls: 0.2298  loss_box_reg: 0.2267  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.04866  time: 1.2984  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:48:18 d2.utils.events]: \u001b[0m eta: 18:59:54  iter: 13839  total_loss: 0.5792  loss_cls: 0.2556  loss_box_reg: 0.2517  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.04487  time: 1.2984  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:48:45 d2.utils.events]: \u001b[0m eta: 19:00:05  iter: 13859  total_loss: 0.7052  loss_cls: 0.316  loss_box_reg: 0.2977  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.05565  time: 1.2984  data_time: 0.0214  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:49:11 d2.utils.events]: \u001b[0m eta: 19:00:01  iter: 13879  total_loss: 0.5708  loss_cls: 0.241  loss_box_reg: 0.2411  loss_rpn_cls: 0.02297  loss_rpn_loc: 0.0494  time: 1.2984  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:49:37 d2.utils.events]: \u001b[0m eta: 18:59:35  iter: 13899  total_loss: 0.6739  loss_cls: 0.2498  loss_box_reg: 0.2478  loss_rpn_cls: 0.02168  loss_rpn_loc: 0.05486  time: 1.2984  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:50:03 d2.utils.events]: \u001b[0m eta: 18:59:09  iter: 13919  total_loss: 0.5784  loss_cls: 0.2179  loss_box_reg: 0.2601  loss_rpn_cls: 0.02395  loss_rpn_loc: 0.06124  time: 1.2984  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:50:29 d2.utils.events]: \u001b[0m eta: 18:58:56  iter: 13939  total_loss: 0.5976  loss_cls: 0.2198  loss_box_reg: 0.2674  loss_rpn_cls: 0.02081  loss_rpn_loc: 0.03728  time: 1.2984  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:50:55 d2.utils.events]: \u001b[0m eta: 18:58:50  iter: 13959  total_loss: 0.7102  loss_cls: 0.3017  loss_box_reg: 0.3061  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.05143  time: 1.2984  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:51:21 d2.utils.events]: \u001b[0m eta: 18:58:25  iter: 13979  total_loss: 0.5537  loss_cls: 0.2178  loss_box_reg: 0.2292  loss_rpn_cls: 0.016  loss_rpn_loc: 0.03949  time: 1.2984  data_time: 0.0248  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:51:47 d2.utils.events]: \u001b[0m eta: 18:58:05  iter: 13999  total_loss: 0.6222  loss_cls: 0.2734  loss_box_reg: 0.2708  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.04788  time: 1.2984  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:52:13 d2.utils.events]: \u001b[0m eta: 18:57:31  iter: 14019  total_loss: 0.6646  loss_cls: 0.2716  loss_box_reg: 0.2887  loss_rpn_cls: 0.01922  loss_rpn_loc: 0.07024  time: 1.2984  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:52:39 d2.utils.events]: \u001b[0m eta: 18:56:46  iter: 14039  total_loss: 0.5224  loss_cls: 0.2201  loss_box_reg: 0.2121  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.04473  time: 1.2984  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:53:05 d2.utils.events]: \u001b[0m eta: 18:56:18  iter: 14059  total_loss: 0.5511  loss_cls: 0.1984  loss_box_reg: 0.2225  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.03913  time: 1.2984  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 671.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 13:53:14 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 13:53:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 13:53:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 13:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2593 s / img. ETA=0:03:59\n",
            "\u001b[32m[03/06 13:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2663 s / img. ETA=0:04:17\n",
            "\u001b[32m[03/06 13:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2684 s / img. ETA=0:04:11\n",
            "\u001b[32m[03/06 13:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2662 s / img. ETA=0:04:04\n",
            "\u001b[32m[03/06 13:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2649 s / img. ETA=0:03:55\n",
            "\u001b[32m[03/06 13:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2639 s / img. ETA=0:03:49\n",
            "\u001b[32m[03/06 13:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 118/878. 0.2621 s / img. ETA=0:03:41\n",
            "\u001b[32m[03/06 13:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 136/878. 0.2607 s / img. ETA=0:03:35\n",
            "\u001b[32m[03/06 13:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 154/878. 0.2609 s / img. ETA=0:03:29\n",
            "\u001b[32m[03/06 13:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 172/878. 0.2609 s / img. ETA=0:03:23\n",
            "\u001b[32m[03/06 13:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 190/878. 0.2611 s / img. ETA=0:03:18\n",
            "\u001b[32m[03/06 13:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 208/878. 0.2607 s / img. ETA=0:03:13\n",
            "\u001b[32m[03/06 13:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 226/878. 0.2607 s / img. ETA=0:03:07\n",
            "\u001b[32m[03/06 13:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 244/878. 0.2605 s / img. ETA=0:03:02\n",
            "\u001b[32m[03/06 13:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 262/878. 0.2606 s / img. ETA=0:02:57\n",
            "\u001b[32m[03/06 13:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 280/878. 0.2604 s / img. ETA=0:02:51\n",
            "\u001b[32m[03/06 13:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 297/878. 0.2608 s / img. ETA=0:02:47\n",
            "\u001b[32m[03/06 13:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 315/878. 0.2608 s / img. ETA=0:02:41\n",
            "\u001b[32m[03/06 13:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 333/878. 0.2606 s / img. ETA=0:02:36\n",
            "\u001b[32m[03/06 13:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 351/878. 0.2608 s / img. ETA=0:02:31\n",
            "\u001b[32m[03/06 13:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 369/878. 0.2607 s / img. ETA=0:02:26\n",
            "\u001b[32m[03/06 13:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 387/878. 0.2606 s / img. ETA=0:02:20\n",
            "\u001b[32m[03/06 13:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 405/878. 0.2606 s / img. ETA=0:02:15\n",
            "\u001b[32m[03/06 13:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 423/878. 0.2607 s / img. ETA=0:02:10\n",
            "\u001b[32m[03/06 13:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 441/878. 0.2606 s / img. ETA=0:02:05\n",
            "\u001b[32m[03/06 13:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 459/878. 0.2606 s / img. ETA=0:02:00\n",
            "\u001b[32m[03/06 13:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 478/878. 0.2606 s / img. ETA=0:01:54\n",
            "\u001b[32m[03/06 13:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 496/878. 0.2604 s / img. ETA=0:01:49\n",
            "\u001b[32m[03/06 13:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 514/878. 0.2603 s / img. ETA=0:01:44\n",
            "\u001b[32m[03/06 13:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 532/878. 0.2603 s / img. ETA=0:01:39\n",
            "\u001b[32m[03/06 13:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 550/878. 0.2604 s / img. ETA=0:01:34\n",
            "\u001b[32m[03/06 13:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 568/878. 0.2603 s / img. ETA=0:01:28\n",
            "\u001b[32m[03/06 13:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 586/878. 0.2602 s / img. ETA=0:01:23\n",
            "\u001b[32m[03/06 13:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 604/878. 0.2603 s / img. ETA=0:01:18\n",
            "\u001b[32m[03/06 13:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 622/878. 0.2603 s / img. ETA=0:01:13\n",
            "\u001b[32m[03/06 13:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 640/878. 0.2603 s / img. ETA=0:01:08\n",
            "\u001b[32m[03/06 13:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 658/878. 0.2603 s / img. ETA=0:01:02\n",
            "\u001b[32m[03/06 13:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 677/878. 0.2602 s / img. ETA=0:00:57\n",
            "\u001b[32m[03/06 13:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 695/878. 0.2601 s / img. ETA=0:00:52\n",
            "\u001b[32m[03/06 13:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 713/878. 0.2603 s / img. ETA=0:00:47\n",
            "\u001b[32m[03/06 13:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 731/878. 0.2603 s / img. ETA=0:00:41\n",
            "\u001b[32m[03/06 13:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 749/878. 0.2602 s / img. ETA=0:00:36\n",
            "\u001b[32m[03/06 13:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 767/878. 0.2603 s / img. ETA=0:00:31\n",
            "\u001b[32m[03/06 13:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 785/878. 0.2603 s / img. ETA=0:00:26\n",
            "\u001b[32m[03/06 13:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 803/878. 0.2603 s / img. ETA=0:00:21\n",
            "\u001b[32m[03/06 13:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 821/878. 0.2603 s / img. ETA=0:00:16\n",
            "\u001b[32m[03/06 13:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 839/878. 0.2602 s / img. ETA=0:00:11\n",
            "\u001b[32m[03/06 13:57:20 d2.evaluation.evaluator]: \u001b[0mInference done 857/878. 0.2603 s / img. ETA=0:00:05\n",
            "\u001b[32m[03/06 13:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 875/878. 0.2603 s / img. ETA=0:00:00\n",
            "\u001b[32m[03/06 13:57:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:09.190274 (0.285441 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 13:57:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:47 (0.260172 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.98 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.13 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.125\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.128\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.272\n",
            "\u001b[32m[03/06 13:57:28 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 13:57:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 13:57:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 13:57:28 d2.evaluation.testing]: \u001b[0mcopypaste: 12.5239,24.2591,30.0867,3.9240,7.7840,12.8101\n",
            "\u001b[32m[03/06 13:57:48 d2.utils.events]: \u001b[0m eta: 18:56:06  iter: 14079  total_loss: 0.6968  loss_cls: 0.2956  loss_box_reg: 0.2994  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.05843  time: 1.2984  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:58:14 d2.utils.events]: \u001b[0m eta: 18:56:07  iter: 14099  total_loss: 0.6929  loss_cls: 0.3179  loss_box_reg: 0.2711  loss_rpn_cls: 0.02526  loss_rpn_loc: 0.06563  time: 1.2984  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:58:40 d2.utils.events]: \u001b[0m eta: 18:55:24  iter: 14119  total_loss: 0.4641  loss_cls: 0.193  loss_box_reg: 0.2125  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.03708  time: 1.2984  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:59:06 d2.utils.events]: \u001b[0m eta: 18:55:41  iter: 14139  total_loss: 0.7848  loss_cls: 0.3227  loss_box_reg: 0.3507  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.05791  time: 1.2984  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:59:32 d2.utils.events]: \u001b[0m eta: 18:55:18  iter: 14159  total_loss: 0.5809  loss_cls: 0.2408  loss_box_reg: 0.2594  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.05052  time: 1.2984  data_time: 0.0231  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 13:59:58 d2.utils.events]: \u001b[0m eta: 18:54:49  iter: 14179  total_loss: 0.7419  loss_cls: 0.273  loss_box_reg: 0.3076  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.08491  time: 1.2984  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:00:24 d2.utils.events]: \u001b[0m eta: 18:54:14  iter: 14199  total_loss: 0.6889  loss_cls: 0.273  loss_box_reg: 0.3011  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.05156  time: 1.2984  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:00:50 d2.utils.events]: \u001b[0m eta: 18:53:48  iter: 14219  total_loss: 0.7143  loss_cls: 0.2893  loss_box_reg: 0.29  loss_rpn_cls: 0.02584  loss_rpn_loc: 0.04528  time: 1.2984  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:01:17 d2.utils.events]: \u001b[0m eta: 18:53:41  iter: 14239  total_loss: 0.598  loss_cls: 0.2192  loss_box_reg: 0.234  loss_rpn_cls: 0.02656  loss_rpn_loc: 0.04942  time: 1.2985  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:01:43 d2.utils.events]: \u001b[0m eta: 18:53:15  iter: 14259  total_loss: 0.6087  loss_cls: 0.2689  loss_box_reg: 0.2458  loss_rpn_cls: 0.0207  loss_rpn_loc: 0.05785  time: 1.2985  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:02:09 d2.utils.events]: \u001b[0m eta: 18:52:57  iter: 14279  total_loss: 0.5668  loss_cls: 0.2187  loss_box_reg: 0.2316  loss_rpn_cls: 0.03012  loss_rpn_loc: 0.05125  time: 1.2985  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:02:35 d2.utils.events]: \u001b[0m eta: 18:52:27  iter: 14299  total_loss: 0.7255  loss_cls: 0.2332  loss_box_reg: 0.2538  loss_rpn_cls: 0.02445  loss_rpn_loc: 0.05894  time: 1.2985  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:03:01 d2.utils.events]: \u001b[0m eta: 18:51:51  iter: 14319  total_loss: 0.5178  loss_cls: 0.2077  loss_box_reg: 0.2424  loss_rpn_cls: 0.01959  loss_rpn_loc: 0.03035  time: 1.2985  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:03:27 d2.utils.events]: \u001b[0m eta: 18:51:25  iter: 14339  total_loss: 0.6238  loss_cls: 0.2386  loss_box_reg: 0.2854  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.03848  time: 1.2985  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:03:53 d2.utils.events]: \u001b[0m eta: 18:50:56  iter: 14359  total_loss: 0.6172  loss_cls: 0.2768  loss_box_reg: 0.279  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.05446  time: 1.2985  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:04:19 d2.utils.events]: \u001b[0m eta: 18:50:30  iter: 14379  total_loss: 0.5013  loss_cls: 0.2107  loss_box_reg: 0.2102  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.0377  time: 1.2985  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:04:45 d2.utils.events]: \u001b[0m eta: 18:49:48  iter: 14399  total_loss: 0.7226  loss_cls: 0.3275  loss_box_reg: 0.2406  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.04839  time: 1.2985  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:05:11 d2.utils.events]: \u001b[0m eta: 18:49:04  iter: 14419  total_loss: 0.6855  loss_cls: 0.2714  loss_box_reg: 0.2152  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.06817  time: 1.2985  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:05:37 d2.utils.events]: \u001b[0m eta: 18:48:05  iter: 14439  total_loss: 0.6451  loss_cls: 0.2235  loss_box_reg: 0.2483  loss_rpn_cls: 0.0283  loss_rpn_loc: 0.05203  time: 1.2985  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:06:03 d2.utils.events]: \u001b[0m eta: 18:48:37  iter: 14459  total_loss: 0.5852  loss_cls: 0.2289  loss_box_reg: 0.2402  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.03666  time: 1.2985  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:06:29 d2.utils.events]: \u001b[0m eta: 18:47:32  iter: 14479  total_loss: 0.6402  loss_cls: 0.2882  loss_box_reg: 0.3065  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.04408  time: 1.2985  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:06:55 d2.utils.events]: \u001b[0m eta: 18:46:47  iter: 14499  total_loss: 0.716  loss_cls: 0.3099  loss_box_reg: 0.3189  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.04141  time: 1.2985  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:07:21 d2.utils.events]: \u001b[0m eta: 18:46:22  iter: 14519  total_loss: 0.5266  loss_cls: 0.2501  loss_box_reg: 0.2686  loss_rpn_cls: 0.01601  loss_rpn_loc: 0.04047  time: 1.2985  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:07:47 d2.utils.events]: \u001b[0m eta: 18:45:39  iter: 14539  total_loss: 0.5395  loss_cls: 0.2207  loss_box_reg: 0.2295  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.04565  time: 1.2985  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:08:13 d2.utils.events]: \u001b[0m eta: 18:45:13  iter: 14559  total_loss: 0.4727  loss_cls: 0.1887  loss_box_reg: 0.2292  loss_rpn_cls: 0.02269  loss_rpn_loc: 0.04408  time: 1.2985  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:08:39 d2.utils.events]: \u001b[0m eta: 18:44:33  iter: 14579  total_loss: 0.6067  loss_cls: 0.2303  loss_box_reg: 0.2763  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.03607  time: 1.2985  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:09:04 d2.utils.events]: \u001b[0m eta: 18:44:00  iter: 14599  total_loss: 0.6103  loss_cls: 0.2427  loss_box_reg: 0.2651  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.05096  time: 1.2985  data_time: 0.0247  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:09:30 d2.utils.events]: \u001b[0m eta: 18:43:12  iter: 14619  total_loss: 0.6207  loss_cls: 0.2531  loss_box_reg: 0.2641  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.04312  time: 1.2985  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:09:56 d2.utils.events]: \u001b[0m eta: 18:42:36  iter: 14639  total_loss: 0.7134  loss_cls: 0.3072  loss_box_reg: 0.336  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.03648  time: 1.2985  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:10:22 d2.utils.events]: \u001b[0m eta: 18:42:03  iter: 14659  total_loss: 0.7582  loss_cls: 0.2654  loss_box_reg: 0.2991  loss_rpn_cls: 0.01903  loss_rpn_loc: 0.07214  time: 1.2985  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:10:48 d2.utils.events]: \u001b[0m eta: 18:41:41  iter: 14679  total_loss: 0.5852  loss_cls: 0.2739  loss_box_reg: 0.2429  loss_rpn_cls: 0.02184  loss_rpn_loc: 0.03998  time: 1.2984  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:11:14 d2.utils.events]: \u001b[0m eta: 18:41:15  iter: 14699  total_loss: 0.6978  loss_cls: 0.2877  loss_box_reg: 0.3144  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.03347  time: 1.2984  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:11:40 d2.utils.events]: \u001b[0m eta: 18:40:56  iter: 14719  total_loss: 0.6305  loss_cls: 0.2685  loss_box_reg: 0.261  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.04309  time: 1.2985  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:12:06 d2.utils.events]: \u001b[0m eta: 18:40:27  iter: 14739  total_loss: 0.6605  loss_cls: 0.2444  loss_box_reg: 0.2944  loss_rpn_cls: 0.01758  loss_rpn_loc: 0.04844  time: 1.2984  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:12:32 d2.utils.events]: \u001b[0m eta: 18:40:19  iter: 14759  total_loss: 0.6574  loss_cls: 0.3273  loss_box_reg: 0.2803  loss_rpn_cls: 0.02405  loss_rpn_loc: 0.04566  time: 1.2985  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:12:58 d2.utils.events]: \u001b[0m eta: 18:39:53  iter: 14779  total_loss: 0.6221  loss_cls: 0.2709  loss_box_reg: 0.2929  loss_rpn_cls: 0.01844  loss_rpn_loc: 0.0457  time: 1.2985  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:13:24 d2.utils.events]: \u001b[0m eta: 18:39:09  iter: 14799  total_loss: 0.603  loss_cls: 0.26  loss_box_reg: 0.2597  loss_rpn_cls: 0.02151  loss_rpn_loc: 0.04908  time: 1.2985  data_time: 0.0216  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:13:50 d2.utils.events]: \u001b[0m eta: 18:38:42  iter: 14819  total_loss: 0.6298  loss_cls: 0.2751  loss_box_reg: 0.2745  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.04999  time: 1.2985  data_time: 0.0229  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:14:16 d2.utils.events]: \u001b[0m eta: 18:38:16  iter: 14839  total_loss: 0.6183  loss_cls: 0.2446  loss_box_reg: 0.2697  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.04626  time: 1.2985  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:14:42 d2.utils.events]: \u001b[0m eta: 18:37:48  iter: 14859  total_loss: 0.6272  loss_cls: 0.2658  loss_box_reg: 0.2364  loss_rpn_cls: 0.02234  loss_rpn_loc: 0.05053  time: 1.2984  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:15:08 d2.utils.events]: \u001b[0m eta: 18:37:08  iter: 14879  total_loss: 0.6754  loss_cls: 0.2806  loss_box_reg: 0.2896  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.05607  time: 1.2985  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:15:34 d2.utils.events]: \u001b[0m eta: 18:36:47  iter: 14899  total_loss: 0.7557  loss_cls: 0.3375  loss_box_reg: 0.3763  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.06465  time: 1.2985  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:16:00 d2.utils.events]: \u001b[0m eta: 18:36:21  iter: 14919  total_loss: 0.5078  loss_cls: 0.2006  loss_box_reg: 0.2299  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.04891  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:16:26 d2.utils.events]: \u001b[0m eta: 18:35:51  iter: 14939  total_loss: 0.6595  loss_cls: 0.2865  loss_box_reg: 0.2909  loss_rpn_cls: 0.02872  loss_rpn_loc: 0.03883  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:16:52 d2.utils.events]: \u001b[0m eta: 18:35:04  iter: 14959  total_loss: 0.4743  loss_cls: 0.1809  loss_box_reg: 0.206  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.03155  time: 1.2984  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:17:18 d2.utils.events]: \u001b[0m eta: 18:34:21  iter: 14979  total_loss: 0.6799  loss_cls: 0.2863  loss_box_reg: 0.2504  loss_rpn_cls: 0.02634  loss_rpn_loc: 0.04752  time: 1.2984  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:17:44 d2.utils.events]: \u001b[0m eta: 18:34:12  iter: 14999  total_loss: 0.6059  loss_cls: 0.2555  loss_box_reg: 0.252  loss_rpn_cls: 0.03394  loss_rpn_loc: 0.07435  time: 1.2984  data_time: 0.0233  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:18:10 d2.utils.events]: \u001b[0m eta: 18:33:57  iter: 15019  total_loss: 0.6156  loss_cls: 0.2603  loss_box_reg: 0.2847  loss_rpn_cls: 0.02931  loss_rpn_loc: 0.03784  time: 1.2984  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:18:35 d2.utils.events]: \u001b[0m eta: 18:33:27  iter: 15039  total_loss: 0.5372  loss_cls: 0.2162  loss_box_reg: 0.2449  loss_rpn_cls: 0.0236  loss_rpn_loc: 0.04162  time: 1.2984  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:19:01 d2.utils.events]: \u001b[0m eta: 18:32:52  iter: 15059  total_loss: 0.7046  loss_cls: 0.2791  loss_box_reg: 0.2951  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.05129  time: 1.2984  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:19:27 d2.utils.events]: \u001b[0m eta: 18:32:12  iter: 15079  total_loss: 0.736  loss_cls: 0.2815  loss_box_reg: 0.3451  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.05311  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:19:53 d2.utils.events]: \u001b[0m eta: 18:31:41  iter: 15099  total_loss: 0.6552  loss_cls: 0.2918  loss_box_reg: 0.2947  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.0502  time: 1.2984  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:20:19 d2.utils.events]: \u001b[0m eta: 18:31:34  iter: 15119  total_loss: 0.5242  loss_cls: 0.2151  loss_box_reg: 0.2184  loss_rpn_cls: 0.02385  loss_rpn_loc: 0.0364  time: 1.2984  data_time: 0.0236  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:20:45 d2.utils.events]: \u001b[0m eta: 18:31:05  iter: 15139  total_loss: 0.6186  loss_cls: 0.2849  loss_box_reg: 0.2735  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.04808  time: 1.2984  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:21:12 d2.utils.events]: \u001b[0m eta: 18:31:05  iter: 15159  total_loss: 0.6382  loss_cls: 0.2684  loss_box_reg: 0.271  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.03865  time: 1.2984  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:21:38 d2.utils.events]: \u001b[0m eta: 18:30:39  iter: 15179  total_loss: 0.6015  loss_cls: 0.2054  loss_box_reg: 0.209  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.06088  time: 1.2984  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:22:03 d2.utils.events]: \u001b[0m eta: 18:30:06  iter: 15199  total_loss: 0.5145  loss_cls: 0.2133  loss_box_reg: 0.2222  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.03479  time: 1.2984  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:22:30 d2.utils.events]: \u001b[0m eta: 18:29:54  iter: 15219  total_loss: 0.5722  loss_cls: 0.2661  loss_box_reg: 0.2622  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.03459  time: 1.2984  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:22:56 d2.utils.events]: \u001b[0m eta: 18:29:13  iter: 15239  total_loss: 0.7426  loss_cls: 0.2974  loss_box_reg: 0.2876  loss_rpn_cls: 0.023  loss_rpn_loc: 0.06041  time: 1.2984  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:23:22 d2.utils.events]: \u001b[0m eta: 18:28:52  iter: 15259  total_loss: 0.7189  loss_cls: 0.2734  loss_box_reg: 0.3275  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.05241  time: 1.2984  data_time: 0.0180  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:23:48 d2.utils.events]: \u001b[0m eta: 18:28:30  iter: 15279  total_loss: 0.7309  loss_cls: 0.3258  loss_box_reg: 0.3805  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.03595  time: 1.2984  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:24:14 d2.utils.events]: \u001b[0m eta: 18:27:50  iter: 15299  total_loss: 0.601  loss_cls: 0.2031  loss_box_reg: 0.2584  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.06474  time: 1.2984  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:24:40 d2.utils.events]: \u001b[0m eta: 18:27:48  iter: 15319  total_loss: 0.6089  loss_cls: 0.2762  loss_box_reg: 0.2559  loss_rpn_cls: 0.01733  loss_rpn_loc: 0.05675  time: 1.2985  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:25:06 d2.utils.events]: \u001b[0m eta: 18:27:50  iter: 15339  total_loss: 0.5059  loss_cls: 0.2163  loss_box_reg: 0.2318  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.03949  time: 1.2985  data_time: 0.0184  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:25:32 d2.utils.events]: \u001b[0m eta: 18:27:10  iter: 15359  total_loss: 0.5762  loss_cls: 0.2327  loss_box_reg: 0.2507  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.04906  time: 1.2985  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:25:58 d2.utils.events]: \u001b[0m eta: 18:26:30  iter: 15379  total_loss: 0.62  loss_cls: 0.2509  loss_box_reg: 0.2792  loss_rpn_cls: 0.01613  loss_rpn_loc: 0.05065  time: 1.2984  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:26:24 d2.utils.events]: \u001b[0m eta: 18:26:03  iter: 15399  total_loss: 0.4438  loss_cls: 0.1723  loss_box_reg: 0.1776  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.04813  time: 1.2984  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:26:50 d2.utils.events]: \u001b[0m eta: 18:25:33  iter: 15419  total_loss: 0.717  loss_cls: 0.3069  loss_box_reg: 0.3207  loss_rpn_cls: 0.02701  loss_rpn_loc: 0.05037  time: 1.2985  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:27:15 d2.utils.events]: \u001b[0m eta: 18:25:00  iter: 15439  total_loss: 0.4861  loss_cls: 0.1879  loss_box_reg: 0.2013  loss_rpn_cls: 0.02513  loss_rpn_loc: 0.03607  time: 1.2984  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:27:41 d2.utils.events]: \u001b[0m eta: 18:24:06  iter: 15459  total_loss: 0.6977  loss_cls: 0.3103  loss_box_reg: 0.309  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.04483  time: 1.2984  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:28:07 d2.utils.events]: \u001b[0m eta: 18:23:49  iter: 15479  total_loss: 0.8007  loss_cls: 0.3426  loss_box_reg: 0.3564  loss_rpn_cls: 0.02432  loss_rpn_loc: 0.05292  time: 1.2984  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:28:33 d2.utils.events]: \u001b[0m eta: 18:23:23  iter: 15499  total_loss: 0.5933  loss_cls: 0.2601  loss_box_reg: 0.2439  loss_rpn_cls: 0.03056  loss_rpn_loc: 0.04282  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:28:59 d2.utils.events]: \u001b[0m eta: 18:23:07  iter: 15519  total_loss: 0.6208  loss_cls: 0.2432  loss_box_reg: 0.2726  loss_rpn_cls: 0.02245  loss_rpn_loc: 0.03716  time: 1.2984  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:29:25 d2.utils.events]: \u001b[0m eta: 18:22:46  iter: 15539  total_loss: 0.7225  loss_cls: 0.3204  loss_box_reg: 0.3102  loss_rpn_cls: 0.02942  loss_rpn_loc: 0.08507  time: 1.2984  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:29:51 d2.utils.events]: \u001b[0m eta: 18:22:20  iter: 15559  total_loss: 0.5801  loss_cls: 0.243  loss_box_reg: 0.2528  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.04281  time: 1.2984  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:30:17 d2.utils.events]: \u001b[0m eta: 18:22:03  iter: 15579  total_loss: 0.6506  loss_cls: 0.291  loss_box_reg: 0.2573  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.05487  time: 1.2984  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:30:43 d2.utils.events]: \u001b[0m eta: 18:21:42  iter: 15599  total_loss: 0.6495  loss_cls: 0.2584  loss_box_reg: 0.312  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.04319  time: 1.2984  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:31:09 d2.utils.events]: \u001b[0m eta: 18:21:19  iter: 15619  total_loss: 0.561  loss_cls: 0.206  loss_box_reg: 0.2497  loss_rpn_cls: 0.02449  loss_rpn_loc: 0.04004  time: 1.2984  data_time: 0.0233  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:31:35 d2.utils.events]: \u001b[0m eta: 18:20:43  iter: 15639  total_loss: 0.6462  loss_cls: 0.2699  loss_box_reg: 0.2726  loss_rpn_cls: 0.01994  loss_rpn_loc: 0.04224  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:32:01 d2.utils.events]: \u001b[0m eta: 18:20:54  iter: 15659  total_loss: 0.7989  loss_cls: 0.328  loss_box_reg: 0.3369  loss_rpn_cls: 0.02821  loss_rpn_loc: 0.05157  time: 1.2984  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:32:28 d2.utils.events]: \u001b[0m eta: 18:20:48  iter: 15679  total_loss: 0.5415  loss_cls: 0.202  loss_box_reg: 0.2434  loss_rpn_cls: 0.01903  loss_rpn_loc: 0.04587  time: 1.2985  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:32:54 d2.utils.events]: \u001b[0m eta: 18:20:16  iter: 15699  total_loss: 0.5558  loss_cls: 0.2535  loss_box_reg: 0.2286  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.04487  time: 1.2985  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:33:20 d2.utils.events]: \u001b[0m eta: 18:20:05  iter: 15719  total_loss: 0.6377  loss_cls: 0.2821  loss_box_reg: 0.2714  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.04727  time: 1.2985  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:33:46 d2.utils.events]: \u001b[0m eta: 18:19:48  iter: 15739  total_loss: 0.5972  loss_cls: 0.2446  loss_box_reg: 0.2617  loss_rpn_cls: 0.01988  loss_rpn_loc: 0.03957  time: 1.2985  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:34:12 d2.utils.events]: \u001b[0m eta: 18:19:10  iter: 15759  total_loss: 0.5541  loss_cls: 0.2624  loss_box_reg: 0.2367  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.03561  time: 1.2985  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:34:38 d2.utils.events]: \u001b[0m eta: 18:18:47  iter: 15779  total_loss: 0.4624  loss_cls: 0.1767  loss_box_reg: 0.2008  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.04992  time: 1.2985  data_time: 0.0181  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:35:04 d2.utils.events]: \u001b[0m eta: 18:18:22  iter: 15799  total_loss: 0.6045  loss_cls: 0.2522  loss_box_reg: 0.2346  loss_rpn_cls: 0.02236  loss_rpn_loc: 0.04747  time: 1.2985  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:35:30 d2.utils.events]: \u001b[0m eta: 18:17:59  iter: 15819  total_loss: 0.5506  loss_cls: 0.224  loss_box_reg: 0.2256  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.03627  time: 1.2985  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 686.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 14:35:37 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/06 14:35:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 14:35:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 14:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2708 s / img. ETA=0:04:12\n",
            "\u001b[32m[03/06 14:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2732 s / img. ETA=0:04:17\n",
            "\u001b[32m[03/06 14:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 46/878. 0.2706 s / img. ETA=0:04:10\n",
            "\u001b[32m[03/06 14:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 64/878. 0.2689 s / img. ETA=0:04:02\n",
            "\u001b[32m[03/06 14:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 82/878. 0.2656 s / img. ETA=0:03:54\n",
            "\u001b[32m[03/06 14:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 100/878. 0.2639 s / img. ETA=0:03:46\n",
            "\u001b[32m[03/06 14:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 118/878. 0.2629 s / img. ETA=0:03:40\n",
            "\u001b[32m[03/06 14:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 136/878. 0.2621 s / img. ETA=0:03:34\n",
            "\u001b[32m[03/06 14:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 154/878. 0.2610 s / img. ETA=0:03:28\n",
            "\u001b[32m[03/06 14:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 172/878. 0.2605 s / img. ETA=0:03:22\n",
            "\u001b[32m[03/06 14:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 190/878. 0.2603 s / img. ETA=0:03:17\n",
            "\u001b[32m[03/06 14:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 209/878. 0.2599 s / img. ETA=0:03:11\n",
            "\u001b[32m[03/06 14:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 227/878. 0.2595 s / img. ETA=0:03:05\n",
            "\u001b[32m[03/06 14:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 245/878. 0.2591 s / img. ETA=0:03:00\n",
            "\u001b[32m[03/06 14:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 263/878. 0.2592 s / img. ETA=0:02:55\n",
            "\u001b[32m[03/06 14:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 281/878. 0.2591 s / img. ETA=0:02:50\n",
            "\u001b[32m[03/06 14:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 299/878. 0.2590 s / img. ETA=0:02:44\n",
            "\u001b[32m[03/06 14:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 317/878. 0.2592 s / img. ETA=0:02:39\n",
            "\u001b[32m[03/06 14:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 335/878. 0.2590 s / img. ETA=0:02:34\n",
            "\u001b[32m[03/06 14:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 353/878. 0.2590 s / img. ETA=0:02:29\n",
            "\u001b[32m[03/06 14:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 371/878. 0.2589 s / img. ETA=0:02:24\n",
            "\u001b[32m[03/06 14:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 389/878. 0.2589 s / img. ETA=0:02:19\n",
            "\u001b[32m[03/06 14:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 408/878. 0.2590 s / img. ETA=0:02:13\n",
            "\u001b[32m[03/06 14:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 426/878. 0.2591 s / img. ETA=0:02:08\n",
            "\u001b[32m[03/06 14:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 444/878. 0.2591 s / img. ETA=0:02:03\n",
            "\u001b[32m[03/06 14:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 462/878. 0.2591 s / img. ETA=0:01:58\n",
            "\u001b[32m[03/06 14:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 480/878. 0.2591 s / img. ETA=0:01:53\n",
            "\u001b[32m[03/06 14:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 498/878. 0.2592 s / img. ETA=0:01:48\n",
            "\u001b[32m[03/06 14:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 516/878. 0.2593 s / img. ETA=0:01:42\n",
            "\u001b[32m[03/06 14:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 534/878. 0.2592 s / img. ETA=0:01:37\n",
            "\u001b[32m[03/06 14:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 552/878. 0.2592 s / img. ETA=0:01:32\n",
            "\u001b[32m[03/06 14:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 570/878. 0.2592 s / img. ETA=0:01:27\n",
            "\u001b[32m[03/06 14:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 588/878. 0.2593 s / img. ETA=0:01:22\n",
            "\u001b[32m[03/06 14:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 606/878. 0.2593 s / img. ETA=0:01:17\n",
            "\u001b[32m[03/06 14:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 624/878. 0.2593 s / img. ETA=0:01:12\n",
            "\u001b[32m[03/06 14:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 643/878. 0.2593 s / img. ETA=0:01:06\n",
            "\u001b[32m[03/06 14:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 661/878. 0.2592 s / img. ETA=0:01:01\n",
            "\u001b[32m[03/06 14:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 679/878. 0.2592 s / img. ETA=0:00:56\n",
            "\u001b[32m[03/06 14:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 697/878. 0.2592 s / img. ETA=0:00:51\n",
            "\u001b[32m[03/06 14:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 715/878. 0.2592 s / img. ETA=0:00:46\n",
            "\u001b[32m[03/06 14:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 733/878. 0.2591 s / img. ETA=0:00:41\n",
            "\u001b[32m[03/06 14:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 752/878. 0.2590 s / img. ETA=0:00:35\n",
            "\u001b[32m[03/06 14:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 770/878. 0.2590 s / img. ETA=0:00:30\n",
            "\u001b[32m[03/06 14:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 788/878. 0.2590 s / img. ETA=0:00:25\n",
            "\u001b[32m[03/06 14:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 806/878. 0.2590 s / img. ETA=0:00:20\n",
            "\u001b[32m[03/06 14:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 824/878. 0.2589 s / img. ETA=0:00:15\n",
            "\u001b[32m[03/06 14:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 842/878. 0.2589 s / img. ETA=0:00:10\n",
            "\u001b[32m[03/06 14:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 861/878. 0.2589 s / img. ETA=0:00:04\n",
            "\u001b[32m[03/06 14:39:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:07.208098 (0.283171 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 14:39:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.258717 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.24s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 1.10 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.16 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.293\n",
            "\u001b[32m[03/06 14:39:49 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 14:39:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 14:39:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 14:39:49 d2.evaluation.testing]: \u001b[0mcopypaste: 12.2048,23.3868,29.5815,5.5825,9.7231,12.4392\n",
            "\u001b[32m[03/06 14:40:12 d2.utils.events]: \u001b[0m eta: 18:17:34  iter: 15839  total_loss: 0.6241  loss_cls: 0.2745  loss_box_reg: 0.2714  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.03333  time: 1.2985  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:40:38 d2.utils.events]: \u001b[0m eta: 18:17:23  iter: 15859  total_loss: 0.7152  loss_cls: 0.2753  loss_box_reg: 0.338  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.0488  time: 1.2985  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:41:04 d2.utils.events]: \u001b[0m eta: 18:17:11  iter: 15879  total_loss: 0.5472  loss_cls: 0.2395  loss_box_reg: 0.2204  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.04468  time: 1.2985  data_time: 0.0182  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:41:30 d2.utils.events]: \u001b[0m eta: 18:16:16  iter: 15899  total_loss: 0.4496  loss_cls: 0.181  loss_box_reg: 0.203  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.03359  time: 1.2985  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:41:56 d2.utils.events]: \u001b[0m eta: 18:16:19  iter: 15919  total_loss: 0.6912  loss_cls: 0.2808  loss_box_reg: 0.3051  loss_rpn_cls: 0.02041  loss_rpn_loc: 0.04728  time: 1.2985  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:42:23 d2.utils.events]: \u001b[0m eta: 18:15:58  iter: 15939  total_loss: 0.5506  loss_cls: 0.2316  loss_box_reg: 0.2696  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.04957  time: 1.2985  data_time: 0.0225  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:42:48 d2.utils.events]: \u001b[0m eta: 18:15:28  iter: 15959  total_loss: 0.7114  loss_cls: 0.3102  loss_box_reg: 0.3351  loss_rpn_cls: 0.0219  loss_rpn_loc: 0.05159  time: 1.2985  data_time: 0.0234  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:43:14 d2.utils.events]: \u001b[0m eta: 18:14:38  iter: 15979  total_loss: 0.6202  loss_cls: 0.2503  loss_box_reg: 0.268  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.03883  time: 1.2985  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:43:40 d2.utils.events]: \u001b[0m eta: 18:14:10  iter: 15999  total_loss: 0.5752  loss_cls: 0.2209  loss_box_reg: 0.2371  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.04206  time: 1.2985  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:44:06 d2.utils.events]: \u001b[0m eta: 18:13:44  iter: 16019  total_loss: 0.6331  loss_cls: 0.256  loss_box_reg: 0.278  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.0712  time: 1.2985  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:44:33 d2.utils.events]: \u001b[0m eta: 18:13:53  iter: 16039  total_loss: 0.6754  loss_cls: 0.2644  loss_box_reg: 0.2709  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.06616  time: 1.2985  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:44:59 d2.utils.events]: \u001b[0m eta: 18:13:41  iter: 16059  total_loss: 0.522  loss_cls: 0.2438  loss_box_reg: 0.2198  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.04515  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:45:25 d2.utils.events]: \u001b[0m eta: 18:13:37  iter: 16079  total_loss: 0.5039  loss_cls: 0.214  loss_box_reg: 0.2152  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.05836  time: 1.2986  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:45:52 d2.utils.events]: \u001b[0m eta: 18:13:33  iter: 16099  total_loss: 0.4895  loss_cls: 0.2327  loss_box_reg: 0.2325  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.03569  time: 1.2986  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:46:18 d2.utils.events]: \u001b[0m eta: 18:12:27  iter: 16119  total_loss: 0.5861  loss_cls: 0.2424  loss_box_reg: 0.2528  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.04129  time: 1.2986  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:46:43 d2.utils.events]: \u001b[0m eta: 18:11:58  iter: 16139  total_loss: 0.5582  loss_cls: 0.1941  loss_box_reg: 0.2487  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.03827  time: 1.2986  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:47:10 d2.utils.events]: \u001b[0m eta: 18:11:18  iter: 16159  total_loss: 0.5266  loss_cls: 0.2424  loss_box_reg: 0.2423  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.03503  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:47:36 d2.utils.events]: \u001b[0m eta: 18:11:01  iter: 16179  total_loss: 0.6532  loss_cls: 0.2402  loss_box_reg: 0.2857  loss_rpn_cls: 0.01658  loss_rpn_loc: 0.05953  time: 1.2986  data_time: 0.0192  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:48:02 d2.utils.events]: \u001b[0m eta: 18:10:36  iter: 16199  total_loss: 0.6002  loss_cls: 0.2415  loss_box_reg: 0.2683  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.05005  time: 1.2986  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:48:28 d2.utils.events]: \u001b[0m eta: 18:09:57  iter: 16219  total_loss: 0.622  loss_cls: 0.2695  loss_box_reg: 0.298  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.04186  time: 1.2986  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:48:54 d2.utils.events]: \u001b[0m eta: 18:09:12  iter: 16239  total_loss: 0.701  loss_cls: 0.3019  loss_box_reg: 0.2834  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.04895  time: 1.2986  data_time: 0.0240  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:49:20 d2.utils.events]: \u001b[0m eta: 18:09:00  iter: 16259  total_loss: 0.7206  loss_cls: 0.2809  loss_box_reg: 0.3256  loss_rpn_cls: 0.01542  loss_rpn_loc: 0.05948  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:49:46 d2.utils.events]: \u001b[0m eta: 18:08:39  iter: 16279  total_loss: 0.4599  loss_cls: 0.1838  loss_box_reg: 0.2031  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.04231  time: 1.2986  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:50:11 d2.utils.events]: \u001b[0m eta: 18:08:13  iter: 16299  total_loss: 0.5896  loss_cls: 0.2472  loss_box_reg: 0.2889  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.05175  time: 1.2986  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:50:37 d2.utils.events]: \u001b[0m eta: 18:07:30  iter: 16319  total_loss: 0.6343  loss_cls: 0.2778  loss_box_reg: 0.2752  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.04722  time: 1.2986  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:51:03 d2.utils.events]: \u001b[0m eta: 18:07:04  iter: 16339  total_loss: 0.5978  loss_cls: 0.2593  loss_box_reg: 0.2505  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.05011  time: 1.2986  data_time: 0.0218  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:51:29 d2.utils.events]: \u001b[0m eta: 18:06:56  iter: 16359  total_loss: 0.8061  loss_cls: 0.3219  loss_box_reg: 0.3336  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.05249  time: 1.2986  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:51:56 d2.utils.events]: \u001b[0m eta: 18:06:51  iter: 16379  total_loss: 0.6623  loss_cls: 0.2572  loss_box_reg: 0.2429  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.1058  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:52:22 d2.utils.events]: \u001b[0m eta: 18:06:43  iter: 16399  total_loss: 0.595  loss_cls: 0.2302  loss_box_reg: 0.2429  loss_rpn_cls: 0.02506  loss_rpn_loc: 0.04772  time: 1.2986  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:52:48 d2.utils.events]: \u001b[0m eta: 18:06:31  iter: 16419  total_loss: 0.5357  loss_cls: 0.1955  loss_box_reg: 0.2289  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.0574  time: 1.2986  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:53:13 d2.utils.events]: \u001b[0m eta: 18:06:00  iter: 16439  total_loss: 0.5703  loss_cls: 0.2275  loss_box_reg: 0.2365  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.05033  time: 1.2986  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:53:40 d2.utils.events]: \u001b[0m eta: 18:05:49  iter: 16459  total_loss: 0.6221  loss_cls: 0.1935  loss_box_reg: 0.2212  loss_rpn_cls: 0.02834  loss_rpn_loc: 0.06243  time: 1.2986  data_time: 0.0250  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:54:06 d2.utils.events]: \u001b[0m eta: 18:05:29  iter: 16479  total_loss: 0.5117  loss_cls: 0.2172  loss_box_reg: 0.2537  loss_rpn_cls: 0.02278  loss_rpn_loc: 0.04837  time: 1.2986  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:54:32 d2.utils.events]: \u001b[0m eta: 18:04:59  iter: 16499  total_loss: 0.5785  loss_cls: 0.2275  loss_box_reg: 0.2264  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.05173  time: 1.2986  data_time: 0.0218  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:54:58 d2.utils.events]: \u001b[0m eta: 18:04:25  iter: 16519  total_loss: 0.6686  loss_cls: 0.2672  loss_box_reg: 0.2377  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.05176  time: 1.2986  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:55:24 d2.utils.events]: \u001b[0m eta: 18:03:42  iter: 16539  total_loss: 0.4894  loss_cls: 0.2163  loss_box_reg: 0.242  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.04407  time: 1.2986  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:55:50 d2.utils.events]: \u001b[0m eta: 18:03:36  iter: 16559  total_loss: 0.5785  loss_cls: 0.2534  loss_box_reg: 0.2562  loss_rpn_cls: 0.02044  loss_rpn_loc: 0.02996  time: 1.2986  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:56:16 d2.utils.events]: \u001b[0m eta: 18:03:05  iter: 16579  total_loss: 0.5732  loss_cls: 0.2204  loss_box_reg: 0.2488  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.04413  time: 1.2986  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:56:42 d2.utils.events]: \u001b[0m eta: 18:02:40  iter: 16599  total_loss: 0.82  loss_cls: 0.3349  loss_box_reg: 0.3359  loss_rpn_cls: 0.02306  loss_rpn_loc: 0.06655  time: 1.2986  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:57:08 d2.utils.events]: \u001b[0m eta: 18:01:50  iter: 16619  total_loss: 0.67  loss_cls: 0.2288  loss_box_reg: 0.2401  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.04434  time: 1.2986  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:57:33 d2.utils.events]: \u001b[0m eta: 18:01:52  iter: 16639  total_loss: 0.6497  loss_cls: 0.2891  loss_box_reg: 0.2955  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.05738  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:57:59 d2.utils.events]: \u001b[0m eta: 18:00:51  iter: 16659  total_loss: 0.6905  loss_cls: 0.2966  loss_box_reg: 0.3057  loss_rpn_cls: 0.02244  loss_rpn_loc: 0.04751  time: 1.2986  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:58:26 d2.utils.events]: \u001b[0m eta: 18:00:27  iter: 16679  total_loss: 0.498  loss_cls: 0.2077  loss_box_reg: 0.2354  loss_rpn_cls: 0.01948  loss_rpn_loc: 0.04343  time: 1.2986  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:58:51 d2.utils.events]: \u001b[0m eta: 17:59:58  iter: 16699  total_loss: 0.6385  loss_cls: 0.2848  loss_box_reg: 0.2825  loss_rpn_cls: 0.02256  loss_rpn_loc: 0.0472  time: 1.2986  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:59:17 d2.utils.events]: \u001b[0m eta: 17:59:26  iter: 16719  total_loss: 0.6801  loss_cls: 0.2934  loss_box_reg: 0.3095  loss_rpn_cls: 0.01939  loss_rpn_loc: 0.04793  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 14:59:43 d2.utils.events]: \u001b[0m eta: 17:58:37  iter: 16739  total_loss: 0.5303  loss_cls: 0.2085  loss_box_reg: 0.2426  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.02816  time: 1.2986  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:00:09 d2.utils.events]: \u001b[0m eta: 17:58:09  iter: 16759  total_loss: 0.454  loss_cls: 0.1703  loss_box_reg: 0.1943  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.03471  time: 1.2986  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:00:35 d2.utils.events]: \u001b[0m eta: 17:57:38  iter: 16779  total_loss: 0.6404  loss_cls: 0.2636  loss_box_reg: 0.301  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.05216  time: 1.2986  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:01:01 d2.utils.events]: \u001b[0m eta: 17:57:12  iter: 16799  total_loss: 0.7041  loss_cls: 0.2779  loss_box_reg: 0.2704  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.05244  time: 1.2986  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:01:27 d2.utils.events]: \u001b[0m eta: 17:56:46  iter: 16819  total_loss: 0.5876  loss_cls: 0.206  loss_box_reg: 0.2452  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.03893  time: 1.2986  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:01:53 d2.utils.events]: \u001b[0m eta: 17:56:06  iter: 16839  total_loss: 0.4343  loss_cls: 0.1528  loss_box_reg: 0.2165  loss_rpn_cls: 0.02058  loss_rpn_loc: 0.03383  time: 1.2986  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:02:19 d2.utils.events]: \u001b[0m eta: 17:55:23  iter: 16859  total_loss: 0.644  loss_cls: 0.2868  loss_box_reg: 0.2899  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.04578  time: 1.2986  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:02:45 d2.utils.events]: \u001b[0m eta: 17:54:47  iter: 16879  total_loss: 0.6165  loss_cls: 0.2543  loss_box_reg: 0.2613  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.0718  time: 1.2986  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:03:11 d2.utils.events]: \u001b[0m eta: 17:54:38  iter: 16899  total_loss: 0.6016  loss_cls: 0.2651  loss_box_reg: 0.26  loss_rpn_cls: 0.01008  loss_rpn_loc: 0.03957  time: 1.2986  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:03:37 d2.utils.events]: \u001b[0m eta: 17:53:55  iter: 16919  total_loss: 0.6491  loss_cls: 0.32  loss_box_reg: 0.2625  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.03571  time: 1.2986  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:04:03 d2.utils.events]: \u001b[0m eta: 17:53:43  iter: 16939  total_loss: 0.6653  loss_cls: 0.2526  loss_box_reg: 0.2649  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.047  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:04:29 d2.utils.events]: \u001b[0m eta: 17:53:30  iter: 16959  total_loss: 0.609  loss_cls: 0.2762  loss_box_reg: 0.2722  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.05143  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:04:55 d2.utils.events]: \u001b[0m eta: 17:53:00  iter: 16979  total_loss: 0.5692  loss_cls: 0.2502  loss_box_reg: 0.2477  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.04104  time: 1.2986  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:05:21 d2.utils.events]: \u001b[0m eta: 17:52:28  iter: 16999  total_loss: 0.5776  loss_cls: 0.2738  loss_box_reg: 0.2209  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.02934  time: 1.2986  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:05:47 d2.utils.events]: \u001b[0m eta: 17:52:00  iter: 17019  total_loss: 0.695  loss_cls: 0.3314  loss_box_reg: 0.3137  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.04276  time: 1.2986  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:06:13 d2.utils.events]: \u001b[0m eta: 17:51:20  iter: 17039  total_loss: 0.489  loss_cls: 0.1961  loss_box_reg: 0.2388  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.03401  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:06:39 d2.utils.events]: \u001b[0m eta: 17:50:30  iter: 17059  total_loss: 0.6377  loss_cls: 0.2787  loss_box_reg: 0.3037  loss_rpn_cls: 0.01572  loss_rpn_loc: 0.03283  time: 1.2986  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:07:05 d2.utils.events]: \u001b[0m eta: 17:50:04  iter: 17079  total_loss: 0.5831  loss_cls: 0.2551  loss_box_reg: 0.2497  loss_rpn_cls: 0.02036  loss_rpn_loc: 0.03598  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:07:31 d2.utils.events]: \u001b[0m eta: 17:49:38  iter: 17099  total_loss: 0.5623  loss_cls: 0.2073  loss_box_reg: 0.2043  loss_rpn_cls: 0.01733  loss_rpn_loc: 0.04244  time: 1.2986  data_time: 0.0241  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:07:57 d2.utils.events]: \u001b[0m eta: 17:49:06  iter: 17119  total_loss: 0.5843  loss_cls: 0.2346  loss_box_reg: 0.2748  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.03628  time: 1.2986  data_time: 0.0187  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:08:23 d2.utils.events]: \u001b[0m eta: 17:48:31  iter: 17139  total_loss: 0.646  loss_cls: 0.2711  loss_box_reg: 0.2774  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.04604  time: 1.2986  data_time: 0.0208  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:08:49 d2.utils.events]: \u001b[0m eta: 17:47:51  iter: 17159  total_loss: 0.618  loss_cls: 0.2809  loss_box_reg: 0.2685  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.05619  time: 1.2986  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:09:15 d2.utils.events]: \u001b[0m eta: 17:46:49  iter: 17179  total_loss: 0.6432  loss_cls: 0.286  loss_box_reg: 0.2327  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.0349  time: 1.2986  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:09:41 d2.utils.events]: \u001b[0m eta: 17:46:30  iter: 17199  total_loss: 0.6735  loss_cls: 0.3014  loss_box_reg: 0.2977  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.04341  time: 1.2986  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:10:07 d2.utils.events]: \u001b[0m eta: 17:46:25  iter: 17219  total_loss: 0.6066  loss_cls: 0.2478  loss_box_reg: 0.2742  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.04093  time: 1.2986  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:10:33 d2.utils.events]: \u001b[0m eta: 17:46:26  iter: 17239  total_loss: 0.6677  loss_cls: 0.2573  loss_box_reg: 0.2918  loss_rpn_cls: 0.02148  loss_rpn_loc: 0.05584  time: 1.2986  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:10:58 d2.utils.events]: \u001b[0m eta: 17:45:23  iter: 17259  total_loss: 0.591  loss_cls: 0.2473  loss_box_reg: 0.2462  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.04736  time: 1.2986  data_time: 0.0235  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:11:24 d2.utils.events]: \u001b[0m eta: 17:44:47  iter: 17279  total_loss: 0.7516  loss_cls: 0.2759  loss_box_reg: 0.3747  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.04885  time: 1.2985  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:11:50 d2.utils.events]: \u001b[0m eta: 17:44:21  iter: 17299  total_loss: 0.6307  loss_cls: 0.293  loss_box_reg: 0.3029  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.03847  time: 1.2986  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:12:16 d2.utils.events]: \u001b[0m eta: 17:43:55  iter: 17319  total_loss: 0.6282  loss_cls: 0.2685  loss_box_reg: 0.2752  loss_rpn_cls: 0.0194  loss_rpn_loc: 0.03698  time: 1.2986  data_time: 0.0217  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:12:42 d2.utils.events]: \u001b[0m eta: 17:43:19  iter: 17339  total_loss: 0.6623  loss_cls: 0.287  loss_box_reg: 0.2986  loss_rpn_cls: 0.02297  loss_rpn_loc: 0.04617  time: 1.2985  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:13:08 d2.utils.events]: \u001b[0m eta: 17:42:55  iter: 17359  total_loss: 0.6617  loss_cls: 0.3038  loss_box_reg: 0.3029  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.04449  time: 1.2986  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:13:34 d2.utils.events]: \u001b[0m eta: 17:42:28  iter: 17379  total_loss: 0.5428  loss_cls: 0.2175  loss_box_reg: 0.2548  loss_rpn_cls: 0.01972  loss_rpn_loc: 0.04701  time: 1.2986  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:14:00 d2.utils.events]: \u001b[0m eta: 17:42:02  iter: 17399  total_loss: 0.5858  loss_cls: 0.2743  loss_box_reg: 0.2626  loss_rpn_cls: 0.02278  loss_rpn_loc: 0.05445  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:14:26 d2.utils.events]: \u001b[0m eta: 17:41:34  iter: 17419  total_loss: 0.6646  loss_cls: 0.2655  loss_box_reg: 0.2884  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.06078  time: 1.2986  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:14:52 d2.utils.events]: \u001b[0m eta: 17:41:14  iter: 17439  total_loss: 0.5807  loss_cls: 0.2509  loss_box_reg: 0.2445  loss_rpn_cls: 0.02263  loss_rpn_loc: 0.04108  time: 1.2986  data_time: 0.0227  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:15:18 d2.utils.events]: \u001b[0m eta: 17:40:55  iter: 17459  total_loss: 0.6766  loss_cls: 0.2738  loss_box_reg: 0.2638  loss_rpn_cls: 0.02012  loss_rpn_loc: 0.0639  time: 1.2986  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:15:44 d2.utils.events]: \u001b[0m eta: 17:40:15  iter: 17479  total_loss: 0.6503  loss_cls: 0.2643  loss_box_reg: 0.3064  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.05419  time: 1.2986  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:16:10 d2.utils.events]: \u001b[0m eta: 17:39:43  iter: 17499  total_loss: 0.6593  loss_cls: 0.2782  loss_box_reg: 0.304  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.04687  time: 1.2986  data_time: 0.0226  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:16:36 d2.utils.events]: \u001b[0m eta: 17:39:18  iter: 17519  total_loss: 0.5831  loss_cls: 0.2336  loss_box_reg: 0.266  loss_rpn_cls: 0.02081  loss_rpn_loc: 0.04648  time: 1.2986  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:17:02 d2.utils.events]: \u001b[0m eta: 17:39:01  iter: 17539  total_loss: 0.617  loss_cls: 0.2422  loss_box_reg: 0.2964  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.04854  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:17:28 d2.utils.events]: \u001b[0m eta: 17:38:28  iter: 17559  total_loss: 0.7417  loss_cls: 0.3289  loss_box_reg: 0.317  loss_rpn_cls: 0.02178  loss_rpn_loc: 0.0679  time: 1.2986  data_time: 0.0207  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 878/878 [00:01<00:00, 668.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 15:17:58 d2.data.common]: \u001b[0mSerializing 878 elements to byte tensors and concatenating them all ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/06 15:17:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[32m[03/06 15:17:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 878 images\n",
            "\u001b[32m[03/06 15:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/878. 0.2570 s / img. ETA=0:04:00\n",
            "\u001b[32m[03/06 15:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 28/878. 0.2653 s / img. ETA=0:04:08\n",
            "\u001b[32m[03/06 15:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 45/878. 0.2685 s / img. ETA=0:04:09\n",
            "\u001b[32m[03/06 15:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 63/878. 0.2658 s / img. ETA=0:04:01\n",
            "\u001b[32m[03/06 15:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 81/878. 0.2649 s / img. ETA=0:03:54\n",
            "\u001b[32m[03/06 15:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 99/878. 0.2645 s / img. ETA=0:03:47\n",
            "\u001b[32m[03/06 15:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 117/878. 0.2636 s / img. ETA=0:03:41\n",
            "\u001b[32m[03/06 15:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 135/878. 0.2623 s / img. ETA=0:03:35\n",
            "\u001b[32m[03/06 15:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 153/878. 0.2611 s / img. ETA=0:03:28\n",
            "\u001b[32m[03/06 15:18:48 d2.evaluation.evaluator]: \u001b[0mInference done 171/878. 0.2606 s / img. ETA=0:03:23\n",
            "\u001b[32m[03/06 15:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 189/878. 0.2603 s / img. ETA=0:03:18\n",
            "\u001b[32m[03/06 15:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 208/878. 0.2599 s / img. ETA=0:03:11\n",
            "\u001b[32m[03/06 15:19:04 d2.evaluation.evaluator]: \u001b[0mInference done 226/878. 0.2596 s / img. ETA=0:03:06\n",
            "\u001b[32m[03/06 15:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 245/878. 0.2591 s / img. ETA=0:03:00\n",
            "\u001b[32m[03/06 15:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 263/878. 0.2594 s / img. ETA=0:02:55\n",
            "\u001b[32m[03/06 15:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 282/878. 0.2590 s / img. ETA=0:02:49\n",
            "\u001b[32m[03/06 15:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 300/878. 0.2592 s / img. ETA=0:02:44\n",
            "\u001b[32m[03/06 15:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 318/878. 0.2593 s / img. ETA=0:02:39\n",
            "\u001b[32m[03/06 15:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 336/878. 0.2593 s / img. ETA=0:02:34\n",
            "\u001b[32m[03/06 15:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 354/878. 0.2594 s / img. ETA=0:02:29\n",
            "\u001b[32m[03/06 15:19:45 d2.evaluation.evaluator]: \u001b[0mInference done 372/878. 0.2594 s / img. ETA=0:02:23\n",
            "\u001b[32m[03/06 15:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 390/878. 0.2593 s / img. ETA=0:02:18\n",
            "\u001b[32m[03/06 15:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 408/878. 0.2592 s / img. ETA=0:02:13\n",
            "\u001b[32m[03/06 15:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 426/878. 0.2592 s / img. ETA=0:02:08\n",
            "\u001b[32m[03/06 15:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 444/878. 0.2590 s / img. ETA=0:02:03\n",
            "\u001b[32m[03/06 15:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 463/878. 0.2589 s / img. ETA=0:01:57\n",
            "\u001b[32m[03/06 15:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 481/878. 0.2588 s / img. ETA=0:01:52\n",
            "\u001b[32m[03/06 15:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 499/878. 0.2587 s / img. ETA=0:01:47\n",
            "\u001b[32m[03/06 15:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 517/878. 0.2588 s / img. ETA=0:01:42\n",
            "\u001b[32m[03/06 15:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 535/878. 0.2588 s / img. ETA=0:01:37\n",
            "\u001b[32m[03/06 15:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 553/878. 0.2587 s / img. ETA=0:01:32\n",
            "\u001b[32m[03/06 15:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 571/878. 0.2587 s / img. ETA=0:01:27\n",
            "\u001b[32m[03/06 15:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 590/878. 0.2586 s / img. ETA=0:01:21\n",
            "\u001b[32m[03/06 15:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 608/878. 0.2586 s / img. ETA=0:01:16\n",
            "\u001b[32m[03/06 15:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 626/878. 0.2586 s / img. ETA=0:01:11\n",
            "\u001b[32m[03/06 15:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 644/878. 0.2586 s / img. ETA=0:01:06\n",
            "\u001b[32m[03/06 15:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 662/878. 0.2587 s / img. ETA=0:01:01\n",
            "\u001b[32m[03/06 15:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 680/878. 0.2586 s / img. ETA=0:00:56\n",
            "\u001b[32m[03/06 15:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 698/878. 0.2588 s / img. ETA=0:00:51\n",
            "\u001b[32m[03/06 15:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 716/878. 0.2588 s / img. ETA=0:00:45\n",
            "\u001b[32m[03/06 15:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 734/878. 0.2587 s / img. ETA=0:00:40\n",
            "\u001b[32m[03/06 15:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 752/878. 0.2588 s / img. ETA=0:00:35\n",
            "\u001b[32m[03/06 15:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 770/878. 0.2589 s / img. ETA=0:00:30\n",
            "\u001b[32m[03/06 15:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 788/878. 0.2589 s / img. ETA=0:00:25\n",
            "\u001b[32m[03/06 15:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 806/878. 0.2589 s / img. ETA=0:00:20\n",
            "\u001b[32m[03/06 15:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 825/878. 0.2587 s / img. ETA=0:00:15\n",
            "\u001b[32m[03/06 15:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 843/878. 0.2586 s / img. ETA=0:00:09\n",
            "\u001b[32m[03/06 15:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 861/878. 0.2586 s / img. ETA=0:00:04\n",
            "\u001b[32m[03/06 15:22:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:07.354536 (0.283339 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/06 15:22:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.258442 s / img per device, on 1 devices)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.96 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.13 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.125\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.40      | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=   all | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= small | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area=medium | maxDets=100 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.40:0.95 | area= large | maxDets=100 ] = 0.276\n",
            "\u001b[32m[03/06 15:22:10 d2.engine.defaults]: \u001b[0mEvaluation results for vinbigdata_valid in csv format:\n",
            "\u001b[32m[03/06 15:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/06 15:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/06 15:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: 12.4683,24.1851,30.4510,0.6076,8.8884,12.7220\n",
            "\u001b[32m[03/06 15:22:10 d2.utils.events]: \u001b[0m eta: 17:37:47  iter: 17579  total_loss: 0.6469  loss_cls: 0.272  loss_box_reg: 0.2863  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.03693  time: 1.2985  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:22:35 d2.utils.events]: \u001b[0m eta: 17:37:18  iter: 17599  total_loss: 0.4365  loss_cls: 0.1984  loss_box_reg: 0.1948  loss_rpn_cls: 0.02356  loss_rpn_loc: 0.04266  time: 1.2985  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:23:01 d2.utils.events]: \u001b[0m eta: 17:37:04  iter: 17619  total_loss: 0.6822  loss_cls: 0.2466  loss_box_reg: 0.2203  loss_rpn_cls: 0.02527  loss_rpn_loc: 0.07051  time: 1.2985  data_time: 0.0183  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:23:27 d2.utils.events]: \u001b[0m eta: 17:36:35  iter: 17639  total_loss: 0.6002  loss_cls: 0.2526  loss_box_reg: 0.2556  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.04033  time: 1.2985  data_time: 0.0239  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:23:53 d2.utils.events]: \u001b[0m eta: 17:36:06  iter: 17659  total_loss: 0.6194  loss_cls: 0.2574  loss_box_reg: 0.2858  loss_rpn_cls: 0.01542  loss_rpn_loc: 0.03234  time: 1.2985  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:24:19 d2.utils.events]: \u001b[0m eta: 17:35:34  iter: 17679  total_loss: 0.7424  loss_cls: 0.3102  loss_box_reg: 0.3234  loss_rpn_cls: 0.03374  loss_rpn_loc: 0.06812  time: 1.2985  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:24:45 d2.utils.events]: \u001b[0m eta: 17:35:03  iter: 17699  total_loss: 0.5226  loss_cls: 0.2114  loss_box_reg: 0.2514  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.04074  time: 1.2985  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:25:12 d2.utils.events]: \u001b[0m eta: 17:34:43  iter: 17719  total_loss: 0.4671  loss_cls: 0.1999  loss_box_reg: 0.2112  loss_rpn_cls: 0.02711  loss_rpn_loc: 0.03157  time: 1.2985  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:25:37 d2.utils.events]: \u001b[0m eta: 17:34:23  iter: 17739  total_loss: 0.4808  loss_cls: 0.1833  loss_box_reg: 0.1985  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.04371  time: 1.2985  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:26:03 d2.utils.events]: \u001b[0m eta: 17:34:05  iter: 17759  total_loss: 0.6034  loss_cls: 0.2425  loss_box_reg: 0.271  loss_rpn_cls: 0.01932  loss_rpn_loc: 0.03466  time: 1.2985  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:26:30 d2.utils.events]: \u001b[0m eta: 17:33:46  iter: 17779  total_loss: 0.6361  loss_cls: 0.2982  loss_box_reg: 0.2773  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.04434  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:26:56 d2.utils.events]: \u001b[0m eta: 17:33:18  iter: 17799  total_loss: 0.6124  loss_cls: 0.2807  loss_box_reg: 0.2873  loss_rpn_cls: 0.01793  loss_rpn_loc: 0.03172  time: 1.2986  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:27:22 d2.utils.events]: \u001b[0m eta: 17:32:52  iter: 17819  total_loss: 0.5414  loss_cls: 0.2474  loss_box_reg: 0.2398  loss_rpn_cls: 0.014  loss_rpn_loc: 0.04197  time: 1.2986  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:27:47 d2.utils.events]: \u001b[0m eta: 17:32:34  iter: 17839  total_loss: 0.5137  loss_cls: 0.2364  loss_box_reg: 0.2478  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.04353  time: 1.2986  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:28:14 d2.utils.events]: \u001b[0m eta: 17:32:31  iter: 17859  total_loss: 0.7826  loss_cls: 0.3423  loss_box_reg: 0.2912  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.06609  time: 1.2986  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:28:40 d2.utils.events]: \u001b[0m eta: 17:32:26  iter: 17879  total_loss: 0.6626  loss_cls: 0.2813  loss_box_reg: 0.2947  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.06085  time: 1.2986  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:29:06 d2.utils.events]: \u001b[0m eta: 17:31:39  iter: 17899  total_loss: 0.6406  loss_cls: 0.2401  loss_box_reg: 0.2832  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.05356  time: 1.2986  data_time: 0.0215  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:29:32 d2.utils.events]: \u001b[0m eta: 17:31:13  iter: 17919  total_loss: 0.4512  loss_cls: 0.1748  loss_box_reg: 0.2096  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.04784  time: 1.2986  data_time: 0.0234  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:29:58 d2.utils.events]: \u001b[0m eta: 17:30:47  iter: 17939  total_loss: 0.53  loss_cls: 0.2302  loss_box_reg: 0.2421  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.04469  time: 1.2986  data_time: 0.0243  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:30:24 d2.utils.events]: \u001b[0m eta: 17:30:15  iter: 17959  total_loss: 0.6178  loss_cls: 0.251  loss_box_reg: 0.3043  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.0405  time: 1.2986  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:30:50 d2.utils.events]: \u001b[0m eta: 17:30:14  iter: 17979  total_loss: 0.6794  loss_cls: 0.2871  loss_box_reg: 0.2989  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.04254  time: 1.2986  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:31:16 d2.utils.events]: \u001b[0m eta: 17:29:51  iter: 17999  total_loss: 0.6241  loss_cls: 0.2542  loss_box_reg: 0.3123  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.04487  time: 1.2986  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:31:42 d2.utils.events]: \u001b[0m eta: 17:29:15  iter: 18019  total_loss: 0.6636  loss_cls: 0.2727  loss_box_reg: 0.3129  loss_rpn_cls: 0.02047  loss_rpn_loc: 0.05835  time: 1.2986  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:32:07 d2.utils.events]: \u001b[0m eta: 17:28:31  iter: 18039  total_loss: 0.5918  loss_cls: 0.2592  loss_box_reg: 0.2779  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.03691  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:32:33 d2.utils.events]: \u001b[0m eta: 17:28:09  iter: 18059  total_loss: 0.5375  loss_cls: 0.2216  loss_box_reg: 0.2302  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.04229  time: 1.2986  data_time: 0.0219  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:32:59 d2.utils.events]: \u001b[0m eta: 17:27:27  iter: 18079  total_loss: 0.553  loss_cls: 0.2064  loss_box_reg: 0.2447  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.04487  time: 1.2985  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:33:25 d2.utils.events]: \u001b[0m eta: 17:26:59  iter: 18099  total_loss: 0.5804  loss_cls: 0.2323  loss_box_reg: 0.2389  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.04173  time: 1.2985  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:33:51 d2.utils.events]: \u001b[0m eta: 17:26:42  iter: 18119  total_loss: 0.688  loss_cls: 0.2752  loss_box_reg: 0.3001  loss_rpn_cls: 0.01757  loss_rpn_loc: 0.0406  time: 1.2985  data_time: 0.0186  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:34:17 d2.utils.events]: \u001b[0m eta: 17:26:16  iter: 18139  total_loss: 0.7135  loss_cls: 0.3053  loss_box_reg: 0.3131  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.03937  time: 1.2985  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:34:43 d2.utils.events]: \u001b[0m eta: 17:26:15  iter: 18159  total_loss: 0.583  loss_cls: 0.2542  loss_box_reg: 0.2748  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.03457  time: 1.2985  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:35:09 d2.utils.events]: \u001b[0m eta: 17:26:11  iter: 18179  total_loss: 0.7156  loss_cls: 0.2775  loss_box_reg: 0.334  loss_rpn_cls: 0.02155  loss_rpn_loc: 0.05207  time: 1.2985  data_time: 0.0201  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:35:35 d2.utils.events]: \u001b[0m eta: 17:25:54  iter: 18199  total_loss: 0.7122  loss_cls: 0.3003  loss_box_reg: 0.31  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.04022  time: 1.2986  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:36:01 d2.utils.events]: \u001b[0m eta: 17:25:25  iter: 18219  total_loss: 0.6919  loss_cls: 0.243  loss_box_reg: 0.2746  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.04055  time: 1.2986  data_time: 0.0199  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:36:27 d2.utils.events]: \u001b[0m eta: 17:24:46  iter: 18239  total_loss: 0.689  loss_cls: 0.2862  loss_box_reg: 0.3144  loss_rpn_cls: 0.01784  loss_rpn_loc: 0.04396  time: 1.2985  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:36:53 d2.utils.events]: \u001b[0m eta: 17:24:59  iter: 18259  total_loss: 0.6543  loss_cls: 0.2988  loss_box_reg: 0.2706  loss_rpn_cls: 0.02578  loss_rpn_loc: 0.04543  time: 1.2985  data_time: 0.0230  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:37:19 d2.utils.events]: \u001b[0m eta: 17:24:40  iter: 18279  total_loss: 0.6719  loss_cls: 0.2548  loss_box_reg: 0.3057  loss_rpn_cls: 0.02163  loss_rpn_loc: 0.05148  time: 1.2986  data_time: 0.0185  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:37:45 d2.utils.events]: \u001b[0m eta: 17:24:21  iter: 18299  total_loss: 0.6163  loss_cls: 0.2775  loss_box_reg: 0.2341  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.04168  time: 1.2986  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:38:12 d2.utils.events]: \u001b[0m eta: 17:23:53  iter: 18319  total_loss: 0.8199  loss_cls: 0.3307  loss_box_reg: 0.3103  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.04429  time: 1.2986  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:38:38 d2.utils.events]: \u001b[0m eta: 17:23:30  iter: 18339  total_loss: 0.7043  loss_cls: 0.3041  loss_box_reg: 0.3039  loss_rpn_cls: 0.01742  loss_rpn_loc: 0.04197  time: 1.2986  data_time: 0.0206  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:39:04 d2.utils.events]: \u001b[0m eta: 17:23:03  iter: 18359  total_loss: 0.7412  loss_cls: 0.315  loss_box_reg: 0.3249  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.04273  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:39:30 d2.utils.events]: \u001b[0m eta: 17:22:41  iter: 18379  total_loss: 0.6206  loss_cls: 0.2771  loss_box_reg: 0.2833  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.0374  time: 1.2986  data_time: 0.0202  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:39:56 d2.utils.events]: \u001b[0m eta: 17:22:15  iter: 18399  total_loss: 0.4796  loss_cls: 0.1718  loss_box_reg: 0.201  loss_rpn_cls: 0.02075  loss_rpn_loc: 0.04259  time: 1.2986  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:40:22 d2.utils.events]: \u001b[0m eta: 17:22:16  iter: 18419  total_loss: 0.7505  loss_cls: 0.3168  loss_box_reg: 0.3431  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.05831  time: 1.2986  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:40:48 d2.utils.events]: \u001b[0m eta: 17:22:11  iter: 18439  total_loss: 0.6582  loss_cls: 0.2812  loss_box_reg: 0.27  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.03814  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:41:14 d2.utils.events]: \u001b[0m eta: 17:21:37  iter: 18459  total_loss: 0.7667  loss_cls: 0.3087  loss_box_reg: 0.2958  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.05789  time: 1.2986  data_time: 0.0195  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:41:40 d2.utils.events]: \u001b[0m eta: 17:21:31  iter: 18479  total_loss: 0.6544  loss_cls: 0.2807  loss_box_reg: 0.2774  loss_rpn_cls: 0.016  loss_rpn_loc: 0.06835  time: 1.2986  data_time: 0.0188  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:42:06 d2.utils.events]: \u001b[0m eta: 17:21:22  iter: 18499  total_loss: 0.6209  loss_cls: 0.2884  loss_box_reg: 0.2535  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.05165  time: 1.2986  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:42:32 d2.utils.events]: \u001b[0m eta: 17:20:50  iter: 18519  total_loss: 0.5879  loss_cls: 0.2751  loss_box_reg: 0.2736  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.04021  time: 1.2986  data_time: 0.0283  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:42:59 d2.utils.events]: \u001b[0m eta: 17:20:33  iter: 18539  total_loss: 0.6767  loss_cls: 0.2728  loss_box_reg: 0.2912  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.04119  time: 1.2986  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:43:24 d2.utils.events]: \u001b[0m eta: 17:20:04  iter: 18559  total_loss: 0.648  loss_cls: 0.2583  loss_box_reg: 0.2863  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.06415  time: 1.2986  data_time: 0.0210  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:43:51 d2.utils.events]: \u001b[0m eta: 17:19:56  iter: 18579  total_loss: 0.5932  loss_cls: 0.2138  loss_box_reg: 0.2439  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.04136  time: 1.2986  data_time: 0.0237  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:44:17 d2.utils.events]: \u001b[0m eta: 17:19:26  iter: 18599  total_loss: 0.5696  loss_cls: 0.2074  loss_box_reg: 0.2343  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.04973  time: 1.2986  data_time: 0.0224  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:44:43 d2.utils.events]: \u001b[0m eta: 17:18:58  iter: 18619  total_loss: 0.6646  loss_cls: 0.2729  loss_box_reg: 0.2614  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.04715  time: 1.2986  data_time: 0.0221  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:45:08 d2.utils.events]: \u001b[0m eta: 17:18:36  iter: 18639  total_loss: 0.6344  loss_cls: 0.2697  loss_box_reg: 0.2678  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.0359  time: 1.2986  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:45:35 d2.utils.events]: \u001b[0m eta: 17:18:17  iter: 18659  total_loss: 0.6032  loss_cls: 0.2231  loss_box_reg: 0.2617  loss_rpn_cls: 0.02232  loss_rpn_loc: 0.0595  time: 1.2986  data_time: 0.0204  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:46:00 d2.utils.events]: \u001b[0m eta: 17:17:49  iter: 18679  total_loss: 0.5755  loss_cls: 0.2396  loss_box_reg: 0.2835  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.03624  time: 1.2986  data_time: 0.0211  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:46:27 d2.utils.events]: \u001b[0m eta: 17:17:21  iter: 18699  total_loss: 0.7438  loss_cls: 0.2969  loss_box_reg: 0.3194  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.05521  time: 1.2986  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:46:53 d2.utils.events]: \u001b[0m eta: 17:17:00  iter: 18719  total_loss: 0.7373  loss_cls: 0.2927  loss_box_reg: 0.3377  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.05311  time: 1.2987  data_time: 0.0196  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:47:19 d2.utils.events]: \u001b[0m eta: 17:16:24  iter: 18739  total_loss: 0.474  loss_cls: 0.1912  loss_box_reg: 0.2298  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.05381  time: 1.2987  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:47:45 d2.utils.events]: \u001b[0m eta: 17:15:54  iter: 18759  total_loss: 0.5849  loss_cls: 0.2619  loss_box_reg: 0.2697  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.03864  time: 1.2986  data_time: 0.0214  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:48:11 d2.utils.events]: \u001b[0m eta: 17:15:14  iter: 18779  total_loss: 0.7637  loss_cls: 0.3126  loss_box_reg: 0.3153  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.06282  time: 1.2986  data_time: 0.0200  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:48:37 d2.utils.events]: \u001b[0m eta: 17:14:44  iter: 18799  total_loss: 0.5033  loss_cls: 0.1945  loss_box_reg: 0.2089  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.02994  time: 1.2986  data_time: 0.0228  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:49:03 d2.utils.events]: \u001b[0m eta: 17:14:22  iter: 18819  total_loss: 0.5191  loss_cls: 0.2109  loss_box_reg: 0.2189  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.0403  time: 1.2986  data_time: 0.0189  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:49:29 d2.utils.events]: \u001b[0m eta: 17:13:59  iter: 18839  total_loss: 0.6564  loss_cls: 0.2695  loss_box_reg: 0.2948  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.04824  time: 1.2986  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:49:55 d2.utils.events]: \u001b[0m eta: 17:13:33  iter: 18859  total_loss: 0.4687  loss_cls: 0.2083  loss_box_reg: 0.2234  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.03814  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:50:21 d2.utils.events]: \u001b[0m eta: 17:13:00  iter: 18879  total_loss: 0.644  loss_cls: 0.2838  loss_box_reg: 0.2763  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.041  time: 1.2987  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:50:47 d2.utils.events]: \u001b[0m eta: 17:12:38  iter: 18899  total_loss: 0.6691  loss_cls: 0.2822  loss_box_reg: 0.2718  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.04382  time: 1.2987  data_time: 0.0190  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:51:12 d2.utils.events]: \u001b[0m eta: 17:12:00  iter: 18919  total_loss: 0.6735  loss_cls: 0.2682  loss_box_reg: 0.3073  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.05067  time: 1.2986  data_time: 0.0205  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:51:38 d2.utils.events]: \u001b[0m eta: 17:11:24  iter: 18939  total_loss: 0.658  loss_cls: 0.2891  loss_box_reg: 0.2805  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.03989  time: 1.2986  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:52:04 d2.utils.events]: \u001b[0m eta: 17:11:17  iter: 18959  total_loss: 0.6085  loss_cls: 0.2258  loss_box_reg: 0.2326  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.04222  time: 1.2986  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:52:31 d2.utils.events]: \u001b[0m eta: 17:10:57  iter: 18979  total_loss: 0.5252  loss_cls: 0.2458  loss_box_reg: 0.2255  loss_rpn_cls: 0.0213  loss_rpn_loc: 0.04831  time: 1.2987  data_time: 0.0247  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:52:57 d2.utils.events]: \u001b[0m eta: 17:10:34  iter: 18999  total_loss: 0.541  loss_cls: 0.2338  loss_box_reg: 0.2303  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.0443  time: 1.2987  data_time: 0.0194  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:53:23 d2.utils.events]: \u001b[0m eta: 17:10:12  iter: 19019  total_loss: 0.5221  loss_cls: 0.2063  loss_box_reg: 0.2502  loss_rpn_cls: 0.009583  loss_rpn_loc: 0.04659  time: 1.2987  data_time: 0.0193  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:53:49 d2.utils.events]: \u001b[0m eta: 17:09:58  iter: 19039  total_loss: 0.5956  loss_cls: 0.2235  loss_box_reg: 0.2606  loss_rpn_cls: 0.0168  loss_rpn_loc: 0.04954  time: 1.2987  data_time: 0.0226  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:54:15 d2.utils.events]: \u001b[0m eta: 17:09:37  iter: 19059  total_loss: 0.6548  loss_cls: 0.2668  loss_box_reg: 0.2392  loss_rpn_cls: 0.02152  loss_rpn_loc: 0.05111  time: 1.2987  data_time: 0.0191  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:54:41 d2.utils.events]: \u001b[0m eta: 17:09:25  iter: 19079  total_loss: 0.5194  loss_cls: 0.2066  loss_box_reg: 0.2319  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.03702  time: 1.2987  data_time: 0.0203  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:55:07 d2.utils.events]: \u001b[0m eta: 17:08:51  iter: 19099  total_loss: 0.6329  loss_cls: 0.2753  loss_box_reg: 0.2767  loss_rpn_cls: 0.02812  loss_rpn_loc: 0.05537  time: 1.2987  data_time: 0.0198  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:55:33 d2.utils.events]: \u001b[0m eta: 17:08:26  iter: 19119  total_loss: 0.5165  loss_cls: 0.1892  loss_box_reg: 0.2511  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.04006  time: 1.2986  data_time: 0.0223  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:55:58 d2.utils.events]: \u001b[0m eta: 17:07:51  iter: 19139  total_loss: 0.7395  loss_cls: 0.3163  loss_box_reg: 0.3123  loss_rpn_cls: 0.02106  loss_rpn_loc: 0.06317  time: 1.2986  data_time: 0.0212  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:56:24 d2.utils.events]: \u001b[0m eta: 17:07:21  iter: 19159  total_loss: 0.5451  loss_cls: 0.2274  loss_box_reg: 0.2284  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.04424  time: 1.2986  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:56:51 d2.utils.events]: \u001b[0m eta: 17:07:08  iter: 19179  total_loss: 0.6946  loss_cls: 0.2823  loss_box_reg: 0.2911  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.03971  time: 1.2987  data_time: 0.0227  lr: 0.003  max_mem: 11748M\n",
            "\u001b[32m[03/06 15:57:17 d2.utils.events]: \u001b[0m eta: 17:06:42  iter: 19199  total_loss: 0.6986  loss_cls: 0.2576  loss_box_reg: 0.2728  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.05338  time: 1.2987  data_time: 0.0197  lr: 0.003  max_mem: 11748M\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}